{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import gym\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\") \n",
    "from lib.envs.cliff_walking import CliffWalkingEnv\n",
    "from lib import plotting\n",
    "\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "matplotlib.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-25 12:26:32,375] Making new env: CartPole-v0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2) {0, 1}\n",
      "Env.Observation_Space: Box(4,)\n",
      "Sample: [  1.86651469e+00  -3.80121549e+37  -3.03092243e-01  -3.28260479e+38]\n",
      "Low: [ -4.80000000e+00  -3.40282347e+38  -4.18879020e-01  -3.40282347e+38]\n",
      "High: [  4.80000000e+00   3.40282347e+38   4.18879020e-01   3.40282347e+38]\n",
      "Next_State: [ 0.00638371  0.20040789 -0.0422918  -0.30179293]  Reward: 1.0  Done: False  _: {}\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "print (env.action_space, set([env.action_space.sample() for _ in range(100)]))\n",
    "print ('Env.Observation_Space:',env.observation_space)\n",
    "print ('Sample:',env.observation_space.sample())\n",
    "print ('Low:',env.observation_space.low)\n",
    "print ('High:',env.observation_space.high)\n",
    "next_state, reward, done, _ = env.step(env.action_space.sample())\n",
    "print ('Next_State:',next_state, ' Reward:',reward, ' Done:', done, ' _:',_)\n",
    "# print ('Low:',env.action_space.low)\n",
    "# print ('High:',env.action_space.high)\n",
    "\n",
    "# for _ in range(1000):\n",
    "#     time.sleep(0.1)\n",
    "#     env.render(close=False)\n",
    "#     state, reward, done, blah = env.step(env.action_space.sample()) # take a random action\n",
    "#     if done == True:\n",
    "#         print (state, reward, done, blah)\n",
    "#         env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('rbf1', RBFSampler(gamma=5.0, n_components=100, random_state=None)), ('rbf2', RBFSampler(gamma=2.0, n_components=100, random_state=None)), ('rbf3', RBFSampler(gamma=1.0, n_components=100, random_state=None)), ('rbf4', RBFSampler(gamma=0.5, n_components=100, random_state=None))],\n",
       "       transformer_weights=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observation_examples = np.array([env.observation_space.sample() for x in range(10000)])\n",
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler.fit(observation_examples)\n",
    "\n",
    "# Used to converte a state to a featurizes represenation.\n",
    "# We use RBF kernels with different variances to cover different parts of the space\n",
    "featurizer = sklearn.pipeline.FeatureUnion([\n",
    "        (\"rbf1\", RBFSampler(gamma=5.0, n_components=100)),\n",
    "        (\"rbf2\", RBFSampler(gamma=2.0, n_components=100)),\n",
    "        (\"rbf3\", RBFSampler(gamma=1.0, n_components=100)),\n",
    "        (\"rbf4\", RBFSampler(gamma=0.5, n_components=100))\n",
    "        ])\n",
    "featurizer.fit(scaler.transform(observation_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "def featurize_state(state):\n",
    "    \"\"\"\n",
    "    Returns the featurized representation for a state.\n",
    "    \"\"\"\n",
    "    scaled = scaler.transform([state])\n",
    "    featurized = featurizer.transform(scaled)\n",
    "    return featurized[0]\n",
    "\n",
    "a = featurize_state([-2.61929672e+00, -1.58608459e+38, 3.32638098e-01, 4.39829973e+37])\n",
    "print (len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PolicyEstimator():\n",
    "    \"\"\"\n",
    "    Policy Function approximator. \n",
    "    Input is the env.state\n",
    "    ->we have two neural nets here: mu and sigma\n",
    "    ->combine them both to get a normal distro (mean, standard deviation)\n",
    "    ->pick an action from that normal distro\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.01, scope=\"policy_estimator\"):\n",
    "        with tf.variable_scope(scope):\n",
    "            self.state = tf.placeholder(tf.float32, [400], \"state\")\n",
    "            self.action = tf.placeholder(dtype=tf.float32, name=\"action\")\n",
    "            self.target = tf.placeholder(dtype=tf.float32, name=\"target\")\n",
    "\n",
    "            # This is just linear classifier\n",
    "            self.mu = tf.contrib.layers.fully_connected(\n",
    "                inputs=tf.expand_dims(self.state, 0),   #a vector with 10 elements could be treat as a 10x1 matrix\n",
    "                num_outputs=1,\n",
    "                activation_fn=None,\n",
    "                weights_initializer=tf.zeros_initializer)\n",
    "            self.mu = tf.squeeze(self.mu)\n",
    "            \n",
    "            self.sigma = tf.contrib.layers.fully_connected(\n",
    "                inputs=tf.expand_dims(self.state, 0),\n",
    "                num_outputs=1,\n",
    "                activation_fn=None,\n",
    "                weights_initializer=tf.zeros_initializer)\n",
    "            \n",
    "            self.sigma = tf.squeeze(self.sigma)\n",
    "            self.sigma = tf.nn.softplus(self.sigma) + 1e-5\n",
    "            self.normal_dist = tf.contrib.distributions.Normal(self.mu, self.sigma)\n",
    "            self.action = self.normal_dist.sample_n(1)\n",
    "            # self.action = tf.clip_by_value(self.action, env.action_space.low[0], env.action_space.high[0]) #a scalar value\n",
    "\n",
    "            # Loss and train op\n",
    "            self.loss = -self.normal_dist.log_prob(self.action) * self.target\n",
    "            #according to docs, the log_prob function is the (log(probability density/mass function))\n",
    "            #loss = log(pmf(self.action))*td_error*-1 (if td_error is positive, we love the action, hence loss is negative)\n",
    "            \n",
    "            # Add cross entropy cost to encourage exploration\n",
    "            self.loss -= 1e-1 * self.normal_dist.entropy()\n",
    "            \n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            self.train_op = self.optimizer.minimize(\n",
    "                self.loss, global_step=tf.contrib.framework.get_global_step())\n",
    "    \n",
    "    def predict(self, state, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        state = featurize_state(state)\n",
    "        return sess.run(self.action, { self.state: state })\n",
    "\n",
    "    #env.state, td_error, env.action\n",
    "    def update(self, state, target, action, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        state = featurize_state(state)\n",
    "        feed_dict = { self.state: state, self.target: target, self.action: action  }\n",
    "        _, loss = sess.run([self.train_op, self.loss], feed_dict)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ValueEstimator():\n",
    "    \"\"\"\n",
    "    Value Function approximator. \n",
    "    Here the neural net tries to map an  (env.curr_state) to a (value_function.value OR td_target)\n",
    "        where, td_target(curr_state) = reward + ValueEstimator.predict(next_state)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, learning_rate=0.1, scope=\"value_estimator\"):\n",
    "        with tf.variable_scope(scope):\n",
    "            self.state = tf.placeholder(tf.float32, [400], \"state\")\n",
    "            self.target = tf.placeholder(dtype=tf.float32, name=\"target\")\n",
    "\n",
    "            # This is just linear classifier\n",
    "            self.output_layer = tf.contrib.layers.fully_connected(\n",
    "                inputs=tf.expand_dims(self.state, 0),\n",
    "                num_outputs=1,\n",
    "                activation_fn=None,\n",
    "                weights_initializer=tf.zeros_initializer)\n",
    "\n",
    "            self.value_estimate = tf.squeeze(self.output_layer)\n",
    "            self.loss = tf.squared_difference(self.value_estimate, self.target)\n",
    "\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "            self.train_op = self.optimizer.minimize(\n",
    "                self.loss, global_step=tf.contrib.framework.get_global_step())        \n",
    "    \n",
    "    def predict(self, state, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        state = featurize_state(state)\n",
    "        return sess.run(self.value_estimate, { self.state: state })\n",
    "\n",
    "    def update(self, state, target, sess=None):\n",
    "        sess = sess or tf.get_default_session()\n",
    "        state = featurize_state(state)\n",
    "        feed_dict = { self.state: state, self.target: target }\n",
    "        _, loss = sess.run([self.train_op, self.loss], feed_dict)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read this to understand: https://webdocs.cs.ualberta.ca/~sutton/book/ebook/node66.html\n",
    "\n",
    "import time\n",
    "def actor_critic(env, estimator_policy, estimator_value, num_episodes, discount_factor=1.0):\n",
    "    \"\"\"\n",
    "    Q-Learning algorithm for fff-policy TD control using Function Approximation.\n",
    "    Finds the optimal greedy policy while following an epsilon-greedy policy.\n",
    "    \n",
    "    Args:\n",
    "        env: OpenAI environment.\n",
    "        estimator: Action-Value function estimator\n",
    "        num_episodes: Number of episodes to run for.\n",
    "        discount_factor: Lambda time discount factor.\n",
    "        epsilon: Chance the sample a random action. Float betwen 0 and 1.\n",
    "        epsilon_decay: Each episode, epsilon is decayed by this factor\n",
    "    \n",
    "    Returns:\n",
    "        An EpisodeStats object with two numpy arrays for episode_lengths and episode_rewards.\n",
    "    \"\"\"\n",
    "\n",
    "    # Keeps track of useful statistics\n",
    "    stats = plotting.EpisodeStats(\n",
    "        episode_lengths=np.zeros(num_episodes),\n",
    "        episode_rewards=np.zeros(num_episodes))    \n",
    "    \n",
    "    Transition = collections.namedtuple(\"Transition\", [\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "    \n",
    "    for i_episode in range(num_episodes):\n",
    "        print ('====================================================================Episode:',i_episode+1, ' started')\n",
    "        # Reset the environment and pick the fisrst action\n",
    "        state = env.reset()\n",
    "        \n",
    "        episode = []\n",
    "        \n",
    "        # One step in the environment\n",
    "        t1 = time.time()\n",
    "        for t in itertools.count():\n",
    "            \n",
    "            # env.render()\n",
    "            \n",
    "            # Take a step\n",
    "            action = estimator_policy.predict(state)\n",
    "            if action[0] < 0.5: action_env = 0\n",
    "            else           : action_env = 1\n",
    "            next_state, reward, done, _ = env.step(action_env)\n",
    "            # print ('----------Action:',action, ' type:', type(action), action[0], ' Action_env:', action_env)\n",
    "            \n",
    "            # Keep track of the transition\n",
    "            episode.append(Transition(\n",
    "              state=state, action=action, reward=reward, next_state=next_state, done=done))\n",
    "            \n",
    "            # Update statistics\n",
    "            stats.episode_rewards[i_episode] += reward\n",
    "            stats.episode_lengths[i_episode] = t\n",
    "            \n",
    "            # Calculate TD Target (#Ideal situation --> value_current = reward + value_next*gamma)\n",
    "            value_next = estimator_value.predict(next_state)\n",
    "            td_target = reward + discount_factor * value_next\n",
    "            td_error = td_target - estimator_value.predict(state) #if positive, we love the action???(why)\n",
    "            #1. if positive, it means that the predicted value is less than the actual value. \n",
    "            #1.1 That means the action led to an increase in value of the state-value function\n",
    "            \n",
    "            # Update the value estimator\n",
    "            estimator_value.update(state, td_target)\n",
    "            \n",
    "            # Update the policy estimator\n",
    "            # using the td error as our advantage estimate\n",
    "            estimator_policy.update(state, td_error, action)\n",
    "            \n",
    "            # Print out which step we're on, useful for debugging.\n",
    "#             if t%10 == 0:\n",
    "#                 print(\"\\rStep {} @ Episode {}/{} ({})\".format(\n",
    "#                         t, i_episode + 1, num_episodes, stats.episode_rewards[i_episode - 1]), end=\"\")\n",
    "#                 print ('\\nStep:',t,'\\tState:',state,'\\tAction:',action,'\\tReward:',reward)\n",
    "#                 print ('TD Error:',td_error, '\\t(',round(time.time() - t1),'s)')\n",
    "\n",
    "            if done:\n",
    "                print(\"\\rStep {} @ Episode {}/{} ({})\".format(\n",
    "                        t, i_episode + 1, num_episodes, stats.episode_rewards[i_episode - 1]), end=\"\")\n",
    "                print ('\\nStep:',t,'\\tState:',state,'\\tAction:',action,'\\tReward:',reward)\n",
    "                print ('TD Error:',td_error, '\\t(',round(time.time() - t1),'s)')\n",
    "                break\n",
    "                \n",
    "            state = next_state\n",
    "    print ('-------------------------------------------------------------------------->DONE!')\n",
    "    for i_episode in range(num_episodes):\n",
    "        print ('i:',i_episode, '\\tReward:',stats.episode_rewards[i_episode], '\\tLength:',stats.episode_lengths[i_episode])\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session Oject: <tensorflow.python.client.session.Session object at 0x00000192C63E7DD8>\n",
      "====================================================================Episode: 1  started\n",
      "Step 15 @ Episode 1/1000 (0.0)\n",
      "Step: 15 \tState: [-0.12181736 -1.74614761  0.19684965  2.66520865] \tAction: [ 0.24850786] \tReward: 1.0\n",
      "TD Error: 1.09011216164 \t( 0 s)\n",
      "====================================================================Episode: 2  started\n",
      "Step 21 @ Episode 2/1000 (16.0)\n",
      "Step: 21 \tState: [-0.20543072 -1.02377538  0.20125462  1.5078886 ] \tAction: [-1.08696127] \tReward: 1.0\n",
      "TD Error: 2.70263974667 \t( 0 s)\n",
      "====================================================================Episode: 3  started\n",
      "Step 33 @ Episode 3/1000 (22.0)\n",
      "Step: 33 \tState: [-0.12465914 -1.41104671  0.18568529  2.06559979] \tAction: [-1.71873999] \tReward: 1.0\n",
      "TD Error: -3.31743659973 \t( 0 s)\n",
      "====================================================================Episode: 4  started\n",
      "Step 16 @ Episode 4/1000 (34.0)\n",
      "Step: 16 \tState: [-0.04976156 -0.45856198  0.20549723  1.08510692] \tAction: [ 0.13260327] \tReward: 1.0\n",
      "TD Error: -1.49425878525 \t( 0 s)\n",
      "====================================================================Episode: 5  started\n",
      "Step 17 @ Episode 5/1000 (17.0)\n",
      "Step: 17 \tState: [-0.08286714 -1.37923838  0.19283091  2.19771879] \tAction: [-0.36642027] \tReward: 1.0\n",
      "TD Error: -1.17351169586 \t( 0 s)\n",
      "====================================================================Episode: 6  started\n",
      "Step 23 @ Episode 6/1000 (18.0)\n",
      "Step: 23 \tState: [-0.19691875 -1.74281031  0.2042581   2.40728   ] \tAction: [-0.95865291] \tReward: 1.0\n",
      "TD Error: 1.90766220093 \t( 0 s)\n",
      "====================================================================Episode: 7  started\n",
      "Step 15 @ Episode 7/1000 (24.0)\n",
      "Step: 15 \tState: [-0.04922754 -0.55787156  0.18503583  1.22714344] \tAction: [-0.82838315] \tReward: 1.0\n",
      "TD Error: 0.0605520963669 \t( 0 s)\n",
      "====================================================================Episode: 8  started\n",
      "Step 11 @ Episode 8/1000 (16.0)\n",
      "Step: 11 \tState: [-0.18990827 -1.78191155  0.19221105  2.69953105] \tAction: [ 0.60521692] \tReward: 1.0\n",
      "TD Error: -4.62401919365 \t( 0 s)\n",
      "====================================================================Episode: 9  started\n",
      "Step 12 @ Episode 9/1000 (12.0)\n",
      "Step: 12 \tState: [-0.20417351 -1.55636848  0.18609836  2.37570251] \tAction: [ 0.23496157] \tReward: 1.0\n",
      "TD Error: -3.28647298813 \t( 0 s)\n",
      "====================================================================Episode: 10  started\n",
      "Step 14 @ Episode 10/1000 (13.0)\n",
      "Step: 14 \tState: [-0.19076473 -0.43833803  0.20749535  0.87545967] \tAction: [-0.49686891] \tReward: 1.0\n",
      "TD Error: 2.57999134064 \t( 0 s)\n",
      "====================================================================Episode: 11  started\n",
      "Step 25 @ Episode 11/1000 (15.0)\n",
      "Step: 25 \tState: [-0.1765766  -1.4147562   0.1751206   2.07521559] \tAction: [-1.23205042] \tReward: 1.0\n",
      "TD Error: 2.56835331917 \t( 0 s)\n",
      "====================================================================Episode: 12  started\n",
      "Step 15 @ Episode 12/1000 (26.0)\n",
      "Step: 15 \tState: [-0.17005149 -1.33975648  0.17157354  2.13054508] \tAction: [ 0.8220883] \tReward: 1.0\n",
      "TD Error: 4.10159697533 \t( 0 s)\n",
      "====================================================================Episode: 13  started\n",
      "Step 10 @ Episode 13/1000 (16.0)\n",
      "Step: 10 \tState: [-0.07075028 -1.14899055  0.17980873  1.95676962] \tAction: [ 2.32413769] \tReward: 1.0\n",
      "TD Error: -2.08350009918 \t( 0 s)\n",
      "====================================================================Episode: 14  started\n",
      "Step 12 @ Episode 14/1000 (11.0)\n",
      "Step: 12 \tState: [-0.04268983 -0.74531425  0.1988445   1.43665933] \tAction: [-0.30133918] \tReward: 1.0\n",
      "TD Error: -5.80293359756 \t( 0 s)\n",
      "====================================================================Episode: 15  started\n",
      "Step 15 @ Episode 15/1000 (13.0)\n",
      "Step: 15 \tState: [-0.21760432 -1.00414765  0.19101947  1.47603668] \tAction: [-2.9706223] \tReward: 1.0\n",
      "TD Error: -4.29374809265 \t( 0 s)\n",
      "====================================================================Episode: 16  started\n",
      "Step 10 @ Episode 16/1000 (16.0)\n",
      "Step: 10 \tState: [-0.11736773 -1.20114919  0.1845377   1.9798972 ] \tAction: [-1.16597486] \tReward: 1.0\n",
      "TD Error: -0.903467273712 \t( 0 s)\n",
      "====================================================================Episode: 17  started\n",
      "Step 10 @ Episode 17/1000 (11.0)\n",
      "Step: 10 \tState: [-0.14464603 -1.21825297  0.17529188  1.91455969] \tAction: [ 0.68492001] \tReward: 1.0\n",
      "TD Error: 4.59479465485 \t( 0 s)\n",
      "====================================================================Episode: 18  started\n",
      "Step 17 @ Episode 18/1000 (11.0)\n",
      "Step: 17 \tState: [-0.06919382 -1.34450639  0.17700231  2.2030705 ] \tAction: [ 0.87957102] \tReward: 1.0\n",
      "TD Error: 7.32295761108 \t( 0 s)\n",
      "====================================================================Episode: 19  started\n",
      "Step 16 @ Episode 19/1000 (18.0)\n",
      "Step: 16 \tState: [ 0.06249751  1.17206221 -0.20590817 -2.16134438] \tAction: [ 1.2856667] \tReward: 1.0\n",
      "TD Error: -2.33883428574 \t( 0 s)\n",
      "====================================================================Episode: 20  started\n",
      "Step 10 @ Episode 20/1000 (17.0)\n",
      "Step: 10 \tState: [-0.15050542 -1.20282464  0.19598463  1.91698712] \tAction: [ 0.42297062] \tReward: 1.0\n",
      "TD Error: 7.06118621826 \t( 0 s)\n",
      "====================================================================Episode: 21  started\n",
      "Step 19 @ Episode 21/1000 (11.0)\n",
      "Step: 19 \tState: [-0.18565633 -1.72432656  0.17912368  2.56301722] \tAction: [ 1.49208903] \tReward: 1.0\n",
      "TD Error: 6.29611773491 \t( 0 s)\n",
      "====================================================================Episode: 22  started\n",
      "Step 14 @ Episode 22/1000 (20.0)\n",
      "Step: 14 \tState: [-0.13106557 -0.77003473  0.18661411  1.373964  ] \tAction: [ 0.85817122] \tReward: 1.0\n",
      "TD Error: 0.467630195618 \t( 0 s)\n",
      "====================================================================Episode: 23  started\n",
      "Step 11 @ Episode 23/1000 (15.0)\n",
      "Step: 11 \tState: [-0.11810175 -1.33653891  0.20545326  2.25946122] \tAction: [-0.0488461] \tReward: 1.0\n",
      "TD Error: -9.21378135681 \t( 0 s)\n",
      "====================================================================Episode: 24  started\n",
      "Step 19 @ Episode 24/1000 (12.0)\n",
      "Step: 19 \tState: [-0.14398009 -0.6418866   0.20105228  1.22531157] \tAction: [-1.96872282] \tReward: 1.0\n",
      "TD Error: -8.11900920868 \t( 0 s)\n",
      "====================================================================Episode: 25  started\n",
      "Step 11 @ Episode 25/1000 (20.0)\n",
      "Step: 11 \tState: [-0.10383022 -0.60221707  0.19871439  1.0938901 ] \tAction: [ 0.54266316] \tReward: 1.0\n",
      "TD Error: -5.9135931015 \t( 0 s)\n",
      "====================================================================Episode: 26  started\n",
      "Step 21 @ Episode 26/1000 (12.0)\n",
      "Step: 21 \tState: [-0.14292276 -1.72400054  0.18299231  2.50670937] \tAction: [-1.50481379] \tReward: 1.0\n",
      "TD Error: -5.92099475861 \t( 0 s)\n",
      "====================================================================Episode: 27  started\n",
      "Step 15 @ Episode 27/1000 (22.0)\n",
      "Step: 15 \tState: [-0.15504139 -0.95659721  0.18733851  1.68940654] \tAction: [ 1.32024467] \tReward: 1.0\n",
      "TD Error: 1.41375484467 \t( 0 s)\n",
      "====================================================================Episode: 28  started\n",
      "Step 11 @ Episode 28/1000 (16.0)\n",
      "Step: 11 \tState: [-0.11407354 -1.32640973  0.17821227  2.24206853] \tAction: [ 2.20009971] \tReward: 1.0\n",
      "TD Error: 2.09089355469 \t( 0 s)\n",
      "====================================================================Episode: 29  started\n",
      "Step 14 @ Episode 29/1000 (12.0)\n",
      "Step: 14 \tState: [-0.18816863 -1.55210536  0.20708297  2.37163599] \tAction: [-0.26822847] \tReward: 1.0\n",
      "TD Error: 10.9204124451 \t( 0 s)\n",
      "====================================================================Episode: 30  started\n",
      "Step 9 @ Episode 30/1000 (15.0)\n",
      "Step: 9 \tState: [-0.07748964 -0.97808168  0.18177421  1.70124496] \tAction: [-0.96610695] \tReward: 1.0\n",
      "TD Error: 4.33752098083 \t( 0 s)\n",
      "====================================================================Episode: 31  started\n",
      "Step 16 @ Episode 31/1000 (10.0)\n",
      "Step: 16 \tState: [-0.15416468 -1.5450738   0.19318969  2.34186548] \tAction: [ 0.18167651] \tReward: 1.0\n",
      "TD Error: 4.13397102356 \t( 0 s)\n",
      "====================================================================Episode: 32  started\n",
      "Step 10 @ Episode 32/1000 (17.0)\n",
      "Step: 10 \tState: [-0.17303802 -1.16369797  0.20548165  1.86321554] \tAction: [ 0.80163491] \tReward: 1.0\n",
      "TD Error: 2.5805662632 \t( 0 s)\n",
      "====================================================================Episode: 33  started\n",
      "Step 10 @ Episode 33/1000 (11.0)\n",
      "Step: 10 \tState: [-0.08615537 -1.14768795  0.17433753  2.02571459] \tAction: [ 0.04480121] \tReward: 1.0\n",
      "TD Error: -2.68155286312 \t( 0 s)\n",
      "====================================================================Episode: 34  started\n",
      "Step 12 @ Episode 34/1000 (11.0)\n",
      "Step: 12 \tState: [-0.19734147 -1.59919377  0.16508939  2.33525744] \tAction: [ 2.19087672] \tReward: 1.0\n",
      "TD Error: -5.15204366446 \t( 0 s)\n",
      "====================================================================Episode: 35  started\n",
      "Step 17 @ Episode 35/1000 (13.0)\n",
      "Step: 17 \tState: [-0.09311114 -0.63074911  0.19710089  1.32459685] \tAction: [-0.71767002] \tReward: 1.0\n",
      "TD Error: -1.66368119717 \t( 0 s)\n",
      "====================================================================Episode: 36  started\n",
      "Step 13 @ Episode 36/1000 (18.0)\n",
      "Step: 13 \tState: [-0.19795231 -1.33650696  0.19619996  2.15994902] \tAction: [-0.28284797] \tReward: 1.0\n",
      "TD Error: 0.00645289421082 \t( 0 s)\n",
      "====================================================================Episode: 37  started\n",
      "Step 10 @ Episode 37/1000 (14.0)\n",
      "Step: 10 \tState: [-0.15399495 -1.56810257  0.17597413  2.46581071] \tAction: [ 1.95729625] \tReward: 1.0\n",
      "TD Error: 0.0264275550842 \t( 0 s)\n",
      "====================================================================Episode: 38  started\n",
      "Step 14 @ Episode 38/1000 (11.0)\n",
      "Step: 14 \tState: [-0.11514298 -1.16260922  0.19145521  2.08008669] \tAction: [-1.16947496] \tReward: 1.0\n",
      "TD Error: 1.95038900375 \t( 0 s)\n",
      "====================================================================Episode: 39  started\n",
      "Step 10 @ Episode 39/1000 (15.0)\n",
      "Step: 10 \tState: [-0.15345918 -1.15698749  0.17860663  1.81948647] \tAction: [-1.35211146] \tReward: 1.0\n",
      "TD Error: 1.58473739624 \t( 0 s)\n",
      "====================================================================Episode: 40  started\n",
      "Step 11 @ Episode 40/1000 (11.0)\n",
      "Step: 11 \tState: [-0.10446324 -1.37402052  0.20345602  2.17744902] \tAction: [-0.14572181] \tReward: 1.0\n",
      "TD Error: 6.56352500916 \t( 0 s)\n",
      "====================================================================Episode: 41  started\n",
      "Step 11 @ Episode 41/1000 (12.0)\n",
      "Step: 11 \tState: [-0.16136293 -1.39868082  0.19862502  2.29757412] \tAction: [ 0.76241958] \tReward: 1.0\n",
      "TD Error: 4.76055049896 \t( 0 s)\n",
      "====================================================================Episode: 42  started\n",
      "Step 9 @ Episode 42/1000 (12.0)\n",
      "Step: 9 \tState: [-0.11265631 -1.78036176  0.19149451  2.68991527] \tAction: [-0.40810314] \tReward: 1.0\n",
      "TD Error: 1.44777083397 \t( 0 s)\n",
      "====================================================================Episode: 43  started\n",
      "Step 16 @ Episode 43/1000 (10.0)\n",
      "Step: 16 \tState: [-0.13918036 -1.13922812  0.20007008  1.82709928] \tAction: [-0.79517508] \tReward: 1.0\n",
      "TD Error: -0.577949285507 \t( 0 s)\n",
      "====================================================================Episode: 44  started\n",
      "Step 9 @ Episode 44/1000 (17.0)\n",
      "Step: 9 \tState: [-0.16551189 -1.40823814  0.19676479  2.14301411] \tAction: [ 0.92147368] \tReward: 1.0\n",
      "TD Error: -0.473811668158 \t( 0 s)\n",
      "====================================================================Episode: 45  started\n",
      "Step 10 @ Episode 45/1000 (10.0)\n",
      "Step: 10 \tState: [-0.16595929 -1.13166638  0.19571094  1.80504897] \tAction: [ 0.21932925] \tReward: 1.0\n",
      "TD Error: 0.690839779377 \t( 0 s)\n",
      "====================================================================Episode: 46  started\n",
      "Step 15 @ Episode 46/1000 (11.0)\n",
      "Step: 15 \tState: [-0.18892145 -0.99627717  0.19668927  1.63080658] \tAction: [-0.06513699] \tReward: 1.0\n",
      "TD Error: 1.64042892456 \t( 0 s)\n",
      "====================================================================Episode: 47  started\n",
      "Step 20 @ Episode 47/1000 (16.0)\n",
      "Step: 20 \tState: [-0.07478923 -0.4213023   0.19491847  0.889114  ] \tAction: [-0.15051025] \tReward: 1.0\n",
      "TD Error: 0.254365223646 \t( 0 s)\n",
      "====================================================================Episode: 48  started\n",
      "Step 15 @ Episode 48/1000 (21.0)\n",
      "Step: 15 \tState: [-0.08946355 -0.16565153  0.19604246  0.69840991] \tAction: [-1.03514218] \tReward: 1.0\n",
      "TD Error: 0.370183379948 \t( 0 s)\n",
      "====================================================================Episode: 49  started\n",
      "Step 14 @ Episode 49/1000 (16.0)\n",
      "Step: 14 \tState: [-0.11806045 -1.56134116  0.17504864  2.43146807] \tAction: [-0.12833531] \tReward: 1.0\n",
      "TD Error: -0.720661377907 \t( 0 s)\n",
      "====================================================================Episode: 50  started\n",
      "Step 14 @ Episode 50/1000 (15.0)\n",
      "Step: 14 \tState: [-0.14368243 -1.13666816  0.20398955  1.86344958] \tAction: [-0.22527909] \tReward: 1.0\n",
      "TD Error: 3.22062902451 \t( 0 s)\n",
      "====================================================================Episode: 51  started\n",
      "Step 12 @ Episode 51/1000 (15.0)\n",
      "Step: 12 \tState: [-0.07195878 -1.17880384  0.20272065  1.98276974] \tAction: [-0.69299138] \tReward: 1.0\n",
      "TD Error: 2.57669814825 \t( 0 s)\n",
      "====================================================================Episode: 52  started\n",
      "Step 13 @ Episode 52/1000 (13.0)\n",
      "Step: 13 \tState: [-0.15096739 -1.40744384  0.19669632  2.28913589] \tAction: [ 0.26668081] \tReward: 1.0\n",
      "TD Error: 0.592632198334 \t( 0 s)\n",
      "====================================================================Episode: 53  started\n",
      "Step 9 @ Episode 53/1000 (14.0)\n",
      "Step: 9 \tState: [-0.14749023 -1.35799107  0.20501675  2.18693543] \tAction: [ 0.20353284] \tReward: 1.0\n",
      "TD Error: -0.374501180649 \t( 0 s)\n",
      "====================================================================Episode: 54  started\n",
      "Step 8 @ Episode 54/1000 (10.0)\n",
      "Step: 8 \tState: [-0.05489927 -1.18864769  0.18443529  1.92807208] \tAction: [ 0.32185176] \tReward: 1.0\n",
      "TD Error: -1.31878962517 \t( 0 s)\n",
      "====================================================================Episode: 55  started\n",
      "Step 17 @ Episode 55/1000 (9.0)\n",
      "Step: 17 \tState: [-0.08519697 -1.40406336  0.18581464  2.19017003] \tAction: [-2.09921265] \tReward: 1.0\n",
      "TD Error: -0.191593813896 \t( 0 s)\n",
      "====================================================================Episode: 56  started\n",
      "Step 14 @ Episode 56/1000 (18.0)\n",
      "Step: 14 \tState: [-0.16544504 -0.79500726  0.18706898  1.37261133] \tAction: [-0.15934539] \tReward: 1.0\n",
      "TD Error: 1.60237366408 \t( 0 s)\n",
      "====================================================================Episode: 57  started\n",
      "Step 24 @ Episode 57/1000 (15.0)\n",
      "Step: 24 \tState: [-0.16523758 -1.55200902  0.19527393  2.42495415] \tAction: [ 0.09750049] \tReward: 1.0\n",
      "TD Error: 0.988036060333 \t( 0 s)\n",
      "====================================================================Episode: 58  started\n",
      "Step 18 @ Episode 58/1000 (25.0)\n",
      "Step: 18 \tState: [-0.16434594 -1.96985075  0.2075881   2.90274598] \tAction: [ 0.4167816] \tReward: 1.0\n",
      "TD Error: 1.8923842907 \t( 0 s)\n",
      "====================================================================Episode: 59  started\n",
      "Step 9 @ Episode 59/1000 (19.0)\n",
      "Step: 9 \tState: [-0.15421152 -1.01862344  0.20011848  1.61682488] \tAction: [ 0.91128421] \tReward: 1.0\n",
      "TD Error: 0.786921930313 \t( 0 s)\n",
      "====================================================================Episode: 60  started\n",
      "Step 9 @ Episode 60/1000 (10.0)\n",
      "Step: 9 \tState: [-0.07975198 -0.99314025  0.19158931  1.69362138] \tAction: [ 0.0930214] \tReward: 1.0\n",
      "TD Error: -1.09071245193 \t( 0 s)\n",
      "====================================================================Episode: 61  started\n",
      "Step 10 @ Episode 61/1000 (10.0)\n",
      "Step: 10 \tState: [-0.08563336 -1.21741245  0.19831979  1.95422953] \tAction: [ 1.72928846] \tReward: 1.0\n",
      "TD Error: -2.20436649323 \t( 0 s)\n",
      "====================================================================Episode: 62  started\n",
      "Step 14 @ Episode 62/1000 (11.0)\n",
      "Step: 14 \tState: [-0.13185787 -1.16441118  0.17193456  1.88663594] \tAction: [-0.66259235] \tReward: 1.0\n",
      "TD Error: -2.19603414536 \t( 0 s)\n",
      "====================================================================Episode: 63  started\n",
      "Step 14 @ Episode 63/1000 (15.0)\n",
      "Step: 14 \tState: [-0.16339945 -1.61338588  0.17823977  2.4622635 ] \tAction: [ 0.05531593] \tReward: 1.0\n",
      "TD Error: 0.213396883011 \t( 0 s)\n",
      "====================================================================Episode: 64  started\n",
      "Step 10 @ Episode 64/1000 (15.0)\n",
      "Step: 10 \tState: [-0.11240022 -1.13402449  0.1786855   1.85420363] \tAction: [-0.52296644] \tReward: 1.0\n",
      "TD Error: 1.94054579735 \t( 0 s)\n",
      "====================================================================Episode: 65  started\n",
      "Step 11 @ Episode 65/1000 (11.0)\n",
      "Step: 11 \tState: [-0.1617104  -1.75222258  0.17138058  2.68076936] \tAction: [ 2.07570219] \tReward: 1.0\n",
      "TD Error: 3.81482166052 \t( 0 s)\n",
      "====================================================================Episode: 66  started\n",
      "Step 13 @ Episode 66/1000 (12.0)\n",
      "Step: 13 \tState: [-0.05448808 -0.60049896  0.18404275  1.28336001] \tAction: [ 1.24496377] \tReward: 1.0\n",
      "TD Error: -0.436377000809 \t( 0 s)\n",
      "====================================================================Episode: 67  started\n",
      "Step 9 @ Episode 67/1000 (14.0)\n",
      "Step: 9 \tState: [-0.11152178 -1.3330757   0.19694721  2.30060931] \tAction: [-1.38358378] \tReward: 1.0\n",
      "TD Error: -1.9913995266 \t( 0 s)\n",
      "====================================================================Episode: 68  started\n",
      "Step 20 @ Episode 68/1000 (10.0)\n",
      "Step: 20 \tState: [-0.06829925 -1.18456566  0.19533752  2.12967265] \tAction: [ 1.11757922] \tReward: 1.0\n",
      "TD Error: -1.1008907795 \t( 0 s)\n",
      "====================================================================Episode: 69  started\n",
      "Step 16 @ Episode 69/1000 (21.0)\n",
      "Step: 16 \tState: [-0.09266919 -1.15472275  0.17267726  1.99699363] \tAction: [ 0.5053398] \tReward: 1.0\n",
      "TD Error: 0.323196840286 \t( 0 s)\n",
      "====================================================================Episode: 70  started\n",
      "Step 9 @ Episode 70/1000 (17.0)\n",
      "Step: 9 \tState: [-0.12816314 -0.95261605  0.20478237  1.64957407] \tAction: [ 1.35408854] \tReward: 1.0\n",
      "TD Error: 4.73689680099 \t( 0 s)\n",
      "====================================================================Episode: 71  started\n",
      "Step 22 @ Episode 71/1000 (10.0)\n",
      "Step: 22 \tState: [-0.12482759 -1.5397116   0.19939892  2.46192584] \tAction: [-0.68849438] \tReward: 1.0\n",
      "TD Error: 7.02755308151 \t( 0 s)\n",
      "====================================================================Episode: 72  started\n",
      "Step 11 @ Episode 72/1000 (23.0)\n",
      "Step: 11 \tState: [-0.12097109 -1.73964619  0.19143194  2.73075238] \tAction: [-0.46551299] \tReward: 1.0\n",
      "TD Error: 4.72646551132 \t( 0 s)\n",
      "====================================================================Episode: 73  started\n",
      "Step 10 @ Episode 73/1000 (12.0)\n",
      "Step: 10 \tState: [-0.11806969 -0.77842872  0.18780264  1.38104462] \tAction: [-1.55513811] \tReward: 1.0\n",
      "TD Error: -1.1641784668 \t( 0 s)\n",
      "====================================================================Episode: 74  started\n",
      "Step 22 @ Episode 74/1000 (11.0)\n",
      "Step: 22 \tState: [-0.1725191  -0.75915271  0.18648335  1.30136167] \tAction: [ 0.0922979] \tReward: 1.0\n",
      "TD Error: -5.19322528839 \t( 0 s)\n",
      "====================================================================Episode: 75  started\n",
      "Step 18 @ Episode 75/1000 (23.0)\n",
      "Step: 18 \tState: [-0.13556004 -1.53620592  0.18396265  2.40404697] \tAction: [ 0.33064348] \tReward: 1.0\n",
      "TD Error: -7.50308704376 \t( 0 s)\n",
      "====================================================================Episode: 76  started\n",
      "Step 12 @ Episode 76/1000 (19.0)\n",
      "Step: 12 \tState: [-0.15184305 -1.52232424  0.20810571  2.54265722] \tAction: [ 0.35851443] \tReward: 1.0\n",
      "TD Error: -2.70902090073 \t( 0 s)\n",
      "====================================================================Episode: 77  started\n",
      "Step 17 @ Episode 77/1000 (13.0)\n",
      "Step: 17 \tState: [-0.12439864 -1.80047167  0.19461926  2.63230824] \tAction: [ 0.8624633] \tReward: 1.0\n",
      "TD Error: 5.5783759594 \t( 0 s)\n",
      "====================================================================Episode: 78  started\n",
      "Step 14 @ Episode 78/1000 (18.0)\n",
      "Step: 14 \tState: [-0.13567312 -1.16103827  0.19820221  1.98832178] \tAction: [ 1.3164283] \tReward: 1.0\n",
      "TD Error: 6.28440184593 \t( 0 s)\n",
      "====================================================================Episode: 79  started\n",
      "Step 12 @ Episode 79/1000 (15.0)\n",
      "Step: 12 \tState: [-0.09219245 -0.74778004  0.18976051  1.39765053] \tAction: [ 0.36268207] \tReward: 1.0\n",
      "TD Error: 4.15325467587 \t( 0 s)\n",
      "====================================================================Episode: 80  started\n",
      "Step 16 @ Episode 80/1000 (13.0)\n",
      "Step: 16 \tState: [-0.19119851 -1.51594988  0.20881232  2.34925608] \tAction: [-0.54557943] \tReward: 1.0\n",
      "TD Error: 2.23278913498 \t( 0 s)\n",
      "====================================================================Episode: 81  started\n",
      "Step 11 @ Episode 81/1000 (17.0)\n",
      "Step: 11 \tState: [-0.11998803 -0.62639853  0.19866563  1.23811592] \tAction: [ 0.5791657] \tReward: 1.0\n",
      "TD Error: -0.938159751892 \t( 0 s)\n",
      "====================================================================Episode: 82  started\n",
      "Step 32 @ Episode 82/1000 (12.0)\n",
      "Step: 32 \tState: [-0.14269584 -1.90950883  0.1874789   2.5834337 ] \tAction: [-0.73235434] \tReward: 1.0\n",
      "TD Error: -2.30752258301 \t( 1 s)\n",
      "====================================================================Episode: 83  started\n",
      "Step 14 @ Episode 83/1000 (33.0)\n",
      "Step: 14 \tState: [-0.0961151  -0.81683549  0.18544499  1.43235019] \tAction: [-1.39883542] \tReward: 1.0\n",
      "TD Error: -2.82869853973 \t( 0 s)\n",
      "====================================================================Episode: 84  started\n",
      "Step 16 @ Episode 84/1000 (15.0)\n",
      "Step: 16 \tState: [-0.10272156 -0.40376316  0.20031925  0.96326721] \tAction: [ 1.18866444] \tReward: 1.0\n",
      "TD Error: -0.486059570313 \t( 0 s)\n",
      "====================================================================Episode: 85  started\n",
      "Step 20 @ Episode 85/1000 (17.0)\n",
      "Step: 20 \tState: [ 0.13523213  0.02961651 -0.20919415 -0.40152823] \tAction: [ 0.3431401] \tReward: 1.0\n",
      "TD Error: 0.365793466568 \t( 0 s)\n",
      "====================================================================Episode: 86  started\n",
      "Step 18 @ Episode 86/1000 (21.0)\n",
      "Step: 18 \tState: [-0.145661   -0.80326426  0.19734932  1.22002368] \tAction: [ 1.02390134] \tReward: 1.0\n",
      "TD Error: 0.148620223999 \t( 0 s)\n",
      "====================================================================Episode: 87  started\n",
      "Step 33 @ Episode 87/1000 (19.0)\n",
      "Step: 33 \tState: [-0.29445519 -1.7661763   0.2055297   2.12629478] \tAction: [-1.05368781] \tReward: 1.0\n",
      "TD Error: -1.30951395035 \t( 0 s)\n",
      "====================================================================Episode: 88  started\n",
      "Step 14 @ Episode 88/1000 (34.0)\n",
      "Step: 14 \tState: [-0.17476191 -1.9280117   0.15775851  2.78981533] \tAction: [ 1.84124339] \tReward: 1.0\n",
      "TD Error: 0.807400417328 \t( 0 s)\n",
      "====================================================================Episode: 89  started\n",
      "Step 23 @ Episode 89/1000 (15.0)\n",
      "Step: 23 \tState: [-0.21660311 -2.10943697  0.19442536  2.83040864] \tAction: [ 1.45935607] \tReward: 1.0\n",
      "TD Error: 4.1793879509 \t( 0 s)\n",
      "====================================================================Episode: 90  started\n",
      "Step 15 @ Episode 90/1000 (24.0)\n",
      "Step: 15 \tState: [-0.16467514 -0.95051965  0.19831809  1.51390723] \tAction: [-0.94516677] \tReward: 1.0\n",
      "TD Error: -0.975108528137 \t( 0 s)\n",
      "====================================================================Episode: 91  started\n",
      "Step 21 @ Episode 91/1000 (16.0)\n",
      "Step: 21 \tState: [-0.17242059 -1.02191179  0.20145992  1.84569682] \tAction: [-1.09787607] \tReward: 1.0\n",
      "TD Error: -1.5457988739 \t( 0 s)\n",
      "====================================================================Episode: 92  started\n",
      "Step 25 @ Episode 92/1000 (22.0)\n",
      "Step: 25 \tState: [ 0.16012803  0.19515103 -0.19894835 -0.59872268] \tAction: [-0.89011496] \tReward: 1.0\n",
      "TD Error: -0.0402810573578 \t( 0 s)\n",
      "====================================================================Episode: 93  started\n",
      "Step 21 @ Episode 93/1000 (26.0)\n",
      "Step: 21 \tState: [-0.11382148 -0.63100742  0.20529505  1.15493218] \tAction: [-1.0226382] \tReward: 1.0\n",
      "TD Error: 0.221074390411 \t( 0 s)\n",
      "====================================================================Episode: 94  started\n",
      "Step 15 @ Episode 94/1000 (22.0)\n",
      "Step: 15 \tState: [-0.10264952 -1.36780016  0.2086129   2.29157744] \tAction: [ 0.68196672] \tReward: 1.0\n",
      "TD Error: -1.33783111572 \t( 0 s)\n",
      "====================================================================Episode: 95  started\n",
      "Step 21 @ Episode 95/1000 (16.0)\n",
      "Step: 21 \tState: [-0.19695925 -0.58310959  0.20930344  1.24258955] \tAction: [ 2.56672645] \tReward: 1.0\n",
      "TD Error: 0.858416366577 \t( 0 s)\n",
      "====================================================================Episode: 96  started\n",
      "Step 21 @ Episode 96/1000 (22.0)\n",
      "Step: 21 \tState: [-0.06655218 -0.65326459  0.1975741   1.33660705] \tAction: [ 0.47126469] \tReward: 1.0\n",
      "TD Error: 2.53450274467 \t( 0 s)\n",
      "====================================================================Episode: 97  started\n",
      "Step 17 @ Episode 97/1000 (22.0)\n",
      "Step: 17 \tState: [-0.12229155 -1.01221989  0.20753744  1.88501233] \tAction: [-2.41902065] \tReward: 1.0\n",
      "TD Error: 1.73158216476 \t( 0 s)\n",
      "====================================================================Episode: 98  started\n",
      "Step 11 @ Episode 98/1000 (18.0)\n",
      "Step: 11 \tState: [-0.05244655 -0.96221683  0.19154795  1.74220485] \tAction: [-0.11937278] \tReward: 1.0\n",
      "TD Error: -0.549773788452 \t( 0 s)\n",
      "====================================================================Episode: 99  started\n",
      "Step 19 @ Episode 99/1000 (12.0)\n",
      "Step: 19 \tState: [-0.11678654 -0.93082506  0.18259917  1.54963805] \tAction: [ 0.64101404] \tReward: 1.0\n",
      "TD Error: -2.27349739075 \t( 0 s)\n",
      "====================================================================Episode: 100  started\n",
      "Step 9 @ Episode 100/1000 (20.0)\n",
      "Step: 9 \tState: [-0.12240823 -1.35820779  0.19749017  2.24256844] \tAction: [ 1.20384693] \tReward: 1.0\n",
      "TD Error: -5.64920253754 \t( 0 s)\n",
      "====================================================================Episode: 101  started\n",
      "Step 27 @ Episode 101/1000 (10.0)\n",
      "Step: 27 \tState: [-0.0615108  -1.74155892  0.18742311  2.70980502] \tAction: [ 1.74134183] \tReward: 1.0\n",
      "TD Error: 0.894464588165 \t( 0 s)\n",
      "====================================================================Episode: 102  started\n",
      "Step 11 @ Episode 102/1000 (28.0)\n",
      "Step: 11 \tState: [-0.19128305 -1.01218358  0.20931955  1.61185141] \tAction: [ 3.17594504] \tReward: 1.0\n",
      "TD Error: -0.813326454163 \t( 0 s)\n",
      "====================================================================Episode: 103  started\n",
      "Step 44 @ Episode 103/1000 (12.0)\n",
      "Step: 44 \tState: [-0.34774346 -1.54931799  0.19034941  1.62487313] \tAction: [-1.46408582] \tReward: 1.0\n",
      "TD Error: 2.20035715103 \t( 0 s)\n",
      "====================================================================Episode: 104  started\n",
      "Step 17 @ Episode 104/1000 (45.0)\n",
      "Step: 17 \tState: [-0.11105359 -0.63820767  0.18635527  1.17416942] \tAction: [-0.63853508] \tReward: 1.0\n",
      "TD Error: 1.48264064789 \t( 0 s)\n",
      "====================================================================Episode: 105  started\n",
      "Step 11 @ Episode 105/1000 (18.0)\n",
      "Step: 11 \tState: [-0.10165764 -0.59571273  0.18879844  1.20690633] \tAction: [-0.23860443] \tReward: 1.0\n",
      "TD Error: 0.492543029785 \t( 0 s)\n",
      "====================================================================Episode: 106  started\n",
      "Step 14 @ Episode 106/1000 (12.0)\n",
      "Step: 14 \tState: [-0.10511941 -1.18317599  0.18196185  1.95873751] \tAction: [-0.34505904] \tReward: 1.0\n",
      "TD Error: -0.528284454346 \t( 0 s)\n",
      "====================================================================Episode: 107  started\n",
      "Step 19 @ Episode 107/1000 (15.0)\n",
      "Step: 19 \tState: [-0.08956188 -0.93878991  0.20189888  1.63949099] \tAction: [-1.24224389] \tReward: 1.0\n",
      "TD Error: -3.08114356995 \t( 0 s)\n",
      "====================================================================Episode: 108  started\n",
      "Step 11 @ Episode 108/1000 (20.0)\n",
      "Step: 11 \tState: [-0.04149643 -0.94655766  0.20218589  1.70016561] \tAction: [-1.68906498] \tReward: 1.0\n",
      "TD Error: -1.43555021286 \t( 0 s)\n",
      "====================================================================Episode: 109  started\n",
      "Step 36 @ Episode 109/1000 (12.0)\n",
      "Step: 36 \tState: [-0.01111438 -0.03351779  0.19929925  0.88515275] \tAction: [ 1.10667169] \tReward: 1.0\n",
      "TD Error: 0.762378787994 \t( 0 s)\n",
      "====================================================================Episode: 110  started\n",
      "Step 18 @ Episode 110/1000 (37.0)\n",
      "Step: 18 \tState: [-0.08441946 -1.93426691  0.17804673  2.85261594] \tAction: [ 1.50719845] \tReward: 1.0\n",
      "TD Error: 0.809213733673 \t( 0 s)\n",
      "====================================================================Episode: 111  started\n",
      "Step 16 @ Episode 111/1000 (19.0)\n",
      "Step: 16 \tState: [-0.16327791 -1.16605549  0.18834129  1.8012809 ] \tAction: [ 1.92296183] \tReward: 1.0\n",
      "TD Error: 1.42018508911 \t( 0 s)\n",
      "====================================================================Episode: 112  started\n",
      "Step 25 @ Episode 112/1000 (17.0)\n",
      "Step: 25 \tState: [ 0.0211594  -0.21906097  0.20792699  1.1412002 ] \tAction: [ 1.5932399] \tReward: 1.0\n",
      "TD Error: 0.555161476135 \t( 0 s)\n",
      "====================================================================Episode: 113  started\n",
      "Step 15 @ Episode 113/1000 (26.0)\n",
      "Step: 15 \tState: [-0.09057837 -0.96164853  0.19259043  1.61776283] \tAction: [ 1.61767554] \tReward: 1.0\n",
      "TD Error: 1.4919002533 \t( 0 s)\n",
      "====================================================================Episode: 114  started\n",
      "Step 17 @ Episode 114/1000 (16.0)\n",
      "Step: 17 \tState: [-0.04435555 -1.33409927  0.17061817  2.0961764 ] \tAction: [-1.97081399] \tReward: 1.0\n",
      "TD Error: 1.72417392731 \t( 0 s)\n",
      "====================================================================Episode: 115  started\n",
      "Step 15 @ Episode 115/1000 (18.0)\n",
      "Step: 15 \tState: [-0.1151341  -0.6370193   0.19211454  1.20828888] \tAction: [-0.24613737] \tReward: 1.0\n",
      "TD Error: 0.625950813293 \t( 0 s)\n",
      "====================================================================Episode: 116  started\n",
      "Step 50 @ Episode 116/1000 (16.0)\n",
      "Step: 50 \tState: [-0.49232015 -1.52184288  0.20905833  1.61702912] \tAction: [-0.53676361] \tReward: 1.0\n",
      "TD Error: -0.593565368652 \t( 1 s)\n",
      "====================================================================Episode: 117  started\n",
      "Step 23 @ Episode 117/1000 (51.0)\n",
      "Step: 23 \tState: [-0.18015903 -1.3602729   0.2054504   2.10120581] \tAction: [ 0.65400547] \tReward: 1.0\n",
      "TD Error: -3.35293598175 \t( 0 s)\n",
      "====================================================================Episode: 118  started\n",
      "Step 10 @ Episode 118/1000 (24.0)\n",
      "Step: 10 \tState: [-0.12554616 -0.80750172  0.18473794  1.24995113] \tAction: [-1.84568596] \tReward: 1.0\n",
      "TD Error: -2.35654888153 \t( 0 s)\n",
      "====================================================================Episode: 119  started\n",
      "Step 23 @ Episode 119/1000 (11.0)\n",
      "Step: 23 \tState: [-0.18188834 -0.5829224   0.19289199  1.17008103] \tAction: [ 0.5270769] \tReward: 1.0\n",
      "TD Error: 2.62031378746 \t( 0 s)\n",
      "====================================================================Episode: 120  started\n",
      "Step 20 @ Episode 120/1000 (24.0)\n",
      "Step: 20 \tState: [-0.12094557 -1.19181928  0.19288733  1.89276233] \tAction: [ 1.45849562] \tReward: 1.0\n",
      "TD Error: 4.5674806118 \t( 0 s)\n",
      "====================================================================Episode: 121  started\n",
      "Step 10 @ Episode 121/1000 (21.0)\n",
      "Step: 10 \tState: [-0.06814658 -0.83425136  0.18523452  1.44405466] \tAction: [ 1.93840659] \tReward: 1.0\n",
      "TD Error: 1.80266933441 \t( 0 s)\n",
      "====================================================================Episode: 122  started\n",
      "Step 18 @ Episode 122/1000 (11.0)\n",
      "Step: 18 \tState: [-0.12297414 -1.52927499  0.19146733  2.43384972] \tAction: [ 0.83307093] \tReward: 1.0\n",
      "TD Error: -3.05688667297 \t( 0 s)\n",
      "====================================================================Episode: 123  started\n",
      "Step 9 @ Episode 123/1000 (19.0)\n",
      "Step: 9 \tState: [-0.11348796 -1.01224216  0.19986712  1.73507606] \tAction: [ 0.35780513] \tReward: 1.0\n",
      "TD Error: -3.49399833679 \t( 0 s)\n",
      "====================================================================Episode: 124  started\n",
      "Step 13 @ Episode 124/1000 (10.0)\n",
      "Step: 13 \tState: [ 0.08878218  1.02600432 -0.17877628 -1.72288769] \tAction: [-0.93946189] \tReward: 1.0\n",
      "TD Error: -4.1722423315 \t( 0 s)\n",
      "====================================================================Episode: 125  started\n",
      "Step 14 @ Episode 125/1000 (14.0)\n",
      "Step: 14 \tState: [-0.12115748 -1.18321229  0.2085483   2.06398816] \tAction: [-1.57010448] \tReward: 1.0\n",
      "TD Error: -1.59257984161 \t( 0 s)\n",
      "====================================================================Episode: 126  started\n",
      "Step 21 @ Episode 126/1000 (15.0)\n",
      "Step: 21 \tState: [-0.13360848 -1.32418654  0.17225409  2.0012889 ] \tAction: [ 0.94503063] \tReward: 1.0\n",
      "TD Error: -1.73491363525 \t( 0 s)\n",
      "====================================================================Episode: 127  started\n",
      "Step 25 @ Episode 127/1000 (22.0)\n",
      "Step: 25 \tState: [-0.13019502 -0.1796354   0.20191478  0.74783812] \tAction: [-0.48758939] \tReward: 1.0\n",
      "TD Error: 2.55474607944 \t( 0 s)\n",
      "====================================================================Episode: 128  started\n",
      "Step 10 @ Episode 128/1000 (26.0)\n",
      "Step: 10 \tState: [-0.13282931 -1.16001114  0.1929433   1.98011022] \tAction: [ 0.79706872] \tReward: 1.0\n",
      "TD Error: 5.63378486633 \t( 0 s)\n",
      "====================================================================Episode: 129  started\n",
      "Step 15 @ Episode 129/1000 (11.0)\n",
      "Step: 15 \tState: [-0.18054035 -1.38253878  0.18009048  2.19286179] \tAction: [ 0.73529339] \tReward: 1.0\n",
      "TD Error: 2.09395809174 \t( 0 s)\n",
      "====================================================================Episode: 130  started\n",
      "Step 26 @ Episode 130/1000 (16.0)\n",
      "Step: 26 \tState: [-0.02675072 -0.78571626  0.19203412  1.63378503] \tAction: [ 3.19541383] \tReward: 1.0\n",
      "TD Error: -2.77425384521 \t( 0 s)\n",
      "====================================================================Episode: 131  started\n",
      "Step 15 @ Episode 131/1000 (27.0)\n",
      "Step: 15 \tState: [-0.0648341  -0.59988688  0.19752654  1.24426094] \tAction: [-0.43257746] \tReward: 1.0\n",
      "TD Error: -5.82923355103 \t( 0 s)\n",
      "====================================================================Episode: 132  started\n",
      "Step 9 @ Episode 132/1000 (16.0)\n",
      "Step: 9 \tState: [-0.132189   -1.03031793  0.20691427  1.70060577] \tAction: [-0.41972882] \tReward: 1.0\n",
      "TD Error: -7.8511920929 \t( 0 s)\n",
      "====================================================================Episode: 133  started\n",
      "Step 13 @ Episode 133/1000 (10.0)\n",
      "Step: 13 \tState: [-0.13096545 -0.95533309  0.19180805  1.61073522] \tAction: [ 2.33609891] \tReward: 1.0\n",
      "TD Error: -4.59491882324 \t( 0 s)\n",
      "====================================================================Episode: 134  started\n",
      "Step 10 @ Episode 134/1000 (14.0)\n",
      "Step: 10 \tState: [-0.06022894 -0.75532314  0.19877431  1.38034512] \tAction: [-1.47183156] \tReward: 1.0\n",
      "TD Error: 1.70544569865 \t( 0 s)\n",
      "====================================================================Episode: 135  started\n",
      "Step 12 @ Episode 135/1000 (11.0)\n",
      "Step: 12 \tState: [-0.12024237 -1.60573062  0.18664101  2.38519752] \tAction: [ 0.14058219] \tReward: 1.0\n",
      "TD Error: 10.5260149002 \t( 0 s)\n",
      "====================================================================Episode: 136  started\n",
      "Step 20 @ Episode 136/1000 (13.0)\n",
      "Step: 20 \tState: [-0.16917588 -1.19681942  0.19038558  1.94675197] \tAction: [-3.22521472] \tReward: 1.0\n",
      "TD Error: 3.22513446808 \t( 0 s)\n",
      "====================================================================Episode: 137  started\n",
      "Step 12 @ Episode 137/1000 (21.0)\n",
      "Step: 12 \tState: [-0.08451895 -0.74711617  0.18536538  1.44348889] \tAction: [ 2.56034064] \tReward: 1.0\n",
      "TD Error: -4.48603076935 \t( 0 s)\n",
      "====================================================================Episode: 138  started\n",
      "Step 16 @ Episode 138/1000 (13.0)\n",
      "Step: 16 \tState: [-0.06616882 -1.18085263  0.20043629  2.071811  ] \tAction: [-3.18233681] \tReward: 1.0\n",
      "TD Error: -9.21754169464 \t( 0 s)\n",
      "====================================================================Episode: 139  started\n",
      "Step 18 @ Episode 139/1000 (17.0)\n",
      "Step: 18 \tState: [-0.12855792 -0.41366278  0.19604144  0.99396552] \tAction: [ 0.79861635] \tReward: 1.0\n",
      "TD Error: -1.31060667038 \t( 0 s)\n",
      "====================================================================Episode: 140  started\n",
      "Step 9 @ Episode 140/1000 (19.0)\n",
      "Step: 9 \tState: [-0.13022861 -1.03218347  0.20635176  1.67627158] \tAction: [ 0.81262684] \tReward: 1.0\n",
      "TD Error: 1.19368495345 \t( 0 s)\n",
      "====================================================================Episode: 141  started\n",
      "Step 35 @ Episode 141/1000 (10.0)\n",
      "Step: 35 \tState: [-0.25168145 -0.98634334  0.20833312  1.34819476] \tAction: [ 0.13793284] \tReward: 1.0\n",
      "TD Error: 4.31886506081 \t( 1 s)\n",
      "====================================================================Episode: 142  started\n",
      "Step 17 @ Episode 142/1000 (36.0)\n",
      "Step: 17 \tState: [-0.07965589 -0.55172825  0.18785552  1.18473228] \tAction: [ 0.46086949] \tReward: 1.0\n",
      "TD Error: 1.83686525822 \t( 0 s)\n",
      "====================================================================Episode: 143  started\n",
      "Step 8 @ Episode 143/1000 (18.0)\n",
      "Step: 8 \tState: [-0.06642335 -1.13358079  0.19773771  1.95625493] \tAction: [-0.23938248] \tReward: 1.0\n",
      "TD Error: -1.57164430618 \t( 0 s)\n",
      "====================================================================Episode: 144  started\n",
      "Step 12 @ Episode 144/1000 (9.0)\n",
      "Step: 12 \tState: [-0.14873986 -1.59312181  0.20292876  2.47639571] \tAction: [ 0.84151256] \tReward: 1.0\n",
      "TD Error: -6.54999523163 \t( 0 s)\n",
      "====================================================================Episode: 145  started\n",
      "Step 16 @ Episode 145/1000 (13.0)\n",
      "Step: 16 \tState: [-0.07593571 -0.77926723  0.20437619  1.36389187] \tAction: [ 0.04949504] \tReward: 1.0\n",
      "TD Error: -1.70158605576 \t( 0 s)\n",
      "====================================================================Episode: 146  started\n",
      "Step 16 @ Episode 146/1000 (17.0)\n",
      "Step: 16 \tState: [-0.22653981 -1.97734181  0.19727807  2.91075457] \tAction: [-1.64152527] \tReward: 1.0\n",
      "TD Error: 4.30735225677 \t( 0 s)\n",
      "====================================================================Episode: 147  started\n",
      "Step 12 @ Episode 147/1000 (17.0)\n",
      "Step: 12 \tState: [-0.11560735 -0.75876264  0.19598209  1.41441584] \tAction: [ 0.81162572] \tReward: 1.0\n",
      "TD Error: 3.23531303406 \t( 0 s)\n",
      "====================================================================Episode: 148  started\n",
      "Step 20 @ Episode 148/1000 (13.0)\n",
      "Step: 20 \tState: [-0.0787737  -0.45476333  0.20207523  0.98853532] \tAction: [-0.82886696] \tReward: 1.0\n",
      "TD Error: 1.01859076917 \t( 0 s)\n",
      "====================================================================Episode: 149  started\n",
      "Step 20 @ Episode 149/1000 (21.0)\n",
      "Step: 20 \tState: [-0.10703219 -1.18850319  0.17522113  1.89947406] \tAction: [ 0.59879124] \tReward: 1.0\n",
      "TD Error: 0.60660815239 \t( 0 s)\n",
      "====================================================================Episode: 150  started\n",
      "Step 12 @ Episode 150/1000 (21.0)\n",
      "Step: 12 \tState: [-0.04675077 -1.14273201  0.17540302  2.02558522] \tAction: [ 0.28176984] \tReward: 1.0\n",
      "TD Error: 1.91703304648 \t( 0 s)\n",
      "====================================================================Episode: 151  started\n",
      "Step 19 @ Episode 151/1000 (13.0)\n",
      "Step: 19 \tState: [-0.14425044 -1.00599111  0.20876939  1.68210878] \tAction: [ 1.12015736] \tReward: 1.0\n",
      "TD Error: 2.79823919237 \t( 0 s)\n",
      "====================================================================Episode: 152  started\n",
      "Step 11 @ Episode 152/1000 (20.0)\n",
      "Step: 11 \tState: [-0.12461677 -0.62002866  0.19987815  1.14485094] \tAction: [-0.80450982] \tReward: 1.0\n",
      "TD Error: 2.07440948486 \t( 0 s)\n",
      "====================================================================Episode: 153  started\n",
      "Step 38 @ Episode 153/1000 (12.0)\n",
      "Step: 38 \tState: [-0.22714792 -0.73648153  0.19080458  1.0203718 ] \tAction: [ 0.63686496] \tReward: 1.0\n",
      "TD Error: -0.422379016876 \t( 0 s)\n",
      "====================================================================Episode: 154  started\n",
      "Step 11 @ Episode 154/1000 (39.0)\n",
      "Step: 11 \tState: [-0.09121243 -1.34972757  0.19909686  2.25901641] \tAction: [ 1.30198526] \tReward: 1.0\n",
      "TD Error: -4.80857753754 \t( 0 s)\n",
      "====================================================================Episode: 155  started\n",
      "Step 12 @ Episode 155/1000 (12.0)\n",
      "Step: 12 \tState: [-0.14556805 -1.15527554  0.20460891  1.85834683] \tAction: [ 0.09214975] \tReward: 1.0\n",
      "TD Error: -4.31952199936 \t( 0 s)\n",
      "====================================================================Episode: 156  started\n",
      "Step 17 @ Episode 156/1000 (13.0)\n",
      "Step: 17 \tState: [-0.15556764 -0.64267391  0.19428938  1.19854382] \tAction: [-1.12152946] \tReward: 1.0\n",
      "TD Error: -0.223038578033 \t( 0 s)\n",
      "====================================================================Episode: 157  started\n",
      "Step 8 @ Episode 157/1000 (18.0)\n",
      "Step: 8 \tState: [-0.0741244  -1.13421177  0.19014553  1.94479436] \tAction: [-1.03603625] \tReward: 1.0\n",
      "TD Error: 1.92082698345 \t( 0 s)\n",
      "====================================================================Episode: 158  started\n",
      "Step 20 @ Episode 158/1000 (9.0)\n",
      "Step: 20 \tState: [-0.23569722 -0.82958636  0.20720394  1.16278906] \tAction: [-0.42027193] \tReward: 1.0\n",
      "TD Error: 4.0558139801 \t( 0 s)\n",
      "====================================================================Episode: 159  started\n",
      "Step 14 @ Episode 159/1000 (21.0)\n",
      "Step: 14 \tState: [-0.12262314 -0.80502485  0.20898789  1.61641705] \tAction: [ 0.96661443] \tReward: 1.0\n",
      "TD Error: -0.691466331482 \t( 0 s)\n",
      "====================================================================Episode: 160  started\n",
      "Step 24 @ Episode 160/1000 (15.0)\n",
      "Step: 24 \tState: [ 0.12007261  0.04663225 -0.20357337 -0.466038  ] \tAction: [ 1.58672214] \tReward: 1.0\n",
      "TD Error: 1.34679269791 \t( 0 s)\n",
      "====================================================================Episode: 161  started\n",
      "Step 15 @ Episode 161/1000 (25.0)\n",
      "Step: 15 \tState: [-0.06778829 -1.03033135  0.18303827  1.75440951] \tAction: [ 1.33736444] \tReward: 1.0\n",
      "TD Error: -5.24306697845 \t( 0 s)\n",
      "====================================================================Episode: 162  started\n",
      "Step 11 @ Episode 162/1000 (16.0)\n",
      "Step: 11 \tState: [-0.16370568 -1.36016205  0.17544892  2.14494591] \tAction: [-1.07056773] \tReward: 1.0\n",
      "TD Error: -6.88336410522 \t( 0 s)\n",
      "====================================================================Episode: 163  started\n",
      "Step 19 @ Episode 163/1000 (12.0)\n",
      "Step: 19 \tState: [ 0.11211124  0.23618223 -0.19826659 -0.61788361] \tAction: [-2.35945487] \tReward: 1.0\n",
      "TD Error: 0.293012046814 \t( 0 s)\n",
      "====================================================================Episode: 164  started\n",
      "Step 12 @ Episode 164/1000 (20.0)\n",
      "Step: 12 \tState: [-0.06265222 -0.82895413  0.19510767  1.54607018] \tAction: [ 0.21652566] \tReward: 1.0\n",
      "TD Error: 3.76639037132 \t( 0 s)\n",
      "====================================================================Episode: 165  started\n",
      "Step 10 @ Episode 165/1000 (13.0)\n",
      "Step: 10 \tState: [-0.09820367 -1.13315746  0.18511535  1.91313707] \tAction: [ 1.20276988] \tReward: 1.0\n",
      "TD Error: 2.97362680435 \t( 0 s)\n",
      "====================================================================Episode: 166  started\n",
      "Step 9 @ Episode 166/1000 (11.0)\n",
      "Step: 9 \tState: [-0.11420791 -1.34509627  0.16958073  2.21975221] \tAction: [ 0.85256946] \tReward: 1.0\n",
      "TD Error: 2.97036368847 \t( 0 s)\n",
      "====================================================================Episode: 167  started\n",
      "Step 11 @ Episode 167/1000 (10.0)\n",
      "Step: 11 \tState: [-0.10348998 -0.97189203  0.17860995  1.76874115] \tAction: [-0.32442647] \tReward: 1.0\n",
      "TD Error: 4.62954506874 \t( 0 s)\n",
      "====================================================================Episode: 168  started\n",
      "Step 11 @ Episode 168/1000 (12.0)\n",
      "Step: 11 \tState: [ 0.1228721   1.02938153 -0.18642029 -1.72225157] \tAction: [-0.00334383] \tReward: 1.0\n",
      "TD Error: 0.626798534393 \t( 0 s)\n",
      "====================================================================Episode: 169  started\n",
      "Step 9 @ Episode 169/1000 (12.0)\n",
      "Step: 9 \tState: [-0.11284102 -1.37309061  0.16918733  2.1350898 ] \tAction: [-1.60412836] \tReward: 1.0\n",
      "TD Error: 4.33236283064 \t( 0 s)\n",
      "====================================================================Episode: 170  started\n",
      "Step 12 @ Episode 170/1000 (10.0)\n",
      "Step: 12 \tState: [-0.13506544 -1.18904974  0.18803746  1.92994347] \tAction: [ 0.6711477] \tReward: 1.0\n",
      "TD Error: 1.61815509796 \t( 0 s)\n",
      "====================================================================Episode: 171  started\n",
      "Step 12 @ Episode 171/1000 (13.0)\n",
      "Step: 12 \tState: [-0.14909266 -1.16016377  0.19192282  1.86694796] \tAction: [-0.05652752] \tReward: 1.0\n",
      "TD Error: 2.37666835785 \t( 0 s)\n",
      "====================================================================Episode: 172  started\n",
      "Step 13 @ Episode 172/1000 (13.0)\n",
      "Step: 13 \tState: [ 0.12116305  0.61011552 -0.19913197 -1.10903883] \tAction: [-0.12189244] \tReward: 1.0\n",
      "TD Error: 4.82878799438 \t( 0 s)\n",
      "====================================================================Episode: 173  started\n",
      "Step 19 @ Episode 173/1000 (14.0)\n",
      "Step: 19 \tState: [-0.11650621 -0.17681697  0.20616874  0.74460063] \tAction: [ 0.17510349] \tReward: 1.0\n",
      "TD Error: -0.860143089294 \t( 0 s)\n",
      "====================================================================Episode: 174  started\n",
      "Step 12 @ Episode 174/1000 (20.0)\n",
      "Step: 12 \tState: [-0.15303151 -1.2255174   0.19118632  1.95507491] \tAction: [-0.67580056] \tReward: 1.0\n",
      "TD Error: -5.98163948059 \t( 0 s)\n",
      "====================================================================Episode: 175  started\n",
      "Step 15 @ Episode 175/1000 (13.0)\n",
      "Step: 15 \tState: [-0.12135297 -1.41451812  0.18206253  2.21797244] \tAction: [-2.40796447] \tReward: 1.0\n",
      "TD Error: -0.185597610474 \t( 0 s)\n",
      "====================================================================Episode: 176  started\n",
      "Step 44 @ Episode 176/1000 (16.0)\n",
      "Step: 44 \tState: [-0.423542   -1.15789924  0.19697178  1.25977995] \tAction: [ 0.68679541] \tReward: 1.0\n",
      "TD Error: 8.05757188797 \t( 1 s)\n",
      "====================================================================Episode: 177  started\n",
      "Step 31 @ Episode 177/1000 (45.0)\n",
      "Step: 31 \tState: [ 0.06968073 -0.22379748  0.20544452  1.24475262] \tAction: [-0.99149853] \tReward: 1.0\n",
      "TD Error: -0.351788711548 \t( 0 s)\n",
      "====================================================================Episode: 178  started\n",
      "Step 12 @ Episode 178/1000 (32.0)\n",
      "Step: 12 \tState: [-0.06059978 -0.45018469  0.19898475  0.93851403] \tAction: [-1.42636144] \tReward: 1.0\n",
      "TD Error: -2.59649372101 \t( 0 s)\n",
      "====================================================================Episode: 179  started\n",
      "Step 15 @ Episode 179/1000 (13.0)\n",
      "Step: 15 \tState: [-0.08423963 -0.64006616  0.18864262  1.12035502] \tAction: [ 0.34600505] \tReward: 1.0\n",
      "TD Error: -3.51870746613 \t( 0 s)\n",
      "====================================================================Episode: 180  started\n",
      "Step 16 @ Episode 180/1000 (16.0)\n",
      "Step: 16 \tState: [ 0.11562483  0.40912292 -0.19396599 -0.90734067] \tAction: [ 1.14685774] \tReward: 1.0\n",
      "TD Error: 0.544298315048 \t( 0 s)\n",
      "====================================================================Episode: 181  started\n",
      "Step 13 @ Episode 181/1000 (17.0)\n",
      "Step: 13 \tState: [-0.10435307 -0.57551242  0.2013984   1.25186284] \tAction: [ 0.11023967] \tReward: 1.0\n",
      "TD Error: -6.64534626007 \t( 0 s)\n",
      "====================================================================Episode: 182  started\n",
      "Step 11 @ Episode 182/1000 (14.0)\n",
      "Step: 11 \tState: [-0.16240584 -1.00476148  0.18018346  1.58310301] \tAction: [ 1.73856688] \tReward: 1.0\n",
      "TD Error: -7.82648277283 \t( 0 s)\n",
      "====================================================================Episode: 183  started\n",
      "Step 13 @ Episode 183/1000 (12.0)\n",
      "Step: 13 \tState: [ 0.1261366   0.6290469  -0.18508022 -1.23969968] \tAction: [ 0.20402946] \tReward: 1.0\n",
      "TD Error: 0.83418006897 \t( 0 s)\n",
      "====================================================================Episode: 184  started\n",
      "Step 14 @ Episode 184/1000 (14.0)\n",
      "Step: 14 \tState: [-0.06671553 -1.2055529   0.18335919  2.03053768] \tAction: [-0.37207168] \tReward: 1.0\n",
      "TD Error: -6.237753582 \t( 0 s)\n",
      "====================================================================Episode: 185  started\n",
      "Step 15 @ Episode 185/1000 (15.0)\n",
      "Step: 15 \tState: [-0.17407336 -1.4108553   0.19394925  2.0702795 ] \tAction: [ 0.16307548] \tReward: 1.0\n",
      "TD Error: -2.34296245575 \t( 0 s)\n",
      "====================================================================Episode: 186  started\n",
      "Step 18 @ Episode 186/1000 (16.0)\n",
      "Step: 18 \tState: [-0.10465107 -0.78737829  0.20936509  1.28395773] \tAction: [ 0.9789061] \tReward: 1.0\n",
      "TD Error: 6.02851867676 \t( 0 s)\n",
      "====================================================================Episode: 187  started\n",
      "Step 11 @ Episode 187/1000 (19.0)\n",
      "Step: 11 \tState: [-0.05456509 -0.59091638  0.19954723  1.23771954] \tAction: [-0.59425497] \tReward: 1.0\n",
      "TD Error: 9.07355728149 \t( 0 s)\n",
      "====================================================================Episode: 188  started\n",
      "Step 11 @ Episode 188/1000 (12.0)\n",
      "Step: 11 \tState: [-0.06950842 -0.98565302  0.18784022  1.74623634] \tAction: [-2.61056089] \tReward: 1.0\n",
      "TD Error: 8.2716217041 \t( 0 s)\n",
      "====================================================================Episode: 189  started\n",
      "Step 54 @ Episode 189/1000 (12.0)\n",
      "Step: 54 \tState: [-0.44977947 -2.29507002  0.17066208  2.20497799] \tAction: [-0.41075942] \tReward: 1.0\n",
      "TD Error: 2.80648097992 \t( 1 s)\n",
      "====================================================================Episode: 190  started\n",
      "Step 26 @ Episode 190/1000 (55.0)\n",
      "Step: 26 \tState: [-0.15475462 -1.1838208   0.18140503  1.86520799] \tAction: [ 0.17071278] \tReward: 1.0\n",
      "TD Error: 0.141042709351 \t( 0 s)\n",
      "====================================================================Episode: 191  started\n",
      "Step 14 @ Episode 191/1000 (27.0)\n",
      "Step: 14 \tState: [-0.13318446 -1.15102849  0.20861342  2.02742883] \tAction: [ 0.84820342] \tReward: 1.0\n",
      "TD Error: -4.37723712921 \t( 0 s)\n",
      "====================================================================Episode: 192  started\n",
      "Step 18 @ Episode 192/1000 (15.0)\n",
      "Step: 18 \tState: [-0.12115616 -0.44368343  0.20299028  0.98738922] \tAction: [ 0.66417712] \tReward: 1.0\n",
      "TD Error: -1.83768787384 \t( 0 s)\n",
      "====================================================================Episode: 193  started\n",
      "Step 30 @ Episode 193/1000 (19.0)\n",
      "Step: 30 \tState: [ 0.12160007 -0.35723632 -0.20796114 -0.0743434 ] \tAction: [-1.22990286] \tReward: 1.0\n",
      "TD Error: -0.408822536469 \t( 0 s)\n",
      "====================================================================Episode: 194  started\n",
      "Step 11 @ Episode 194/1000 (31.0)\n",
      "Step: 11 \tState: [-0.03401063 -1.33340689  0.18423813  2.26808144] \tAction: [-1.34945881] \tReward: 1.0\n",
      "TD Error: -1.45650243759 \t( 0 s)\n",
      "====================================================================Episode: 195  started\n",
      "Step 8 @ Episode 195/1000 (12.0)\n",
      "Step: 8 \tState: [-0.07969187 -1.16009976  0.18183567  1.93068803] \tAction: [-1.96267843] \tReward: 1.0\n",
      "TD Error: -0.853028011322 \t( 0 s)\n",
      "====================================================================Episode: 196  started\n",
      "Step 10 @ Episode 196/1000 (9.0)\n",
      "Step: 10 \tState: [-0.07873385 -1.57216984  0.19053773  2.5028715 ] \tAction: [-0.98476094] \tReward: 1.0\n",
      "TD Error: -1.8188539505 \t( 0 s)\n",
      "====================================================================Episode: 197  started\n",
      "Step 13 @ Episode 197/1000 (11.0)\n",
      "Step: 13 \tState: [-0.14580508 -1.37397217  0.17005668  2.09446264] \tAction: [ 3.35867882] \tReward: 1.0\n",
      "TD Error: -0.169803524017 \t( 0 s)\n",
      "====================================================================Episode: 198  started\n",
      "Step 39 @ Episode 198/1000 (14.0)\n",
      "Step: 39 \tState: [-0.37647728 -1.75762566  0.19940818  2.27252352] \tAction: [ 1.12299764] \tReward: 1.0\n",
      "TD Error: -0.799234485626 \t( 0 s)\n",
      "====================================================================Episode: 199  started\n",
      "Step 36 @ Episode 199/1000 (40.0)\n",
      "Step: 36 \tState: [-0.25830692 -1.87775407  0.16859038  2.20810143] \tAction: [ 2.52417111] \tReward: 1.0\n",
      "TD Error: -1.57954006195 \t( 0 s)\n",
      "====================================================================Episode: 200  started\n",
      "Step 30 @ Episode 200/1000 (37.0)\n",
      "Step: 30 \tState: [ 0.1383125   0.37457218 -0.20169485 -1.08438134] \tAction: [-2.89531279] \tReward: 1.0\n",
      "TD Error: -1.1994392395 \t( 0 s)\n",
      "====================================================================Episode: 201  started\n",
      "Step 10 @ Episode 201/1000 (31.0)\n",
      "Step: 10 \tState: [ 0.10409363  1.17863778 -0.19990918 -1.92303563] \tAction: [-3.21061492] \tReward: 1.0\n",
      "TD Error: -2.50021605492 \t( 0 s)\n",
      "====================================================================Episode: 202  started\n",
      "Step 14 @ Episode 202/1000 (11.0)\n",
      "Step: 14 \tState: [-0.1979864  -0.8319738   0.19892461  1.23084538] \tAction: [ 1.2396183] \tReward: 1.0\n",
      "TD Error: -0.000500679016113 \t( 0 s)\n",
      "====================================================================Episode: 203  started\n",
      "Step 16 @ Episode 203/1000 (15.0)\n",
      "Step: 16 \tState: [-0.07581542 -1.14204433  0.20266664  2.16714651] \tAction: [-0.54222703] \tReward: 1.0\n",
      "TD Error: -0.882736873627 \t( 0 s)\n",
      "====================================================================Episode: 204  started\n",
      "Step 9 @ Episode 204/1000 (17.0)\n",
      "Step: 9 \tState: [ 0.08251387  1.37286771 -0.17452992 -2.22276248] \tAction: [-0.66855335] \tReward: 1.0\n",
      "TD Error: -2.66216096878 \t( 0 s)\n",
      "====================================================================Episode: 205  started\n",
      "Step 12 @ Episode 205/1000 (10.0)\n",
      "Step: 12 \tState: [ 0.09437044  1.16080332 -0.17462601 -1.80021418] \tAction: [-0.44114879] \tReward: 1.0\n",
      "TD Error: -0.510841631889 \t( 0 s)\n",
      "====================================================================Episode: 206  started\n",
      "Step 26 @ Episode 206/1000 (13.0)\n",
      "Step: 26 \tState: [-0.19227603 -0.82737645  0.19990498  1.37916012] \tAction: [-0.89140666] \tReward: 1.0\n",
      "TD Error: -0.495040607452 \t( 0 s)\n",
      "====================================================================Episode: 207  started\n",
      "Step 13 @ Episode 207/1000 (27.0)\n",
      "Step: 13 \tState: [-0.15925    -0.9361738   0.20698431  1.75034654] \tAction: [-1.23347974] \tReward: 1.0\n",
      "TD Error: -0.247034931183 \t( 0 s)\n",
      "====================================================================Episode: 208  started\n",
      "Step 42 @ Episode 208/1000 (14.0)\n",
      "Step: 42 \tState: [-0.16796074 -0.81067326  0.18839189  1.50044842] \tAction: [ 0.93025368] \tReward: 1.0\n",
      "TD Error: 0.802396583557 \t( 0 s)\n",
      "====================================================================Episode: 209  started\n",
      "Step 9 @ Episode 209/1000 (43.0)\n",
      "Step: 9 \tState: [-0.1204644  -1.38973608  0.19157296  2.19150988] \tAction: [-0.02802939] \tReward: 1.0\n",
      "TD Error: 0.150078248978 \t( 0 s)\n",
      "====================================================================Episode: 210  started\n",
      "Step 18 @ Episode 210/1000 (10.0)\n",
      "Step: 18 \tState: [-0.11342631 -0.40177483  0.199236    0.93409415] \tAction: [-1.37286341] \tReward: 1.0\n",
      "TD Error: -0.32876291275 \t( 0 s)\n",
      "====================================================================Episode: 211  started\n",
      "Step 12 @ Episode 211/1000 (19.0)\n",
      "Step: 12 \tState: [ 0.09754589  0.4178697  -0.20095405 -0.83505037] \tAction: [ 1.72442389] \tReward: 1.0\n",
      "TD Error: 1.34097738266 \t( 0 s)\n",
      "====================================================================Episode: 212  started\n",
      "Step 11 @ Episode 212/1000 (13.0)\n",
      "Step: 11 \tState: [-0.11972058 -0.97514809  0.20439866  1.69937498] \tAction: [ 1.40067947] \tReward: 1.0\n",
      "TD Error: -2.30417079926 \t( 0 s)\n",
      "====================================================================Episode: 213  started\n",
      "Step 8 @ Episode 213/1000 (12.0)\n",
      "Step: 8 \tState: [-0.13029336 -0.74900373  0.2076924   1.40850773] \tAction: [ 0.98053396] \tReward: 1.0\n",
      "TD Error: -3.40407180786 \t( 0 s)\n",
      "====================================================================Episode: 214  started\n",
      "Step 14 @ Episode 214/1000 (9.0)\n",
      "Step: 14 \tState: [-0.12267545 -1.52263122  0.17780676  2.463765  ] \tAction: [-1.65316546] \tReward: 1.0\n",
      "TD Error: -6.11781024933 \t( 0 s)\n",
      "====================================================================Episode: 215  started\n",
      "Step 15 @ Episode 215/1000 (15.0)\n",
      "Step: 15 \tState: [ 0.12330422  0.94954118 -0.19837128 -1.78583164] \tAction: [ 2.69378042] \tReward: 1.0\n",
      "TD Error: 3.15604023933 \t( 0 s)\n",
      "====================================================================Episode: 216  started\n",
      "Step 9 @ Episode 216/1000 (16.0)\n",
      "Step: 9 \tState: [-0.08337366 -0.94670577  0.18439724  1.60522383] \tAction: [ 0.55026537] \tReward: 1.0\n",
      "TD Error: -0.181519699097 \t( 0 s)\n",
      "====================================================================Episode: 217  started\n",
      "Step 12 @ Episode 217/1000 (10.0)\n",
      "Step: 12 \tState: [-0.14847719 -1.54013909  0.19850889  2.39600095] \tAction: [ 2.20197463] \tReward: 1.0\n",
      "TD Error: 3.77188773155 \t( 0 s)\n",
      "====================================================================Episode: 218  started\n",
      "Step 19 @ Episode 218/1000 (13.0)\n",
      "Step: 19 \tState: [ 0.12530251 -0.21790615 -0.20848878 -0.22462418] \tAction: [ 0.47547767] \tReward: 1.0\n",
      "TD Error: 0.51922223568 \t( 0 s)\n",
      "====================================================================Episode: 219  started\n",
      "Step 25 @ Episode 219/1000 (20.0)\n",
      "Step: 25 \tState: [-0.20432385 -1.74327657  0.18416259  2.40970869] \tAction: [ 3.79348254] \tReward: 1.0\n",
      "TD Error: 9.74862966537 \t( 0 s)\n",
      "====================================================================Episode: 220  started\n",
      "Step 18 @ Episode 220/1000 (26.0)\n",
      "Step: 18 \tState: [-0.06265338 -0.80096256  0.19903078  1.38838936] \tAction: [ 0.65102923] \tReward: 1.0\n",
      "TD Error: 5.47255859375 \t( 0 s)\n",
      "====================================================================Episode: 221  started\n",
      "Step 42 @ Episode 221/1000 (19.0)\n",
      "Step: 42 \tState: [-0.31759041 -1.12639682  0.19522838  1.24222633] \tAction: [-3.91615272] \tReward: 1.0\n",
      "TD Error: 3.39564418793 \t( 0 s)\n",
      "====================================================================Episode: 222  started\n",
      "Step 16 @ Episode 222/1000 (43.0)\n",
      "Step: 16 \tState: [-0.08907214 -0.38318583  0.19477929  0.92304172] \tAction: [-0.45166087] \tReward: 1.0\n",
      "TD Error: -1.41622848511 \t( 0 s)\n",
      "====================================================================Episode: 223  started\n",
      "Step 13 @ Episode 223/1000 (17.0)\n",
      "Step: 13 \tState: [-0.1705668  -0.9695753   0.19153587  1.55975645] \tAction: [ 1.98573029] \tReward: 1.0\n",
      "TD Error: -6.11626415253 \t( 0 s)\n",
      "====================================================================Episode: 224  started\n",
      "Step 9 @ Episode 224/1000 (14.0)\n",
      "Step: 9 \tState: [-0.11343654 -0.60265598  0.20118787  1.07819132] \tAction: [-0.63991314] \tReward: 1.0\n",
      "TD Error: -6.4027671814 \t( 0 s)\n",
      "====================================================================Episode: 225  started\n",
      "Step 30 @ Episode 225/1000 (10.0)\n",
      "Step: 30 \tState: [-0.02261992 -0.04590093  0.20865381  0.84414711] \tAction: [-2.13256955] \tReward: 1.0\n",
      "TD Error: -0.880625200272 \t( 0 s)\n",
      "====================================================================Episode: 226  started\n",
      "Step 17 @ Episode 226/1000 (31.0)\n",
      "Step: 17 \tState: [-0.15748274 -1.03490832  0.20286285  1.76129532] \tAction: [ 2.39776254] \tReward: 1.0\n",
      "TD Error: 0.154747390747 \t( 0 s)\n",
      "====================================================================Episode: 227  started\n",
      "Step 28 @ Episode 227/1000 (18.0)\n",
      "Step: 28 \tState: [ 0.00248529  0.06086184 -0.19891477 -0.77064317] \tAction: [-1.365538] \tReward: 1.0\n",
      "TD Error: 0.332521486282 \t( 0 s)\n",
      "====================================================================Episode: 228  started\n",
      "Step 24 @ Episode 228/1000 (29.0)\n",
      "Step: 24 \tState: [-0.06811803 -0.4663251   0.19808059  1.39875466] \tAction: [-1.66664934] \tReward: 1.0\n",
      "TD Error: -0.223180651665 \t( 0 s)\n",
      "====================================================================Episode: 229  started\n",
      "Step 21 @ Episode 229/1000 (25.0)\n",
      "Step: 21 \tState: [ 0.00604697 -0.24411725  0.19938211  1.07481441] \tAction: [ 1.23369992] \tReward: 1.0\n",
      "TD Error: -0.431682693958 \t( 0 s)\n",
      "====================================================================Episode: 230  started\n",
      "Step 23 @ Episode 230/1000 (22.0)\n",
      "Step: 23 \tState: [ 0.10276923  0.59324331 -0.19783088 -1.31643305] \tAction: [ 3.45173144] \tReward: 1.0\n",
      "TD Error: 0.570723438263 \t( 0 s)\n",
      "====================================================================Episode: 231  started\n",
      "Step 14 @ Episode 231/1000 (24.0)\n",
      "Step: 14 \tState: [-0.18207216 -0.78185852  0.18548224  1.34049404] \tAction: [-1.12422156] \tReward: 1.0\n",
      "TD Error: -0.401920247078 \t( 0 s)\n",
      "====================================================================Episode: 232  started\n",
      "Step 16 @ Episode 232/1000 (15.0)\n",
      "Step: 16 \tState: [ 0.10276707  0.05781548 -0.20678298 -0.46251557] \tAction: [ 1.74346328] \tReward: 1.0\n",
      "TD Error: 0.502254009247 \t( 0 s)\n",
      "====================================================================Episode: 233  started\n",
      "Step 20 @ Episode 233/1000 (17.0)\n",
      "Step: 20 \tState: [-0.16765895 -0.77438145  0.19165211  1.47675179] \tAction: [-0.27715358] \tReward: 1.0\n",
      "TD Error: -0.439138299227 \t( 0 s)\n",
      "====================================================================Episode: 234  started\n",
      "Step 20 @ Episode 234/1000 (21.0)\n",
      "Step: 20 \tState: [-0.19327455 -1.19467442  0.19497386  1.97222215] \tAction: [-3.5939033] \tReward: 1.0\n",
      "TD Error: -0.656330537796 \t( 0 s)\n",
      "====================================================================Episode: 235  started\n",
      "Step 39 @ Episode 235/1000 (21.0)\n",
      "Step: 39 \tState: [ 0.03260954  0.55699109  0.2087474   0.38227782] \tAction: [-1.38120019] \tReward: 1.0\n",
      "TD Error: -0.428341507912 \t( 0 s)\n",
      "====================================================================Episode: 236  started\n",
      "Step 20 @ Episode 236/1000 (40.0)\n",
      "Step: 20 \tState: [ 0.1305905   0.82894264 -0.18566778 -1.46596629] \tAction: [-4.45510817] \tReward: 1.0\n",
      "TD Error: 0.642283630371 \t( 0 s)\n",
      "====================================================================Episode: 237  started\n",
      "Step 19 @ Episode 237/1000 (21.0)\n",
      "Step: 19 \tState: [ 0.16451681  0.24040787 -0.20799293 -0.80727517] \tAction: [ 3.70541143] \tReward: 1.0\n",
      "TD Error: -0.729296016693 \t( 0 s)\n",
      "====================================================================Episode: 238  started\n",
      "Step 12 @ Episode 238/1000 (20.0)\n",
      "Step: 12 \tState: [-0.13781541 -1.21618245  0.19382095  1.94243413] \tAction: [ 3.45017195] \tReward: 1.0\n",
      "TD Error: -1.42561120987 \t( 0 s)\n",
      "====================================================================Episode: 239  started\n",
      "Step 10 @ Episode 239/1000 (13.0)\n",
      "Step: 10 \tState: [-0.11047597 -1.56514589  0.18077197  2.40119424] \tAction: [ 1.38257325] \tReward: 1.0\n",
      "TD Error: 1.82897977829 \t( 0 s)\n",
      "====================================================================Episode: 240  started\n",
      "Step 13 @ Episode 240/1000 (11.0)\n",
      "Step: 13 \tState: [-0.12052928 -1.32195579  0.20354984  2.25126726] \tAction: [ 2.85908771] \tReward: 1.0\n",
      "TD Error: 4.65729160309 \t( 0 s)\n",
      "====================================================================Episode: 241  started\n",
      "Step 45 @ Episode 241/1000 (14.0)\n",
      "Step: 45 \tState: [ 0.01732648  0.23596308 -0.19442456 -1.24017732] \tAction: [ 1.37231886] \tReward: 1.0\n",
      "TD Error: -0.160331058502 \t( 1 s)\n",
      "====================================================================Episode: 242  started\n",
      "Step 11 @ Episode 242/1000 (46.0)\n",
      "Step: 11 \tState: [-0.05895408 -0.95666952  0.20187385  1.73876143] \tAction: [-1.42649317] \tReward: 1.0\n",
      "TD Error: -2.39167525768 \t( 0 s)\n",
      "====================================================================Episode: 243  started\n",
      "Step 28 @ Episode 243/1000 (12.0)\n",
      "Step: 28 \tState: [-0.08782469 -0.78826706  0.19817635  1.25194781] \tAction: [ 5.96841717] \tReward: 1.0\n",
      "TD Error: 1.562368536 \t( 0 s)\n",
      "====================================================================Episode: 244  started\n",
      "Step 23 @ Episode 244/1000 (29.0)\n",
      "Step: 23 \tState: [-0.14933399 -0.6083401   0.19039031  1.26648117] \tAction: [-1.18273056] \tReward: 1.0\n",
      "TD Error: 1.13180847168 \t( 0 s)\n",
      "====================================================================Episode: 245  started\n",
      "Step 24 @ Episode 245/1000 (24.0)\n",
      "Step: 24 \tState: [-0.16036881 -0.78555036  0.19472427  1.28212312] \tAction: [-2.72368765] \tReward: 1.0\n",
      "TD Error: 0.245536494255 \t( 0 s)\n",
      "====================================================================Episode: 246  started\n",
      "Step 32 @ Episode 246/1000 (25.0)\n",
      "Step: 32 \tState: [-0.38264531 -1.96616539  0.16805269  2.20996978] \tAction: [ 0.01189947] \tReward: 1.0\n",
      "TD Error: 1.92773035765 \t( 0 s)\n",
      "====================================================================Episode: 247  started\n",
      "Step 21 @ Episode 247/1000 (33.0)\n",
      "Step: 21 \tState: [-0.11642384 -0.2413309   0.20695916  0.88767338] \tAction: [ 2.48113918] \tReward: 1.0\n",
      "TD Error: -0.952355623245 \t( 0 s)\n",
      "====================================================================Episode: 248  started\n",
      "Step 25 @ Episode 248/1000 (22.0)\n",
      "Step: 25 \tState: [ 0.09559775  1.38841115 -0.19611805 -2.13748028] \tAction: [-0.96933359] \tReward: 1.0\n",
      "TD Error: 0.00673828125 \t( 0 s)\n",
      "====================================================================Episode: 249  started\n",
      "Step 11 @ Episode 249/1000 (26.0)\n",
      "Step: 11 \tState: [ 0.11050835  1.34177584 -0.16984949 -2.06721999] \tAction: [ 1.36243737] \tReward: 1.0\n",
      "TD Error: 1.36178331375 \t( 0 s)\n",
      "====================================================================Episode: 250  started\n",
      "Step 19 @ Episode 250/1000 (12.0)\n",
      "Step: 19 \tState: [-0.15411581 -0.99889731  0.19849749  1.65918868] \tAction: [-2.71807122] \tReward: 1.0\n",
      "TD Error: -0.732650864124 \t( 0 s)\n",
      "====================================================================Episode: 251  started\n",
      "Step 17 @ Episode 251/1000 (20.0)\n",
      "Step: 17 \tState: [ 0.09767029  0.19649203 -0.19759655 -0.76902516] \tAction: [-3.67425013] \tReward: 1.0\n",
      "TD Error: -1.83581123352 \t( 0 s)\n",
      "====================================================================Episode: 252  started\n",
      "Step 15 @ Episode 252/1000 (18.0)\n",
      "Step: 15 \tState: [ 0.13809175  0.58467892 -0.19253096 -1.17496272] \tAction: [ 0.4897961] \tReward: 1.0\n",
      "TD Error: -2.45239677429 \t( 0 s)\n",
      "====================================================================Episode: 253  started\n",
      "Step 12 @ Episode 253/1000 (16.0)\n",
      "Step: 12 \tState: [-0.13346816 -0.78020647  0.20603893  1.44216284] \tAction: [-3.70597434] \tReward: 1.0\n",
      "TD Error: 3.52359886169 \t( 0 s)\n",
      "====================================================================Episode: 254  started\n",
      "Step 10 @ Episode 254/1000 (13.0)\n",
      "Step: 10 \tState: [-0.10275997 -0.82515603  0.20906001  1.43614526] \tAction: [-0.92063063] \tReward: 1.0\n",
      "TD Error: 2.74387586117 \t( 0 s)\n",
      "====================================================================Episode: 255  started\n",
      "Step 25 @ Episode 255/1000 (11.0)\n",
      "Step: 25 \tState: [-0.13581974 -0.99439071  0.19079923  1.78130325] \tAction: [-3.7628665] \tReward: 1.0\n",
      "TD Error: -2.24604120255 \t( 0 s)\n",
      "====================================================================Episode: 256  started\n",
      "Step 13 @ Episode 256/1000 (26.0)\n",
      "Step: 13 \tState: [-0.12385076 -0.57043765  0.20650794  1.32970938] \tAction: [ 5.97170019] \tReward: 1.0\n",
      "TD Error: -1.90687665939 \t( 0 s)\n",
      "====================================================================Episode: 257  started\n",
      "Step 60 @ Episode 257/1000 (14.0)\n",
      "Step: 60 \tState: [ 0.07807033  0.40205996 -0.1979884  -1.01173714] \tAction: [ 0.20033832] \tReward: 1.0\n",
      "TD Error: 1.63464744091 \t( 1 s)\n",
      "====================================================================Episode: 258  started\n",
      "Step 25 @ Episode 258/1000 (61.0)\n",
      "Step: 25 \tState: [-0.07397393 -0.21312332  0.2019457   1.14427149] \tAction: [-1.62017131] \tReward: 1.0\n",
      "TD Error: -1.20381774902 \t( 0 s)\n",
      "====================================================================Episode: 259  started\n",
      "Step 17 @ Episode 259/1000 (26.0)\n",
      "Step: 17 \tState: [-0.08733663 -0.9710887   0.1755244   1.75908492] \tAction: [ 6.14994192] \tReward: 1.0\n",
      "TD Error: -1.88300548494 \t( 0 s)\n",
      "====================================================================Episode: 260  started\n",
      "Step 9 @ Episode 260/1000 (18.0)\n",
      "Step: 9 \tState: [-0.09067111 -1.37205929  0.20599755  2.2293636 ] \tAction: [-2.32600427] \tReward: 1.0\n",
      "TD Error: 4.01486926079 \t( 0 s)\n",
      "====================================================================Episode: 261  started\n",
      "Step 40 @ Episode 261/1000 (10.0)\n",
      "Step: 40 \tState: [ 0.10726637  0.43581427 -0.19571638 -1.31778811] \tAction: [-2.92353368] \tReward: 1.0\n",
      "TD Error: 0.188595128059 \t( 1 s)\n",
      "====================================================================Episode: 262  started\n",
      "Step 20 @ Episode 262/1000 (41.0)\n",
      "Step: 20 \tState: [-0.17012678 -0.3966433   0.20259806  0.95173383] \tAction: [ 0.13669723] \tReward: 1.0\n",
      "TD Error: 2.39578595161 \t( 0 s)\n",
      "====================================================================Episode: 263  started\n",
      "Step 26 @ Episode 263/1000 (21.0)\n",
      "Step: 26 \tState: [-0.17406403 -0.7505893   0.18788237  1.43063799] \tAction: [-0.71409506] \tReward: 1.0\n",
      "TD Error: 1.06636636257 \t( 0 s)\n",
      "====================================================================Episode: 264  started\n",
      "Step 11 @ Episode 264/1000 (27.0)\n",
      "Step: 11 \tState: [-0.04060651 -0.96894768  0.17892639  1.7214642 ] \tAction: [-3.92488599] \tReward: 1.0\n",
      "TD Error: 0.415663146973 \t( 0 s)\n",
      "====================================================================Episode: 265  started\n",
      "Step 37 @ Episode 265/1000 (12.0)\n",
      "Step: 37 \tState: [-0.14175611 -1.41454721  0.17807047  2.24716117] \tAction: [-3.52952504] \tReward: 1.0\n",
      "TD Error: -0.361234092712 \t( 0 s)\n",
      "====================================================================Episode: 266  started\n",
      "Step 32 @ Episode 266/1000 (38.0)\n",
      "Step: 32 \tState: [-0.04567061 -0.43139071  0.20320515  1.08747093] \tAction: [-1.94132352] \tReward: 1.0\n",
      "TD Error: 0.373089504242 \t( 1 s)\n",
      "====================================================================Episode: 267  started\n",
      "Step 20 @ Episode 267/1000 (33.0)\n",
      "Step: 20 \tState: [-0.20478826 -0.4295068   0.20118807  0.86276907] \tAction: [ 0.11446072] \tReward: 1.0\n",
      "TD Error: -0.777121925354 \t( 0 s)\n",
      "====================================================================Episode: 268  started\n",
      "Step 14 @ Episode 268/1000 (21.0)\n",
      "Step: 14 \tState: [-0.05915002 -0.74611041  0.1868791   1.40055301] \tAction: [-6.1483469] \tReward: 1.0\n",
      "TD Error: -2.35332431793 \t( 0 s)\n",
      "====================================================================Episode: 269  started\n",
      "Step 33 @ Episode 269/1000 (15.0)\n",
      "Step: 33 \tState: [-0.10420131 -0.93686176  0.19047234  1.75391497] \tAction: [ 2.82854486] \tReward: 1.0\n",
      "TD Error: -2.18160438538 \t( 0 s)\n",
      "====================================================================Episode: 270  started\n",
      "Step 39 @ Episode 270/1000 (34.0)\n",
      "Step: 39 \tState: [-0.39695016 -2.52654126  0.17991119  2.85443229] \tAction: [ 2.34647918] \tReward: 1.0\n",
      "TD Error: 0.30245513916 \t( 0 s)\n",
      "====================================================================Episode: 271  started\n",
      "Step 48 @ Episode 271/1000 (40.0)\n",
      "Step: 48 \tState: [ 0.60006578  1.15082556 -0.18948631 -1.03741551] \tAction: [-0.83990693] \tReward: 1.0\n",
      "TD Error: 0.266263008118 \t( 1 s)\n",
      "====================================================================Episode: 272  started\n",
      "Step 12 @ Episode 272/1000 (49.0)\n",
      "Step: 12 \tState: [-0.19215021 -1.15965939  0.20422     1.90432484] \tAction: [-0.95023847] \tReward: 1.0\n",
      "TD Error: -3.37059144974 \t( 0 s)\n",
      "====================================================================Episode: 273  started\n",
      "Step 27 @ Episode 273/1000 (13.0)\n",
      "Step: 27 \tState: [-0.0562755  -0.19536351  0.19905266  1.02114478] \tAction: [-2.44807744] \tReward: 1.0\n",
      "TD Error: -0.52364154458 \t( 0 s)\n",
      "====================================================================Episode: 274  started\n",
      "Step 15 @ Episode 274/1000 (28.0)\n",
      "Step: 15 \tState: [-0.14273926 -0.99151008  0.20278381  1.69213236] \tAction: [ 2.74682951] \tReward: 1.0\n",
      "TD Error: 0.254216074944 \t( 0 s)\n",
      "====================================================================Episode: 275  started\n",
      "Step 49 @ Episode 275/1000 (16.0)\n",
      "Step: 49 \tState: [ 0.10158596  0.58456628 -0.20452315 -1.32244929] \tAction: [-1.94358718] \tReward: 1.0\n",
      "TD Error: -4.78555488586 \t( 1 s)\n",
      "====================================================================Episode: 276  started\n",
      "Step 13 @ Episode 276/1000 (50.0)\n",
      "Step: 13 \tState: [ 0.07794964  0.612045   -0.18461889 -1.24605589] \tAction: [ 1.65445197] \tReward: 1.0\n",
      "TD Error: -3.10960693359 \t( 0 s)\n",
      "====================================================================Episode: 277  started\n",
      "Step 16 @ Episode 277/1000 (14.0)\n",
      "Step: 16 \tState: [-0.15301235 -0.76478947  0.19193618  1.35015277] \tAction: [ 3.28873301] \tReward: 1.0\n",
      "TD Error: 1.96171045303 \t( 0 s)\n",
      "====================================================================Episode: 278  started\n",
      "Step 42 @ Episode 278/1000 (17.0)\n",
      "Step: 42 \tState: [ 0.09654517 -0.09630023  0.18298791  1.43924587] \tAction: [-2.04619598] \tReward: 1.0\n",
      "TD Error: -1.08607940674 \t( 0 s)\n",
      "====================================================================Episode: 279  started\n",
      "Step 11 @ Episode 279/1000 (43.0)\n",
      "Step: 11 \tState: [-0.15270274 -1.01256512  0.19630797  1.69661317] \tAction: [ 0.53991044] \tReward: 1.0\n",
      "TD Error: -3.99975624084 \t( 0 s)\n",
      "====================================================================Episode: 280  started\n",
      "Step 11 @ Episode 280/1000 (12.0)\n",
      "Step: 11 \tState: [-0.07499279 -1.36628482  0.17524979  2.22723374] \tAction: [-1.63092279] \tReward: 1.0\n",
      "TD Error: -5.11508159637 \t( 0 s)\n",
      "====================================================================Episode: 281  started\n",
      "Step 25 @ Episode 281/1000 (12.0)\n",
      "Step: 25 \tState: [ 0.01594893  0.56980098 -0.20300621 -1.53174994] \tAction: [-4.05247259] \tReward: 1.0\n",
      "TD Error: 0.221959924698 \t( 0 s)\n",
      "====================================================================Episode: 282  started\n",
      "Step 22 @ Episode 282/1000 (26.0)\n",
      "Step: 22 \tState: [ 0.20240529  1.21015775 -0.20181898 -1.88466131] \tAction: [-2.19715691] \tReward: 1.0\n",
      "TD Error: -0.369006222486 \t( 0 s)\n",
      "====================================================================Episode: 283  started\n",
      "Step 25 @ Episode 283/1000 (23.0)\n",
      "Step: 25 \tState: [-0.0691528  -0.6179752   0.20887487  1.43784654] \tAction: [ 0.15348668] \tReward: 1.0\n",
      "TD Error: -0.0137540340424 \t( 0 s)\n",
      "====================================================================Episode: 284  started\n",
      "Step 12 @ Episode 284/1000 (26.0)\n",
      "Step: 12 \tState: [-0.06791225 -0.74800942  0.18089599  1.46326746] \tAction: [-1.94058621] \tReward: 1.0\n",
      "TD Error: 1.99049220085 \t( 0 s)\n",
      "====================================================================Episode: 285  started\n",
      "Step 14 @ Episode 285/1000 (13.0)\n",
      "Step: 14 \tState: [-0.11161992 -1.16186999  0.20514099  1.94532401] \tAction: [ 2.62351441] \tReward: 1.0\n",
      "TD Error: 4.23161592484 \t( 0 s)\n",
      "====================================================================Episode: 286  started\n",
      "Step 11 @ Episode 286/1000 (15.0)\n",
      "Step: 11 \tState: [ 0.13501224  0.94542364 -0.1780502  -1.63105104] \tAction: [-0.31680804] \tReward: 1.0\n",
      "TD Error: -0.592794442177 \t( 0 s)\n",
      "====================================================================Episode: 287  started\n",
      "Step 18 @ Episode 287/1000 (12.0)\n",
      "Step: 18 \tState: [ 0.06215956  0.81816356 -0.19727585 -1.62524982] \tAction: [-3.13482046] \tReward: 1.0\n",
      "TD Error: 1.42198596001 \t( 0 s)\n",
      "====================================================================Episode: 288  started\n",
      "Step 17 @ Episode 288/1000 (19.0)\n",
      "Step: 17 \tState: [-0.13022838 -0.95749672  0.18630466  1.5133407 ] \tAction: [-2.48920536] \tReward: 1.0\n",
      "TD Error: 0.749212360382 \t( 0 s)\n",
      "====================================================================Episode: 289  started\n",
      "Step 15 @ Episode 289/1000 (18.0)\n",
      "Step: 15 \tState: [ 0.09299513  0.964305   -0.19522941 -1.85235184] \tAction: [-3.66190386] \tReward: 1.0\n",
      "TD Error: 1.7803103447 \t( 0 s)\n",
      "====================================================================Episode: 290  started\n",
      "Step 29 @ Episode 290/1000 (16.0)\n",
      "Step: 29 \tState: [-0.01470888 -0.60369825  0.1865606   1.23125541] \tAction: [ 1.00602877] \tReward: 1.0\n",
      "TD Error: -1.40754022598 \t( 0 s)\n",
      "====================================================================Episode: 291  started\n",
      "Step 13 @ Episode 291/1000 (30.0)\n",
      "Step: 13 \tState: [ 0.1564563   0.63082552 -0.20519121 -1.20368057] \tAction: [-2.65856194] \tReward: 1.0\n",
      "TD Error: 3.50519881248 \t( 0 s)\n",
      "====================================================================Episode: 292  started\n",
      "Step 10 @ Episode 292/1000 (14.0)\n",
      "Step: 10 \tState: [-0.11148161 -0.81344966  0.2031744   1.41117957] \tAction: [-1.6259402] \tReward: 1.0\n",
      "TD Error: -1.80675983429 \t( 0 s)\n",
      "====================================================================Episode: 293  started\n",
      "Step 17 @ Episode 293/1000 (11.0)\n",
      "Step: 17 \tState: [ 0.06262204  0.5817463  -0.20553698 -1.24042357] \tAction: [-3.28145576] \tReward: 1.0\n",
      "TD Error: 0.358472776413 \t( 0 s)\n",
      "====================================================================Episode: 294  started\n",
      "Step 14 @ Episode 294/1000 (18.0)\n",
      "Step: 14 \tState: [-0.08282288 -0.3983752   0.19411367  0.9548565 ] \tAction: [-6.15826893] \tReward: 1.0\n",
      "TD Error: -0.336254882813 \t( 0 s)\n",
      "====================================================================Episode: 295  started\n",
      "Step 9 @ Episode 295/1000 (15.0)\n",
      "Step: 9 \tState: [ 0.11216224  1.3539409  -0.19873243 -2.30606184] \tAction: [-3.60572338] \tReward: 1.0\n",
      "TD Error: -3.89431934357 \t( 0 s)\n",
      "====================================================================Episode: 296  started\n",
      "Step 12 @ Episode 296/1000 (10.0)\n",
      "Step: 12 \tState: [ 0.0948048   0.78316731 -0.20541087 -1.48009706] \tAction: [-5.85174894] \tReward: 1.0\n",
      "TD Error: -6.48952922821 \t( 0 s)\n",
      "====================================================================Episode: 297  started\n",
      "Step 19 @ Episode 297/1000 (13.0)\n",
      "Step: 19 \tState: [-0.11775279 -0.21246751  0.20177382  0.61591159] \tAction: [-0.5137251] \tReward: 1.0\n",
      "TD Error: 3.97734379768 \t( 0 s)\n",
      "====================================================================Episode: 298  started\n",
      "Step 20 @ Episode 298/1000 (20.0)\n",
      "Step: 20 \tState: [-0.16375333 -1.20569948  0.17919633  1.70945491] \tAction: [-4.35567093] \tReward: 1.0\n",
      "TD Error: 3.83272838593 \t( 0 s)\n",
      "====================================================================Episode: 299  started\n",
      "Step 10 @ Episode 299/1000 (21.0)\n",
      "Step: 10 \tState: [-0.13039619 -1.19977486  0.17111321  1.97489491] \tAction: [ 4.55525255] \tReward: 1.0\n",
      "TD Error: -2.83709754944 \t( 0 s)\n",
      "====================================================================Episode: 300  started\n",
      "Step 17 @ Episode 300/1000 (11.0)\n",
      "Step: 17 \tState: [-0.1631661  -0.64306879  0.20211682  1.22610394] \tAction: [-0.66411489] \tReward: 1.0\n",
      "TD Error: -9.75100631714 \t( 0 s)\n",
      "====================================================================Episode: 301  started\n",
      "Step 43 @ Episode 301/1000 (18.0)\n",
      "Step: 43 \tState: [-0.11920633 -0.59965166  0.19412804  1.25052521] \tAction: [-2.91578555] \tReward: 1.0\n",
      "TD Error: -2.03524036407 \t( 1 s)\n",
      "====================================================================Episode: 302  started\n",
      "Step 29 @ Episode 302/1000 (44.0)\n",
      "Step: 29 \tState: [-0.04958477  0.1334603   0.2007115   0.46440627] \tAction: [-2.03826594] \tReward: 1.0\n",
      "TD Error: 1.32354409695 \t( 0 s)\n",
      "====================================================================Episode: 303  started\n",
      "Step 12 @ Episode 303/1000 (30.0)\n",
      "Step: 12 \tState: [-0.14756929 -0.44576077  0.19578627  0.80626593] \tAction: [ 3.25466108] \tReward: 1.0\n",
      "TD Error: 0.779414463043 \t( 0 s)\n",
      "====================================================================Episode: 304  started\n",
      "Step 11 @ Episode 304/1000 (13.0)\n",
      "Step: 11 \tState: [-0.09727226 -0.57390261  0.1873058   1.14243848] \tAction: [-2.36768675] \tReward: 1.0\n",
      "TD Error: 0.0563412666321 \t( 0 s)\n",
      "====================================================================Episode: 305  started\n",
      "Step 16 @ Episode 305/1000 (12.0)\n",
      "Step: 16 \tState: [-0.11813066 -0.05297     0.19925729  0.57077377] \tAction: [ 2.52022576] \tReward: 1.0\n",
      "TD Error: -0.0154200553894 \t( 0 s)\n",
      "====================================================================Episode: 306  started\n",
      "Step 12 @ Episode 306/1000 (17.0)\n",
      "Step: 12 \tState: [-0.07816937 -1.56987811  0.16817829  2.46763437] \tAction: [ 2.00630045] \tReward: 1.0\n",
      "TD Error: -1.19140195847 \t( 0 s)\n",
      "====================================================================Episode: 307  started\n",
      "Step 10 @ Episode 307/1000 (13.0)\n",
      "Step: 10 \tState: [-0.09610974 -0.82435068  0.18514619  1.47466526] \tAction: [-4.68754435] \tReward: 1.0\n",
      "TD Error: 0.799706506729 \t( 0 s)\n",
      "====================================================================Episode: 308  started\n",
      "Step 15 @ Episode 308/1000 (11.0)\n",
      "Step: 15 \tState: [ 0.12765399  0.63770807 -0.19002594 -1.20572014] \tAction: [ 5.08946848] \tReward: 1.0\n",
      "TD Error: -2.71670207977 \t( 0 s)\n",
      "====================================================================Episode: 309  started\n",
      "Step 17 @ Episode 309/1000 (16.0)\n",
      "Step: 17 \tState: [ 0.13819667  1.02309233 -0.20531419 -1.70113314] \tAction: [ 1.93717897] \tReward: 1.0\n",
      "TD Error: -0.124646282196 \t( 0 s)\n",
      "====================================================================Episode: 310  started\n",
      "Step 12 @ Episode 310/1000 (18.0)\n",
      "Step: 12 \tState: [-0.10400352 -0.78389103  0.19752201  1.34265447] \tAction: [-2.57369566] \tReward: 1.0\n",
      "TD Error: 0.305247879028 \t( 0 s)\n",
      "====================================================================Episode: 311  started\n",
      "Step 17 @ Episode 311/1000 (13.0)\n",
      "Step: 17 \tState: [-0.14577086 -1.79945031  0.18102179  2.66362336] \tAction: [ 3.48501277] \tReward: 1.0\n",
      "TD Error: -1.27329468727 \t( 0 s)\n",
      "====================================================================Episode: 312  started\n",
      "Step 11 @ Episode 312/1000 (18.0)\n",
      "Step: 11 \tState: [ 0.1285369   0.60726472 -0.19200419 -1.1681505 ] \tAction: [ 0.96515733] \tReward: 1.0\n",
      "TD Error: 2.93468666077 \t( 0 s)\n",
      "====================================================================Episode: 313  started\n",
      "Step 10 @ Episode 313/1000 (12.0)\n",
      "Step: 10 \tState: [-0.10133614 -0.80838547  0.20774738  1.46327807] \tAction: [ 4.17412806] \tReward: 1.0\n",
      "TD Error: 1.33088231087 \t( 0 s)\n",
      "====================================================================Episode: 314  started\n",
      "Step 31 @ Episode 314/1000 (11.0)\n",
      "Step: 31 \tState: [ 0.04696038  0.2126619  -0.19725284 -0.99299963] \tAction: [ 1.97110105] \tReward: 1.0\n",
      "TD Error: 2.6422121048 \t( 0 s)\n",
      "====================================================================Episode: 315  started\n",
      "Step 42 @ Episode 315/1000 (32.0)\n",
      "Step: 42 \tState: [-0.11813091 -0.80483291  0.1871248   1.35741497] \tAction: [-0.30300584] \tReward: 1.0\n",
      "TD Error: 1.2311899513 \t( 0 s)\n",
      "====================================================================Episode: 316  started\n",
      "Step 9 @ Episode 316/1000 (43.0)\n",
      "Step: 9 \tState: [ 0.13874119  0.60973214 -0.18866266 -1.1205202 ] \tAction: [ 3.27020955] \tReward: 1.0\n",
      "TD Error: -4.6482711792 \t( 0 s)\n",
      "====================================================================Episode: 317  started\n",
      "Step 21 @ Episode 317/1000 (10.0)\n",
      "Step: 21 \tState: [-0.07795632 -0.18939938  0.20430925  0.86885589] \tAction: [-4.91794252] \tReward: 1.0\n",
      "TD Error: 2.92906427383 \t( 0 s)\n",
      "====================================================================Episode: 318  started\n",
      "Step 9 @ Episode 318/1000 (22.0)\n",
      "Step: 9 \tState: [ 0.09991092  1.71724916 -0.1890351  -2.73565264] \tAction: [-0.76820457] \tReward: 1.0\n",
      "TD Error: -12.761689949 \t( 0 s)\n",
      "====================================================================Episode: 319  started\n",
      "Step 20 @ Episode 319/1000 (10.0)\n",
      "Step: 20 \tState: [ 0.16827472  0.83518482 -0.18896488 -1.41028882] \tAction: [ 0.29157013] \tReward: 1.0\n",
      "TD Error: -5.9937084198 \t( 0 s)\n",
      "====================================================================Episode: 320  started\n",
      "Step 20 @ Episode 320/1000 (21.0)\n",
      "Step: 20 \tState: [-0.10217159  0.00765676  0.20283666  0.69406724] \tAction: [-1.83370662] \tReward: 1.0\n",
      "TD Error: -1.01847572327 \t( 0 s)\n",
      "====================================================================Episode: 321  started\n",
      "Step 26 @ Episode 321/1000 (21.0)\n",
      "Step: 26 \tState: [-0.21140837 -0.73073478  0.1975649   1.14696222] \tAction: [-1.00508761] \tReward: 1.0\n",
      "TD Error: -3.33002662659 \t( 0 s)\n",
      "====================================================================Episode: 322  started\n",
      "Step 28 @ Episode 322/1000 (27.0)\n",
      "Step: 28 \tState: [ 0.14480745  1.53420845 -0.18729169 -2.21774675] \tAction: [-0.76801074] \tReward: 1.0\n",
      "TD Error: 2.63770799637 \t( 0 s)\n",
      "====================================================================Episode: 323  started\n",
      "Step 13 @ Episode 323/1000 (29.0)\n",
      "Step: 13 \tState: [ 0.17442768  0.59120175 -0.19245709 -1.06302956] \tAction: [ 4.01099873] \tReward: 1.0\n",
      "TD Error: 7.28280944824 \t( 0 s)\n",
      "====================================================================Episode: 324  started\n",
      "Step 12 @ Episode 324/1000 (14.0)\n",
      "Step: 12 \tState: [-0.05396461 -0.75501724  0.1920538   1.48998715] \tAction: [-2.143332] \tReward: 1.0\n",
      "TD Error: -3.63687210083 \t( 0 s)\n",
      "====================================================================Episode: 325  started\n",
      "Step 17 @ Episode 325/1000 (13.0)\n",
      "Step: 17 \tState: [-0.18102589 -1.00223397  0.20831582  1.62867813] \tAction: [-4.30609083] \tReward: 1.0\n",
      "TD Error: -10.3068540573 \t( 0 s)\n",
      "====================================================================Episode: 326  started\n",
      "Step 17 @ Episode 326/1000 (18.0)\n",
      "Step: 17 \tState: [ 0.0804578  -0.21194228 -0.20861015 -0.24515661] \tAction: [-6.0581398] \tReward: 1.0\n",
      "TD Error: 2.27836399078 \t( 0 s)\n",
      "====================================================================Episode: 327  started\n",
      "Step 56 @ Episode 327/1000 (18.0)\n",
      "Step: 56 \tState: [ 0.12684107 -0.41220179  0.18566222  1.34688626] \tAction: [ 3.42335987] \tReward: 1.0\n",
      "TD Error: -1.69862673283 \t( 1 s)\n",
      "====================================================================Episode: 328  started\n",
      "Step 33 @ Episode 328/1000 (57.0)\n",
      "Step: 33 \tState: [ 0.19834797  1.38383882 -0.18995877 -1.93209809] \tAction: [-1.02087545] \tReward: 1.0\n",
      "TD Error: 2.16942424774 \t( 0 s)\n",
      "====================================================================Episode: 329  started\n",
      "Step 21 @ Episode 329/1000 (34.0)\n",
      "Step: 21 \tState: [ 0.12801069  0.99628167 -0.18702473 -1.57117972] \tAction: [-1.38456762] \tReward: 1.0\n",
      "TD Error: -0.851814651489 \t( 0 s)\n",
      "====================================================================Episode: 330  started\n",
      "Step 30 @ Episode 330/1000 (22.0)\n",
      "Step: 30 \tState: [ 0.00245015  0.02390889 -0.19750686 -0.87561828] \tAction: [-6.78889132] \tReward: 1.0\n",
      "TD Error: -3.40287704468 \t( 0 s)\n",
      "====================================================================Episode: 331  started\n",
      "Step 42 @ Episode 331/1000 (31.0)\n",
      "Step: 42 \tState: [-0.04612151  0.44677742 -0.20915975 -1.42976161] \tAction: [ 0.90350044] \tReward: 1.0\n",
      "TD Error: -3.68583116531 \t( 1 s)\n",
      "====================================================================Episode: 332  started\n",
      "Step 24 @ Episode 332/1000 (43.0)\n",
      "Step: 24 \tState: [-0.16953568 -0.37381007  0.1946278   0.8981779 ] \tAction: [ 0.2935895] \tReward: 1.0\n",
      "TD Error: 4.49484386444 \t( 0 s)\n",
      "====================================================================Episode: 333  started\n",
      "Step 19 @ Episode 333/1000 (25.0)\n",
      "Step: 19 \tState: [-0.12007572 -0.55875429  0.20688413  1.11391375] \tAction: [-3.27484512] \tReward: 1.0\n",
      "TD Error: 6.3817358017 \t( 0 s)\n",
      "====================================================================Episode: 334  started\n",
      "Step 38 @ Episode 334/1000 (20.0)\n",
      "Step: 38 \tState: [-0.15162561 -1.13641658  0.20288984  1.76723356] \tAction: [ 4.07420635] \tReward: 1.0\n",
      "TD Error: 5.35700817108 \t( 0 s)\n",
      "====================================================================Episode: 335  started\n",
      "Step 48 @ Episode 335/1000 (39.0)\n",
      "Step: 48 \tState: [ 0.16232089 -0.42272477  0.2035025   1.58907887] \tAction: [-5.2545929] \tReward: 1.0\n",
      "TD Error: -0.32592124939 \t( 1 s)\n",
      "====================================================================Episode: 336  started\n",
      "Step 23 @ Episode 336/1000 (49.0)\n",
      "Step: 23 \tState: [ 0.06201878  1.00473999 -0.17590857 -1.765885  ] \tAction: [ 2.72186661] \tReward: 1.0\n",
      "TD Error: -1.07833914757 \t( 0 s)\n",
      "====================================================================Episode: 337  started\n",
      "Step 30 @ Episode 337/1000 (24.0)\n",
      "Step: 30 \tState: [-0.12244415 -0.05356531  0.19887679  0.75105069] \tAction: [-6.39612865] \tReward: 1.0\n",
      "TD Error: -1.04271087646 \t( 0 s)\n",
      "====================================================================Episode: 338  started\n",
      "Step 14 @ Episode 338/1000 (31.0)\n",
      "Step: 14 \tState: [ 0.13850589  0.40016142 -0.20734664 -1.01989502] \tAction: [-0.70117921] \tReward: 1.0\n",
      "TD Error: 0.219311273098 \t( 0 s)\n",
      "====================================================================Episode: 339  started\n",
      "Step 26 @ Episode 339/1000 (15.0)\n",
      "Step: 26 \tState: [-0.03839351 -1.14509818  0.20265311  2.17367703] \tAction: [-5.01309013] \tReward: 1.0\n",
      "TD Error: -2.7264503479 \t( 0 s)\n",
      "====================================================================Episode: 340  started\n",
      "Step 9 @ Episode 340/1000 (27.0)\n",
      "Step: 9 \tState: [-0.13906969 -1.4085551   0.1762533   2.10939846] \tAction: [ 3.41608882] \tReward: 1.0\n",
      "TD Error: -3.2417301178 \t( 0 s)\n",
      "====================================================================Episode: 341  started\n",
      "Step 26 @ Episode 341/1000 (10.0)\n",
      "Step: 26 \tState: [ 0.06464853  0.01009027 -0.20084412 -0.74861514] \tAction: [ 4.12715769] \tReward: 1.0\n",
      "TD Error: 0.310742950439 \t( 0 s)\n",
      "====================================================================Episode: 342  started\n",
      "Step 21 @ Episode 342/1000 (27.0)\n",
      "Step: 21 \tState: [-0.17251938 -0.97823465  0.19345498  1.74872081] \tAction: [ 4.55144262] \tReward: 1.0\n",
      "TD Error: -3.0235584259 \t( 0 s)\n",
      "====================================================================Episode: 343  started\n",
      "Step 23 @ Episode 343/1000 (22.0)\n",
      "Step: 23 \tState: [-0.10889624 -0.64950352  0.197382    1.22528581] \tAction: [ 3.12601614] \tReward: 1.0\n",
      "TD Error: 1.82310948372 \t( 0 s)\n",
      "====================================================================Episode: 344  started\n",
      "Step 14 @ Episode 344/1000 (24.0)\n",
      "Step: 14 \tState: [-0.06158256 -0.80768961  0.18808004  1.41355475] \tAction: [ 0.86741155] \tReward: 1.0\n",
      "TD Error: 1.97720308304 \t( 0 s)\n",
      "====================================================================Episode: 345  started\n",
      "Step 10 @ Episode 345/1000 (15.0)\n",
      "Step: 10 \tState: [-0.1581911  -0.75153649  0.20926128  1.38925155] \tAction: [-0.48299801] \tReward: 1.0\n",
      "TD Error: -0.880811882019 \t( 0 s)\n",
      "====================================================================Episode: 346  started\n",
      "Step 21 @ Episode 346/1000 (11.0)\n",
      "Step: 21 \tState: [ 0.18112297  0.60535848 -0.19953129 -1.02401579] \tAction: [-2.13668609] \tReward: 1.0\n",
      "TD Error: -1.65200090408 \t( 0 s)\n",
      "====================================================================Episode: 347  started\n",
      "Step 22 @ Episode 347/1000 (22.0)\n",
      "Step: 22 \tState: [ 0.25061977  1.2040742  -0.18329607 -1.68967331] \tAction: [-0.51807386] \tReward: 1.0\n",
      "TD Error: -2.23829841614 \t( 0 s)\n",
      "====================================================================Episode: 348  started\n",
      "Step 25 @ Episode 348/1000 (23.0)\n",
      "Step: 25 \tState: [-0.2277258  -0.54849624  0.1983665   0.77872038] \tAction: [-4.66600323] \tReward: 1.0\n",
      "TD Error: -0.988700485229 \t( 0 s)\n",
      "====================================================================Episode: 349  started\n",
      "Step 12 @ Episode 349/1000 (26.0)\n",
      "Step: 12 \tState: [ 0.17375741  0.80882418 -0.20501814 -1.37382053] \tAction: [ 2.59310222] \tReward: 1.0\n",
      "TD Error: -3.24230489731 \t( 0 s)\n",
      "====================================================================Episode: 350  started\n",
      "Step 20 @ Episode 350/1000 (13.0)\n",
      "Step: 20 \tState: [-0.2318883  -0.83104478  0.20757858  1.38089173] \tAction: [-2.59106469] \tReward: 1.0\n",
      "TD Error: -5.38964748383 \t( 0 s)\n",
      "====================================================================Episode: 351  started\n",
      "Step 59 @ Episode 351/1000 (21.0)\n",
      "Step: 59 \tState: [-0.36153819 -0.13266592 -0.18579496 -1.39627851] \tAction: [ 3.49612737] \tReward: 1.0\n",
      "TD Error: -2.09955673218 \t( 1 s)\n",
      "====================================================================Episode: 352  started\n",
      "Step 20 @ Episode 352/1000 (60.0)\n",
      "Step: 20 \tState: [-0.17809168 -1.53587685  0.17437421  2.11342652] \tAction: [ 7.47373915] \tReward: 1.0\n",
      "TD Error: -1.64505577087 \t( 0 s)\n",
      "====================================================================Episode: 353  started\n",
      "Step 16 @ Episode 353/1000 (21.0)\n",
      "Step: 16 \tState: [-0.1032414  -0.82560025  0.20795539  1.53340896] \tAction: [-7.53094435] \tReward: 1.0\n",
      "TD Error: -4.46288909912 \t( 0 s)\n",
      "====================================================================Episode: 354  started\n",
      "Step 28 @ Episode 354/1000 (17.0)\n",
      "Step: 28 \tState: [ 0.0464834  -0.39994991 -0.20760999 -0.11358891] \tAction: [-0.21048985] \tReward: 1.0\n",
      "TD Error: -0.137141704559 \t( 0 s)\n",
      "====================================================================Episode: 355  started\n",
      "Step 13 @ Episode 355/1000 (29.0)\n",
      "Step: 13 \tState: [-0.13463051 -0.97300207  0.18605717  1.55456473] \tAction: [-0.80299884] \tReward: 1.0\n",
      "TD Error: -1.66723270416 \t( 0 s)\n",
      "====================================================================Episode: 356  started\n",
      "Step 19 @ Episode 356/1000 (14.0)\n",
      "Step: 19 \tState: [ 0.18132375  0.54458086 -0.19186672 -0.91307996] \tAction: [-2.1750412] \tReward: 1.0\n",
      "TD Error: -1.71301255226 \t( 0 s)\n",
      "====================================================================Episode: 357  started\n",
      "Step 24 @ Episode 357/1000 (20.0)\n",
      "Step: 24 \tState: [-0.02017636 -0.77113241  0.18952734  1.60849744] \tAction: [ 0.85162944] \tReward: 1.0\n",
      "TD Error: -1.22659649849 \t( 0 s)\n",
      "====================================================================Episode: 358  started\n",
      "Step 9 @ Episode 358/1000 (25.0)\n",
      "Step: 9 \tState: [-0.13050375 -0.95376084  0.1806031   1.62541779] \tAction: [ 1.81925166] \tReward: 1.0\n",
      "TD Error: -0.336444759369 \t( 0 s)\n",
      "====================================================================Episode: 359  started\n",
      "Step 58 @ Episode 359/1000 (10.0)\n",
      "Step: 58 \tState: [-0.28196484 -1.16202138  0.20729649  1.68710705] \tAction: [-0.19378003] \tReward: 1.0\n",
      "TD Error: 0.599385237694 \t( 1 s)\n",
      "====================================================================Episode: 360  started\n",
      "Step 16 @ Episode 360/1000 (59.0)\n",
      "Step: 16 \tState: [ 0.21512589  1.55475059 -0.19570371 -2.35657475] \tAction: [ 2.01442695] \tReward: 1.0\n",
      "TD Error: -5.78191440105 \t( 0 s)\n",
      "====================================================================Episode: 361  started\n",
      "Step 16 @ Episode 361/1000 (17.0)\n",
      "Step: 16 \tState: [-0.13210519 -1.19725431  0.18688224  2.09326211] \tAction: [-1.74832511] \tReward: 1.0\n",
      "TD Error: -0.538300180435 \t( 0 s)\n",
      "====================================================================Episode: 362  started\n",
      "Step 41 @ Episode 362/1000 (17.0)\n",
      "Step: 41 \tState: [-0.04463764  0.2326522  -0.19678508 -1.35666161] \tAction: [-1.74471164] \tReward: 1.0\n",
      "TD Error: -3.73089281321 \t( 0 s)\n",
      "====================================================================Episode: 363  started\n",
      "Step 17 @ Episode 363/1000 (42.0)\n",
      "Step: 17 \tState: [-0.13845146 -0.22453034  0.20000418  0.83054417] \tAction: [ 8.77516556] \tReward: 1.0\n",
      "TD Error: 0.588390111923 \t( 0 s)\n",
      "====================================================================Episode: 364  started\n",
      "Step 23 @ Episode 364/1000 (18.0)\n",
      "Step: 23 \tState: [-0.1830346  -1.0052917   0.20209467  1.72409804] \tAction: [ 4.21174431] \tReward: 1.0\n",
      "TD Error: -0.842586421967 \t( 0 s)\n",
      "====================================================================Episode: 365  started\n",
      "Step 33 @ Episode 365/1000 (24.0)\n",
      "Step: 33 \tState: [-0.02135996 -0.57056294  0.19595661  1.57251428] \tAction: [ 0.81816596] \tReward: 1.0\n",
      "TD Error: -0.49659371376 \t( 0 s)\n",
      "====================================================================Episode: 366  started\n",
      "Step 12 @ Episode 366/1000 (34.0)\n",
      "Step: 12 \tState: [-0.16151723 -0.8065714   0.18644659  1.36722615] \tAction: [-4.18266869] \tReward: 1.0\n",
      "TD Error: 0.679807424545 \t( 0 s)\n",
      "====================================================================Episode: 367  started\n",
      "Step 35 @ Episode 367/1000 (13.0)\n",
      "Step: 35 \tState: [-0.035026    0.12484066  0.2083648   0.61096489] \tAction: [ 0.07374783] \tReward: 1.0\n",
      "TD Error: -0.479098033905 \t( 0 s)\n",
      "====================================================================Episode: 368  started\n",
      "Step 35 @ Episode 368/1000 (36.0)\n",
      "Step: 35 \tState: [ 0.1168385   0.54383719  0.20858592  0.51412896] \tAction: [ 6.47217703] \tReward: 1.0\n",
      "TD Error: -0.47071595192 \t( 0 s)\n",
      "====================================================================Episode: 369  started\n",
      "Step 24 @ Episode 369/1000 (36.0)\n",
      "Step: 24 \tState: [-0.11054242 -1.194292    0.20140365  2.0482098 ] \tAction: [ 6.82181931] \tReward: 1.0\n",
      "TD Error: -0.989981794357 \t( 0 s)\n",
      "====================================================================Episode: 370  started\n",
      "Step 19 @ Episode 370/1000 (25.0)\n",
      "Step: 19 \tState: [-0.06033463 -1.33433115  0.20893896  2.40709296] \tAction: [-0.23457465] \tReward: 1.0\n",
      "TD Error: -0.613824653625 \t( 0 s)\n",
      "====================================================================Episode: 371  started\n",
      "Step 29 @ Episode 371/1000 (20.0)\n",
      "Step: 29 \tState: [-0.07068673 -0.18743425  0.20478104  1.00401827] \tAction: [ 4.07341528] \tReward: 1.0\n",
      "TD Error: -0.134473848343 \t( 0 s)\n",
      "====================================================================Episode: 372  started\n",
      "Step 15 @ Episode 372/1000 (30.0)\n",
      "Step: 15 \tState: [-0.14096313 -0.61404716  0.2094065   1.2748638 ] \tAction: [ 2.23951507] \tReward: 1.0\n",
      "TD Error: -1.43168535233 \t( 0 s)\n",
      "====================================================================Episode: 373  started\n",
      "Step 46 @ Episode 373/1000 (16.0)\n",
      "Step: 46 \tState: [ 0.09833742 -0.44161187  0.20886496  1.10672311] \tAction: [-2.87054729] \tReward: 1.0\n",
      "TD Error: -1.27081151009 \t( 1 s)\n",
      "====================================================================Episode: 374  started\n",
      "Step 15 @ Episode 374/1000 (47.0)\n",
      "Step: 15 \tState: [-0.13282954 -1.00313024  0.19603046  1.76381811] \tAction: [ 9.64840698] \tReward: 1.0\n",
      "TD Error: 0.786671185493 \t( 0 s)\n",
      "====================================================================Episode: 375  started\n",
      "Step 14 @ Episode 375/1000 (16.0)\n",
      "Step: 14 \tState: [ 0.17898349  0.81590713 -0.2091383  -1.46767255] \tAction: [-1.92466557] \tReward: 1.0\n",
      "TD Error: 1.36061000824 \t( 0 s)\n",
      "====================================================================Episode: 376  started\n",
      "Step 20 @ Episode 376/1000 (15.0)\n",
      "Step: 20 \tState: [-0.03853189 -0.46141163  0.19927242  1.18403965] \tAction: [-3.72254682] \tReward: 1.0\n",
      "TD Error: -2.55803074837 \t( 0 s)\n",
      "====================================================================Episode: 377  started\n",
      "Step 45 @ Episode 377/1000 (21.0)\n",
      "Step: 45 \tState: [-0.25808762 -1.32531528  0.20815369  1.36708914] \tAction: [ 1.93064713] \tReward: 1.0\n",
      "TD Error: 1.6077375412 \t( 1 s)\n",
      "====================================================================Episode: 378  started\n",
      "Step 14 @ Episode 378/1000 (46.0)\n",
      "Step: 14 \tState: [ 0.09999789  0.41997312 -0.19611661 -0.93875237] \tAction: [-2.85021567] \tReward: 1.0\n",
      "TD Error: -6.23084964752 \t( 0 s)\n",
      "====================================================================Episode: 379  started\n",
      "Step 28 @ Episode 379/1000 (15.0)\n",
      "Step: 28 \tState: [ 0.17207452  0.40924647 -0.20231673 -1.17381398] \tAction: [ 2.75962639] \tReward: 1.0\n",
      "TD Error: -2.77026872635 \t( 0 s)\n",
      "====================================================================Episode: 380  started\n",
      "Step 26 @ Episode 380/1000 (29.0)\n",
      "Step: 26 \tState: [-0.13364946 -0.75915258  0.2050171   1.43229077] \tAction: [-4.92383909] \tReward: 1.0\n",
      "TD Error: 0.867835131288 \t( 0 s)\n",
      "====================================================================Episode: 381  started\n",
      "Step 7 @ Episode 381/1000 (27.0)\n",
      "Step: 7 \tState: [-0.06004733 -1.34251526  0.17676199  2.21205947] \tAction: [-3.18976879] \tReward: 1.0\n",
      "TD Error: 1.25834772587 \t( 0 s)\n",
      "====================================================================Episode: 382  started\n",
      "Step 29 @ Episode 382/1000 (8.0)\n",
      "Step: 29 \tState: [ 0.02952432  0.56448303 -0.19501978 -1.37840973] \tAction: [ 0.53137529] \tReward: 1.0\n",
      "TD Error: 2.46558151245 \t( 0 s)\n",
      "====================================================================Episode: 383  started\n",
      "Step 7 @ Episode 383/1000 (30.0)\n",
      "Step: 7 \tState: [ 0.11402757  1.38497255 -0.18427755 -2.2568428 ] \tAction: [ 9.54510307] \tReward: 1.0\n",
      "TD Error: 9.5680229187 \t( 0 s)\n",
      "====================================================================Episode: 384  started\n",
      "Step 14 @ Episode 384/1000 (8.0)\n",
      "Step: 14 \tState: [-0.05399873 -0.82631579  0.19707632  1.46691584] \tAction: [ 2.34346867] \tReward: 1.0\n",
      "TD Error: -2.39542970657 \t( 0 s)\n",
      "====================================================================Episode: 385  started\n",
      "Step 23 @ Episode 385/1000 (15.0)\n",
      "Step: 23 \tState: [ 0.03439695  0.17258917 -0.20823369 -0.836128  ] \tAction: [-1.15018988] \tReward: 1.0\n",
      "TD Error: 11.2325313568 \t( 0 s)\n",
      "====================================================================Episode: 386  started\n",
      "Step 57 @ Episode 386/1000 (24.0)\n",
      "Step: 57 \tState: [-0.22707567 -0.10745285 -0.20687163 -1.46109874] \tAction: [ 0.73995692] \tReward: 1.0\n",
      "TD Error: -4.21991271973 \t( 1 s)\n",
      "====================================================================Episode: 387  started\n",
      "Step 18 @ Episode 387/1000 (58.0)\n",
      "Step: 18 \tState: [ 0.08826536  0.01435245 -0.2086877  -0.5531542 ] \tAction: [-0.03834504] \tReward: 1.0\n",
      "TD Error: -4.26780815125 \t( 0 s)\n",
      "====================================================================Episode: 388  started\n",
      "Step 15 @ Episode 388/1000 (19.0)\n",
      "Step: 15 \tState: [ 0.19196355  0.56961678 -0.20899097 -1.18774959] \tAction: [ 2.049124] \tReward: 1.0\n",
      "TD Error: -7.43827362061 \t( 0 s)\n",
      "====================================================================Episode: 389  started\n",
      "Step 22 @ Episode 389/1000 (16.0)\n",
      "Step: 22 \tState: [-0.03493437 -1.52179244  0.17712489  2.46416658] \tAction: [ 5.45318556] \tReward: 1.0\n",
      "TD Error: -2.71341145039 \t( 0 s)\n",
      "====================================================================Episode: 390  started\n",
      "Step 17 @ Episode 390/1000 (23.0)\n",
      "Step: 17 \tState: [-0.0821383  -0.54731299  0.18824113  1.09915341] \tAction: [-2.90943193] \tReward: 1.0\n",
      "TD Error: 2.44700527191 \t( 0 s)\n",
      "====================================================================Episode: 391  started\n",
      "Step 59 @ Episode 391/1000 (18.0)\n",
      "Step: 59 \tState: [-0.77228427 -2.47046845  0.19990126  2.06338588] \tAction: [ 1.84488225] \tReward: 1.0\n",
      "TD Error: 4.48451814651 \t( 1 s)\n",
      "====================================================================Episode: 392  started\n",
      "Step 13 @ Episode 392/1000 (60.0)\n",
      "Step: 13 \tState: [-0.19658254 -0.95438513  0.19593793  1.57115533] \tAction: [ 6.35966301] \tReward: 1.0\n",
      "TD Error: 2.91325759888 \t( 0 s)\n",
      "====================================================================Episode: 393  started\n",
      "Step 19 @ Episode 393/1000 (14.0)\n",
      "Step: 19 \tState: [-0.19672552 -0.630312    0.20834261  1.06066173] \tAction: [ 1.09211946] \tReward: 1.0\n",
      "TD Error: 0.375992655754 \t( 0 s)\n",
      "====================================================================Episode: 394  started\n",
      "Step 34 @ Episode 394/1000 (20.0)\n",
      "Step: 34 \tState: [ 0.00437892  0.78858959 -0.17701028 -1.80997344] \tAction: [-1.34944975] \tReward: 1.0\n",
      "TD Error: -4.30297622681 \t( 1 s)\n",
      "====================================================================Episode: 395  started\n",
      "Step 21 @ Episode 395/1000 (35.0)\n",
      "Step: 21 \tState: [-0.13469332 -0.63195374  0.20335309  1.24802883] \tAction: [-10.64166355] \tReward: 1.0\n",
      "TD Error: -1.87136468887 \t( 0 s)\n",
      "====================================================================Episode: 396  started\n",
      "Step 37 @ Episode 396/1000 (22.0)\n",
      "Step: 37 \tState: [-0.11848927  0.18732202  0.20517438  0.30246334] \tAction: [ 3.47213531] \tReward: 1.0\n",
      "TD Error: -0.11396946907 \t( 0 s)\n",
      "====================================================================Episode: 397  started\n",
      "Step 9 @ Episode 397/1000 (38.0)\n",
      "Step: 9 \tState: [-0.17209974 -1.34659282  0.19986867  2.15307712] \tAction: [ 1.52015805] \tReward: 1.0\n",
      "TD Error: -1.22580969334 \t( 0 s)\n",
      "====================================================================Episode: 398  started\n",
      "Step 15 @ Episode 398/1000 (10.0)\n",
      "Step: 15 \tState: [-0.11491978 -0.97633555  0.1956548   1.60056156] \tAction: [ 9.88162327] \tReward: 1.0\n",
      "TD Error: 0.73653639555 \t( 0 s)\n",
      "====================================================================Episode: 399  started\n",
      "Step 32 @ Episode 399/1000 (16.0)\n",
      "Step: 32 \tState: [ 0.1063039   0.75230911 -0.20654489 -1.40352123] \tAction: [-0.56508023] \tReward: 1.0\n",
      "TD Error: -1.15321335793 \t( 0 s)\n",
      "====================================================================Episode: 400  started\n",
      "Step 15 @ Episode 400/1000 (33.0)\n",
      "Step: 15 \tState: [-0.08633468 -0.62218872  0.20599779  1.14731696] \tAction: [ 3.42862892] \tReward: 1.0\n",
      "TD Error: 0.558179807663 \t( 0 s)\n",
      "====================================================================Episode: 401  started\n",
      "Step 13 @ Episode 401/1000 (16.0)\n",
      "Step: 13 \tState: [-0.09995136 -1.393541    0.17310162  2.21988196] \tAction: [ 9.17625237] \tReward: 1.0\n",
      "TD Error: -0.441129624844 \t( 0 s)\n",
      "====================================================================Episode: 402  started\n",
      "Step 9 @ Episode 402/1000 (14.0)\n",
      "Step: 9 \tState: [-0.11480799 -0.95962513  0.1847013   1.69949072] \tAction: [ 13.82083511] \tReward: 1.0\n",
      "TD Error: 0.0168011188507 \t( 0 s)\n",
      "====================================================================Episode: 403  started\n",
      "Step 38 @ Episode 403/1000 (10.0)\n",
      "Step: 38 \tState: [-0.05591631 -0.81868178  0.20676336  1.75872653] \tAction: [ 3.07599044] \tReward: 1.0\n",
      "TD Error: -1.4053833127 \t( 0 s)\n",
      "====================================================================Episode: 404  started\n",
      "Step 21 @ Episode 404/1000 (39.0)\n",
      "Step: 21 \tState: [ 0.03202074  0.22408841 -0.20456885 -0.83133363] \tAction: [-4.48524141] \tReward: 1.0\n",
      "TD Error: 2.4945602417 \t( 0 s)\n",
      "====================================================================Episode: 405  started\n",
      "Step 31 @ Episode 405/1000 (22.0)\n",
      "Step: 31 \tState: [-0.1973467  -1.33676337  0.172334    2.03946434] \tAction: [-2.44374824] \tReward: 1.0\n",
      "TD Error: 0.885011005402 \t( 0 s)\n",
      "====================================================================Episode: 406  started\n",
      "Step 23 @ Episode 406/1000 (32.0)\n",
      "Step: 23 \tState: [-0.12731998 -1.00561671  0.20724348  1.84563864] \tAction: [-1.15598464] \tReward: 1.0\n",
      "TD Error: 3.29960479736 \t( 0 s)\n",
      "====================================================================Episode: 407  started\n",
      "Step 20 @ Episode 407/1000 (24.0)\n",
      "Step: 20 \tState: [ 0.04436076  0.74646497 -0.18265972 -1.51147406] \tAction: [-5.14175129] \tReward: 1.0\n",
      "TD Error: 1.19236888885 \t( 0 s)\n",
      "====================================================================Episode: 408  started\n",
      "Step 10 @ Episode 408/1000 (21.0)\n",
      "Step: 10 \tState: [-0.11788785 -1.19413714  0.20333731  1.92140712] \tAction: [-1.80791914] \tReward: 1.0\n",
      "TD Error: 2.00413718224 \t( 0 s)\n",
      "====================================================================Episode: 409  started\n",
      "Step 48 @ Episode 409/1000 (11.0)\n",
      "Step: 48 \tState: [-0.61722678 -2.27785788  0.17440796  1.92470104] \tAction: [ 6.07158947] \tReward: 1.0\n",
      "TD Error: 1.24678459167 \t( 1 s)\n",
      "====================================================================Episode: 410  started\n",
      "Step 13 @ Episode 410/1000 (49.0)\n",
      "Step: 13 \tState: [-0.12811699 -1.01008399  0.18702887  1.68655217] \tAction: [ 0.99226964] \tReward: 1.0\n",
      "TD Error: -1.87500047684 \t( 0 s)\n",
      "====================================================================Episode: 411  started\n",
      "Step 22 @ Episode 411/1000 (14.0)\n",
      "Step: 22 \tState: [ 0.08079124 -0.01867184 -0.20663548 -0.69704626] \tAction: [ 3.49258065] \tReward: 1.0\n",
      "TD Error: -1.85185565948 \t( 0 s)\n",
      "====================================================================Episode: 412  started\n",
      "Step 39 @ Episode 412/1000 (23.0)\n",
      "Step: 39 \tState: [-0.4237061  -1.69934157  0.20075619  1.81650613] \tAction: [ 0.00126367] \tReward: 1.0\n",
      "TD Error: -2.28036231995 \t( 0 s)\n",
      "====================================================================Episode: 413  started\n",
      "Step 11 @ Episode 413/1000 (40.0)\n",
      "Step: 11 \tState: [-0.0805341  -0.96563033  0.1900816   1.59457315] \tAction: [ 2.94283104] \tReward: 1.0\n",
      "TD Error: -2.0674071312 \t( 0 s)\n",
      "====================================================================Episode: 414  started\n",
      "Step 19 @ Episode 414/1000 (12.0)\n",
      "Step: 19 \tState: [-0.17502357 -0.98698571  0.19641467  1.59642561] \tAction: [-2.24815083] \tReward: 1.0\n",
      "TD Error: 0.196912744641 \t( 0 s)\n",
      "====================================================================Episode: 415  started\n",
      "Step 12 @ Episode 415/1000 (20.0)\n",
      "Step: 12 \tState: [ 0.09314947  0.83894803 -0.20408015 -1.51941015] \tAction: [-1.28291249] \tReward: 1.0\n",
      "TD Error: -3.82643222809 \t( 0 s)\n",
      "====================================================================Episode: 416  started\n",
      "Step 16 @ Episode 416/1000 (13.0)\n",
      "Step: 16 \tState: [-0.09060176 -0.83456327  0.19182755  1.42662221] \tAction: [ 5.63937044] \tReward: 1.0\n",
      "TD Error: 0.871502280235 \t( 0 s)\n",
      "====================================================================Episode: 417  started\n",
      "Step 12 @ Episode 417/1000 (17.0)\n",
      "Step: 12 \tState: [-0.17050946 -1.173655    0.1866732   1.88847229] \tAction: [ 8.43805313] \tReward: 1.0\n",
      "TD Error: 2.59037249088 \t( 0 s)\n",
      "====================================================================Episode: 418  started\n",
      "Step 14 @ Episode 418/1000 (13.0)\n",
      "Step: 14 \tState: [ 0.12024009  0.79036653 -0.18438047 -1.44741303] \tAction: [ 7.05841255] \tReward: 1.0\n",
      "TD Error: -2.83821516037 \t( 0 s)\n",
      "====================================================================Episode: 419  started\n",
      "Step 49 @ Episode 419/1000 (15.0)\n",
      "Step: 49 \tState: [ 0.54547066  2.07039989 -0.20659089 -2.09458426] \tAction: [ 3.85104012] \tReward: 1.0\n",
      "TD Error: -2.94394130707 \t( 1 s)\n",
      "====================================================================Episode: 420  started\n",
      "Step 22 @ Episode 420/1000 (50.0)\n",
      "Step: 22 \tState: [-0.05066727 -0.76126352  0.20406702  1.50426536] \tAction: [ 1.60238123] \tReward: 1.0\n",
      "TD Error: -3.67533988953 \t( 0 s)\n",
      "====================================================================Episode: 421  started\n",
      "Step 31 @ Episode 421/1000 (23.0)\n",
      "Step: 31 \tState: [ 0.15010652  0.99922004 -0.19019527 -1.48038244] \tAction: [-1.37531817] \tReward: 1.0\n",
      "TD Error: 2.92830314636 \t( 0 s)\n",
      "====================================================================Episode: 422  started\n",
      "Step 34 @ Episode 422/1000 (32.0)\n",
      "Step: 34 \tState: [ 0.24904697  1.5337408  -0.1724843  -1.9538172 ] \tAction: [-3.08331156] \tReward: 1.0\n",
      "TD Error: 7.40270404816 \t( 0 s)\n",
      "====================================================================Episode: 423  started\n",
      "Step 9 @ Episode 423/1000 (35.0)\n",
      "Step: 9 \tState: [-0.12074784 -1.41513113  0.16895313  2.15303289] \tAction: [-5.92101908] \tReward: 1.0\n",
      "TD Error: -2.79164247513 \t( 0 s)\n",
      "====================================================================Episode: 424  started\n",
      "Step 13 @ Episode 424/1000 (10.0)\n",
      "Step: 13 \tState: [ 0.095137    0.97406548 -0.17734271 -1.61790701] \tAction: [-2.95658708] \tReward: 1.0\n",
      "TD Error: 1.11616892815 \t( 0 s)\n",
      "====================================================================Episode: 425  started\n",
      "Step 17 @ Episode 425/1000 (14.0)\n",
      "Step: 17 \tState: [ 0.14004983  0.21370496 -0.20182751 -0.6330485 ] \tAction: [-4.57620192] \tReward: 1.0\n",
      "TD Error: -2.27636413574 \t( 0 s)\n",
      "====================================================================Episode: 426  started\n",
      "Step 16 @ Episode 426/1000 (18.0)\n",
      "Step: 16 \tState: [-0.14052838 -0.78978839  0.1961905   1.28394522] \tAction: [-5.01732302] \tReward: 1.0\n",
      "TD Error: -0.316284227371 \t( 0 s)\n",
      "====================================================================Episode: 427  started\n",
      "Step 23 @ Episode 427/1000 (17.0)\n",
      "Step: 23 \tState: [-0.11111488 -0.56254051  0.19231656  1.31743907] \tAction: [ 10.57873058] \tReward: 1.0\n",
      "TD Error: 3.76203079224 \t( 0 s)\n",
      "====================================================================Episode: 428  started\n",
      "Step 10 @ Episode 428/1000 (24.0)\n",
      "Step: 10 \tState: [ 0.06817097  0.77321517 -0.195371   -1.39265623] \tAction: [ 0.71897578] \tReward: 1.0\n",
      "TD Error: -9.42830066681 \t( 0 s)\n",
      "====================================================================Episode: 429  started\n",
      "Step 12 @ Episode 429/1000 (11.0)\n",
      "Step: 12 \tState: [-0.09501855 -0.38331797  0.20640771  0.87342445] \tAction: [-0.83623856] \tReward: 1.0\n",
      "TD Error: 3.14235687256 \t( 0 s)\n",
      "====================================================================Episode: 430  started\n",
      "Step 18 @ Episode 430/1000 (13.0)\n",
      "Step: 18 \tState: [ 0.05053979  0.81605825 -0.18861914 -1.57351871] \tAction: [-1.35685468] \tReward: 1.0\n",
      "TD Error: -10.823879528 \t( 0 s)\n",
      "====================================================================Episode: 431  started\n",
      "Step 21 @ Episode 431/1000 (19.0)\n",
      "Step: 21 \tState: [ 0.07373392  0.19109598 -0.19392613 -0.8164864 ] \tAction: [ 1.98876441] \tReward: 1.0\n",
      "TD Error: -0.987842941284 \t( 0 s)\n",
      "====================================================================Episode: 432  started\n",
      "Step 18 @ Episode 432/1000 (22.0)\n",
      "Step: 18 \tState: [-0.08140371 -0.42974247  0.19209644  1.07801404] \tAction: [ 0.2539551] \tReward: 1.0\n",
      "TD Error: 1.31454825401 \t( 0 s)\n",
      "====================================================================Episode: 433  started\n",
      "Step 11 @ Episode 433/1000 (19.0)\n",
      "Step: 11 \tState: [-0.12061685 -0.20469905  0.19940717  0.63624624] \tAction: [ 1.64437747] \tReward: 1.0\n",
      "TD Error: -1.18196659088 \t( 0 s)\n",
      "====================================================================Episode: 434  started\n",
      "Step 41 @ Episode 434/1000 (12.0)\n",
      "Step: 41 \tState: [ 0.00432099 -0.58939994  0.20200987  1.51957678] \tAction: [-7.19226074] \tReward: 1.0\n",
      "TD Error: -3.18178358078 \t( 1 s)\n",
      "====================================================================Episode: 435  started\n",
      "Step 10 @ Episode 435/1000 (42.0)\n",
      "Step: 10 \tState: [-0.12705073 -1.18126292  0.18068042  1.86132404] \tAction: [ 4.43553257] \tReward: 1.0\n",
      "TD Error: -3.1246383667 \t( 0 s)\n",
      "====================================================================Episode: 436  started\n",
      "Step 37 @ Episode 436/1000 (11.0)\n",
      "Step: 37 \tState: [-0.20415004 -1.38930433  0.19950261  1.90512669] \tAction: [-6.22487974] \tReward: 1.0\n",
      "TD Error: -3.88320741653 \t( 1 s)\n",
      "====================================================================Episode: 437  started\n",
      "Step 26 @ Episode 437/1000 (38.0)\n",
      "Step: 26 \tState: [-0.01562103 -0.01371005  0.20703748  0.47454008] \tAction: [ 4.93067884] \tReward: 1.0\n",
      "TD Error: 0.574042725563 \t( 0 s)\n",
      "====================================================================Episode: 438  started\n",
      "Step 47 @ Episode 438/1000 (27.0)\n",
      "Step: 47 \tState: [-0.24265158 -0.4958132  -0.19052842 -1.00879438] \tAction: [-1.45149016] \tReward: 1.0\n",
      "TD Error: -2.508406353 \t( 1 s)\n",
      "====================================================================Episode: 439  started\n",
      "Step 39 @ Episode 439/1000 (48.0)\n",
      "Step: 39 \tState: [-0.03534625  0.11335966  0.20038049  0.80498797] \tAction: [-5.24647236] \tReward: 1.0\n",
      "TD Error: -1.13881540298 \t( 1 s)\n",
      "====================================================================Episode: 440  started\n",
      "Step 12 @ Episode 440/1000 (40.0)\n",
      "Step: 12 \tState: [-0.11015273 -0.80919377  0.19751405  1.48174356] \tAction: [-1.303177] \tReward: 1.0\n",
      "TD Error: -1.82964515686 \t( 0 s)\n",
      "====================================================================Episode: 441  started\n",
      "Step 12 @ Episode 441/1000 (13.0)\n",
      "Step: 12 \tState: [-0.08694778 -1.15259878  0.20238353  1.97645705] \tAction: [-1.31855798] \tReward: 1.0\n",
      "TD Error: -0.534751272202 \t( 0 s)\n",
      "====================================================================Episode: 442  started\n",
      "Step 10 @ Episode 442/1000 (13.0)\n",
      "Step: 10 \tState: [ 0.13906991  0.429133   -0.19872049 -0.91844738] \tAction: [ 9.64853764] \tReward: 1.0\n",
      "TD Error: -3.5574965477 \t( 0 s)\n",
      "====================================================================Episode: 443  started\n",
      "Step 8 @ Episode 443/1000 (11.0)\n",
      "Step: 8 \tState: [ 0.07627912  0.7769502  -0.19705424 -1.38944749] \tAction: [ 1.14397132] \tReward: 1.0\n",
      "TD Error: -5.87538166046 \t( 0 s)\n",
      "====================================================================Episode: 444  started\n",
      "Step 30 @ Episode 444/1000 (9.0)\n",
      "Step: 30 \tState: [ 0.29840323  1.14353131 -0.19116312 -1.23955562] \tAction: [-2.66957545] \tReward: 1.0\n",
      "TD Error: -3.71125115156 \t( 0 s)\n",
      "====================================================================Episode: 445  started\n",
      "Step 34 @ Episode 445/1000 (31.0)\n",
      "Step: 34 \tState: [-0.22591899 -0.81660374  0.20440999  1.12703712] \tAction: [-1.40839827] \tReward: 1.0\n",
      "TD Error: -3.75411939621 \t( 0 s)\n",
      "====================================================================Episode: 446  started\n",
      "Step 33 @ Episode 446/1000 (35.0)\n",
      "Step: 33 \tState: [-0.12280767 -0.17796103 -0.20789023 -0.83213877] \tAction: [ 3.91566896] \tReward: 1.0\n",
      "TD Error: -0.357847213745 \t( 0 s)\n",
      "====================================================================Episode: 447  started\n",
      "Step 15 @ Episode 447/1000 (34.0)\n",
      "Step: 15 \tState: [ 0.13553589  0.95798692 -0.20303824 -1.57056954] \tAction: [-0.69145644] \tReward: 1.0\n",
      "TD Error: 0.700998497009 \t( 0 s)\n",
      "====================================================================Episode: 448  started\n",
      "Step 23 @ Episode 448/1000 (16.0)\n",
      "Step: 23 \tState: [-0.07384131 -0.24386568  0.20423574  0.9923262 ] \tAction: [ 8.42275143] \tReward: 1.0\n",
      "TD Error: -0.673834300041 \t( 0 s)\n",
      "====================================================================Episode: 449  started\n",
      "Step 15 @ Episode 449/1000 (24.0)\n",
      "Step: 15 \tState: [-0.09062446 -0.5762922   0.20338333  1.27140828] \tAction: [ 3.23967481] \tReward: 1.0\n",
      "TD Error: -0.734536743164 \t( 0 s)\n",
      "====================================================================Episode: 450  started\n",
      "Step 14 @ Episode 450/1000 (16.0)\n",
      "Step: 14 \tState: [-0.05604348 -1.17111366  0.17412265  1.9227992 ] \tAction: [-9.90231133] \tReward: 1.0\n",
      "TD Error: -0.963553237915 \t( 0 s)\n",
      "====================================================================Episode: 451  started\n",
      "Step 8 @ Episode 451/1000 (15.0)\n",
      "Step: 8 \tState: [-0.07247432 -1.13408788  0.18152538  1.88787653] \tAction: [ 6.94842768] \tReward: 1.0\n",
      "TD Error: 3.50084247589 \t( 0 s)\n",
      "====================================================================Episode: 452  started\n",
      "Step 15 @ Episode 452/1000 (9.0)\n",
      "Step: 15 \tState: [-0.10572362 -0.62396863  0.20316834  1.2505074 ] \tAction: [ 5.08560658] \tReward: 1.0\n",
      "TD Error: 6.63175048828 \t( 0 s)\n",
      "====================================================================Episode: 453  started\n",
      "Step 14 @ Episode 453/1000 (16.0)\n",
      "Step: 14 \tState: [-0.09344823 -1.53194566  0.18477356  2.44871186] \tAction: [-4.7720809] \tReward: 1.0\n",
      "TD Error: 6.47532272339 \t( 0 s)\n",
      "====================================================================Episode: 454  started\n",
      "Step 16 @ Episode 454/1000 (15.0)\n",
      "Step: 16 \tState: [ 0.14075728  0.37084287 -0.20577499 -0.90944994] \tAction: [-2.06757593] \tReward: 1.0\n",
      "TD Error: 3.39812469482 \t( 0 s)\n",
      "====================================================================Episode: 455  started\n",
      "Step 35 @ Episode 455/1000 (17.0)\n",
      "Step: 35 \tState: [-0.13516215 -1.32245167  0.18361235  2.01535944] \tAction: [-4.25186825] \tReward: 1.0\n",
      "TD Error: 1.38329901397 \t( 0 s)\n",
      "====================================================================Episode: 456  started\n",
      "Step 11 @ Episode 456/1000 (36.0)\n",
      "Step: 11 \tState: [-0.17890167 -1.32710457  0.20267745  2.2068704 ] \tAction: [ 0.35406747] \tReward: 1.0\n",
      "TD Error: 2.62394350767 \t( 0 s)\n",
      "====================================================================Episode: 457  started\n",
      "Step 56 @ Episode 457/1000 (12.0)\n",
      "Step: 56 \tState: [-0.30143378 -0.67733246 -0.205954   -0.30715134] \tAction: [ 2.73637176] \tReward: 1.0\n",
      "TD Error: 2.67026834488 \t( 1 s)\n",
      "====================================================================Episode: 458  started\n",
      "Step 13 @ Episode 458/1000 (57.0)\n",
      "Step: 13 \tState: [-0.14134234 -1.32881747  0.19604964  2.15091162] \tAction: [-3.9915278] \tReward: 1.0\n",
      "TD Error: 0.806810355186 \t( 0 s)\n",
      "====================================================================Episode: 459  started\n",
      "Step 25 @ Episode 459/1000 (14.0)\n",
      "Step: 25 \tState: [-0.09307145 -0.2473233   0.1984812   0.74967118] \tAction: [-3.80993533] \tReward: 1.0\n",
      "TD Error: -2.47696762085 \t( 0 s)\n",
      "====================================================================Episode: 460  started\n",
      "Step 48 @ Episode 460/1000 (26.0)\n",
      "Step: 48 \tState: [-0.36339903 -1.49297566  0.18491479  1.81218098] \tAction: [ 0.37519443] \tReward: 1.0\n",
      "TD Error: -3.80249919891 \t( 1 s)\n",
      "====================================================================Episode: 461  started\n",
      "Step 17 @ Episode 461/1000 (49.0)\n",
      "Step: 17 \tState: [-0.1926675  -1.00507259  0.19793718  1.66033275] \tAction: [-3.48079371] \tReward: 1.0\n",
      "TD Error: -3.89741125107 \t( 0 s)\n",
      "====================================================================Episode: 462  started\n",
      "Step 20 @ Episode 462/1000 (18.0)\n",
      "Step: 20 \tState: [-0.04122536 -0.37929649  0.2042464   1.07972527] \tAction: [-10.10808277] \tReward: 1.0\n",
      "TD Error: -3.238301754 \t( 0 s)\n",
      "====================================================================Episode: 463  started\n",
      "Step 10 @ Episode 463/1000 (21.0)\n",
      "Step: 10 \tState: [-0.15900675 -1.52167691  0.19530467  2.52433932] \tAction: [ 3.74402165] \tReward: 1.0\n",
      "TD Error: -6.49378995895 \t( 0 s)\n",
      "====================================================================Episode: 464  started\n",
      "Step 16 @ Episode 464/1000 (11.0)\n",
      "Step: 16 \tState: [ 0.06672398  0.78062435 -0.18318259 -1.58811086] \tAction: [ 2.69409657] \tReward: 1.0\n",
      "TD Error: -0.510252949595 \t( 0 s)\n",
      "====================================================================Episode: 465  started\n",
      "Step 24 @ Episode 465/1000 (17.0)\n",
      "Step: 24 \tState: [ 0.02872084  0.77331581 -0.19114195 -1.472511  ] \tAction: [ 2.0473063] \tReward: 1.0\n",
      "TD Error: -0.715975141525 \t( 0 s)\n",
      "====================================================================Episode: 466  started\n",
      "Step 11 @ Episode 466/1000 (25.0)\n",
      "Step: 11 \tState: [ 0.1404785   0.61896202 -0.19375248 -1.13202337] \tAction: [ 5.62633848] \tReward: 1.0\n",
      "TD Error: 0.881053686142 \t( 0 s)\n",
      "====================================================================Episode: 467  started\n",
      "Step 19 @ Episode 467/1000 (12.0)\n",
      "Step: 19 \tState: [ 0.08907647  0.16845587 -0.20835037 -0.81694648] \tAction: [ 0.45500112] \tReward: 1.0\n",
      "TD Error: 0.528602600098 \t( 0 s)\n",
      "====================================================================Episode: 468  started\n",
      "Step 18 @ Episode 468/1000 (20.0)\n",
      "Step: 18 \tState: [ 0.07800156  0.01948666 -0.20297559 -0.58574118] \tAction: [ 2.29277945] \tReward: 1.0\n",
      "TD Error: -0.566125488281 \t( 0 s)\n",
      "====================================================================Episode: 469  started\n",
      "Step 26 @ Episode 469/1000 (19.0)\n",
      "Step: 26 \tState: [-0.1018097  -0.39847524  0.19690403  0.88153551] \tAction: [-6.03606939] \tReward: 1.0\n",
      "TD Error: -1.38480188847 \t( 0 s)\n",
      "====================================================================Episode: 470  started\n",
      "Step 32 @ Episode 470/1000 (27.0)\n",
      "Step: 32 \tState: [ 0.10655     0.44173927 -0.19339741 -0.91372522] \tAction: [-4.14152861] \tReward: 1.0\n",
      "TD Error: -1.90031051636 \t( 0 s)\n",
      "====================================================================Episode: 471  started\n",
      "Step 65 @ Episode 471/1000 (33.0)\n",
      "Step: 65 \tState: [ 0.0713719  -0.94187432  0.19598968  1.81126278] \tAction: [-2.29441643] \tReward: 1.0\n",
      "TD Error: -3.03940253258 \t( 1 s)\n",
      "====================================================================Episode: 472  started\n",
      "Step 15 @ Episode 472/1000 (66.0)\n",
      "Step: 15 \tState: [ 0.16835303  0.64710186 -0.19186362 -1.21653872] \tAction: [-3.34644866] \tReward: 1.0\n",
      "TD Error: -2.25668468475 \t( 0 s)\n",
      "====================================================================Episode: 473  started\n",
      "Step 52 @ Episode 473/1000 (16.0)\n",
      "Step: 52 \tState: [-0.34165149 -1.56394435  0.19483109  1.83088391] \tAction: [-11.4646759] \tReward: 1.0\n",
      "TD Error: 1.44777507782 \t( 1 s)\n",
      "====================================================================Episode: 474  started\n",
      "Step 47 @ Episode 474/1000 (53.0)\n",
      "Step: 47 \tState: [-0.12315304  0.2462848  -0.20097119 -1.22174148] \tAction: [ 4.62152147] \tReward: 1.0\n",
      "TD Error: -1.77545518875 \t( 1 s)\n",
      "====================================================================Episode: 475  started\n",
      "Step 11 @ Episode 475/1000 (48.0)\n",
      "Step: 11 \tState: [-0.10012829 -1.35256812  0.20035886  2.29443562] \tAction: [ 0.53591794] \tReward: 1.0\n",
      "TD Error: 6.88575611115 \t( 0 s)\n",
      "====================================================================Episode: 476  started\n",
      "Step 14 @ Episode 476/1000 (12.0)\n",
      "Step: 14 \tState: [-0.12038593 -0.76784386  0.19841813  1.45592963] \tAction: [-1.52647388] \tReward: 1.0\n",
      "TD Error: 4.56403369904 \t( 0 s)\n",
      "====================================================================Episode: 477  started\n",
      "Step 22 @ Episode 477/1000 (15.0)\n",
      "Step: 22 \tState: [-0.1864424  -1.56768602  0.17113411  2.08958992] \tAction: [-4.39749622] \tReward: 1.0\n",
      "TD Error: 3.37406153679 \t( 0 s)\n",
      "====================================================================Episode: 478  started\n",
      "Step 22 @ Episode 478/1000 (23.0)\n",
      "Step: 22 \tState: [ 0.06130031  1.16215527 -0.20707779 -2.04572282] \tAction: [-11.85203838] \tReward: 1.0\n",
      "TD Error: -2.20764673948 \t( 0 s)\n",
      "====================================================================Episode: 479  started\n",
      "Step 34 @ Episode 479/1000 (23.0)\n",
      "Step: 34 \tState: [ 0.19942666  1.52318018 -0.19225766 -2.0000128 ] \tAction: [ 0.42752782] \tReward: 1.0\n",
      "TD Error: -0.335954713821 \t( 0 s)\n",
      "====================================================================Episode: 480  started\n",
      "Step 18 @ Episode 480/1000 (35.0)\n",
      "Step: 18 \tState: [-0.10176031 -1.1519894   0.19587107  2.02049404] \tAction: [-0.73291433] \tReward: 1.0\n",
      "TD Error: -7.03238973618 \t( 0 s)\n",
      "====================================================================Episode: 481  started\n",
      "Step 13 @ Episode 481/1000 (19.0)\n",
      "Step: 13 \tState: [-0.1121458  -0.55501672  0.20020337  1.21903265] \tAction: [-10.89122009] \tReward: 1.0\n",
      "TD Error: -3.86407361031 \t( 0 s)\n",
      "====================================================================Episode: 482  started\n",
      "Step 30 @ Episode 482/1000 (14.0)\n",
      "Step: 30 \tState: [ 0.05190337  0.03851518 -0.20751827 -0.73042816] \tAction: [ 0.17956762] \tReward: 1.0\n",
      "TD Error: 1.4662191391 \t( 0 s)\n",
      "====================================================================Episode: 483  started\n",
      "Step 17 @ Episode 483/1000 (31.0)\n",
      "Step: 17 \tState: [-0.1521329  -0.64879185  0.20943169  1.20460333] \tAction: [ 4.79445601] \tReward: 1.0\n",
      "TD Error: 0.232060718536 \t( 0 s)\n",
      "====================================================================Episode: 484  started\n",
      "Step 12 @ Episode 484/1000 (18.0)\n",
      "Step: 12 \tState: [ 0.12944729  1.16360261 -0.20029513 -1.92758664] \tAction: [-3.66748524] \tReward: 1.0\n",
      "TD Error: 0.665309333801 \t( 0 s)\n",
      "====================================================================Episode: 485  started\n",
      "Step 12 @ Episode 485/1000 (13.0)\n",
      "Step: 12 \tState: [ 0.1983765   0.42241513 -0.20342721 -0.75971001] \tAction: [ 1.48972344] \tReward: 1.0\n",
      "TD Error: 2.39977111816 \t( 0 s)\n",
      "====================================================================Episode: 486  started\n",
      "Step 14 @ Episode 486/1000 (13.0)\n",
      "Step: 14 \tState: [ 0.10152723  0.77146949 -0.1934325  -1.4556926 ] \tAction: [-2.71539807] \tReward: 1.0\n",
      "TD Error: 2.08465237617 \t( 0 s)\n",
      "====================================================================Episode: 487  started\n",
      "Step 21 @ Episode 487/1000 (15.0)\n",
      "Step: 21 \tState: [ 0.05114852  0.6490793  -0.20162907 -1.40826689] \tAction: [ 2.73472786] \tReward: 1.0\n",
      "TD Error: -2.41762156487 \t( 0 s)\n",
      "====================================================================Episode: 488  started\n",
      "Step 14 @ Episode 488/1000 (22.0)\n",
      "Step: 14 \tState: [ 0.09398706  1.13698627 -0.17312212 -1.85658791] \tAction: [-0.78697634] \tReward: 1.0\n",
      "TD Error: -1.78016834259 \t( 0 s)\n",
      "====================================================================Episode: 489  started\n",
      "Step 13 @ Episode 489/1000 (15.0)\n",
      "Step: 13 \tState: [ 0.09912639  0.5664093  -0.20111453 -1.25832892] \tAction: [-3.04246402] \tReward: 1.0\n",
      "TD Error: -1.3858212471 \t( 0 s)\n",
      "====================================================================Episode: 490  started\n",
      "Step 32 @ Episode 490/1000 (14.0)\n",
      "Step: 32 \tState: [-0.08142528 -0.01938187  0.2022179   0.38629371] \tAction: [-2.12907124] \tReward: 1.0\n",
      "TD Error: 1.95637903214 \t( 0 s)\n",
      "====================================================================Episode: 491  started\n",
      "Step 13 @ Episode 491/1000 (33.0)\n",
      "Step: 13 \tState: [ 0.10727959  0.61850169 -0.20564612 -1.25781407] \tAction: [-3.51020002] \tReward: 1.0\n",
      "TD Error: -1.64270038605 \t( 0 s)\n",
      "====================================================================Episode: 492  started\n",
      "Step 15 @ Episode 492/1000 (14.0)\n",
      "Step: 15 \tState: [-0.09980318 -0.246684    0.208496    0.75174066] \tAction: [ 2.8033216] \tReward: 1.0\n",
      "TD Error: 2.38305587769 \t( 0 s)\n",
      "====================================================================Episode: 493  started\n",
      "Step 15 @ Episode 493/1000 (16.0)\n",
      "Step: 15 \tState: [-0.11413437 -0.96757379  0.20097849  1.70549036] \tAction: [-2.4461453] \tReward: 1.0\n",
      "TD Error: 3.48517007828 \t( 0 s)\n",
      "====================================================================Episode: 494  started\n",
      "Step 13 @ Episode 494/1000 (16.0)\n",
      "Step: 13 \tState: [ 0.10758467  0.19772455 -0.20071907 -0.73400864] \tAction: [-0.79146588] \tReward: 1.0\n",
      "TD Error: -0.894622278214 \t( 0 s)\n",
      "====================================================================Episode: 495  started\n",
      "Step 21 @ Episode 495/1000 (14.0)\n",
      "Step: 21 \tState: [-0.03447898 -0.95171699  0.19995622  1.78709024] \tAction: [ 8.03750229] \tReward: 1.0\n",
      "TD Error: 0.395623517036 \t( 0 s)\n",
      "====================================================================Episode: 496  started\n",
      "Step 12 @ Episode 496/1000 (22.0)\n",
      "Step: 12 \tState: [-0.18395381 -1.15672345  0.19611891  1.76677132] \tAction: [-2.45552969] \tReward: 1.0\n",
      "TD Error: 1.33171319962 \t( 0 s)\n",
      "====================================================================Episode: 497  started\n",
      "Step 11 @ Episode 497/1000 (13.0)\n",
      "Step: 11 \tState: [-0.14373134 -0.64241508  0.19616938  1.16086787] \tAction: [-10.77405643] \tReward: 1.0\n",
      "TD Error: -1.22428560257 \t( 0 s)\n",
      "====================================================================Episode: 498  started\n",
      "Step 14 @ Episode 498/1000 (12.0)\n",
      "Step: 14 \tState: [-0.11099652 -0.75441649  0.20348093  1.45504858] \tAction: [-0.70852238] \tReward: 1.0\n",
      "TD Error: -7.70248470306 \t( 0 s)\n",
      "====================================================================Episode: 499  started\n",
      "Step 13 @ Episode 499/1000 (15.0)\n",
      "Step: 13 \tState: [-0.13870316 -0.63438465  0.18802656  1.18891498] \tAction: [ 3.36114168] \tReward: 1.0\n",
      "TD Error: -6.64300403595 \t( 0 s)\n",
      "====================================================================Episode: 500  started\n",
      "Step 20 @ Episode 500/1000 (14.0)\n",
      "Step: 20 \tState: [-0.18688055 -0.7780567   0.19933419  1.37320877] \tAction: [ 8.24885178] \tReward: 1.0\n",
      "TD Error: -3.68086929321 \t( 0 s)\n",
      "====================================================================Episode: 501  started\n",
      "Step 11 @ Episode 501/1000 (21.0)\n",
      "Step: 11 \tState: [-0.11441145 -1.02505491  0.18601281  1.66977457] \tAction: [ 2.0632031] \tReward: 1.0\n",
      "TD Error: -0.759333610535 \t( 0 s)\n",
      "====================================================================Episode: 502  started\n",
      "Step 17 @ Episode 502/1000 (12.0)\n",
      "Step: 17 \tState: [-0.1230583  -0.22204174  0.20305972  0.7474667 ] \tAction: [-5.83622789] \tReward: 1.0\n",
      "TD Error: 2.72256317139 \t( 0 s)\n",
      "====================================================================Episode: 503  started\n",
      "Step 13 @ Episode 503/1000 (18.0)\n",
      "Step: 13 \tState: [-0.04039751 -0.94007147  0.18106924  1.72201503] \tAction: [-5.29628658] \tReward: 1.0\n",
      "TD Error: 0.795346260071 \t( 0 s)\n",
      "====================================================================Episode: 504  started\n",
      "Step 14 @ Episode 504/1000 (14.0)\n",
      "Step: 14 \tState: [-0.09071339 -0.78644722  0.19209877  1.57079009] \tAction: [ 2.70800304] \tReward: 1.0\n",
      "TD Error: -0.905023479462 \t( 0 s)\n",
      "====================================================================Episode: 505  started\n",
      "Step 31 @ Episode 505/1000 (15.0)\n",
      "Step: 31 \tState: [-0.1472038  -0.98468618  0.19218698  1.68058531] \tAction: [-6.23500204] \tReward: 1.0\n",
      "TD Error: -1.37973203659 \t( 0 s)\n",
      "====================================================================Episode: 506  started\n",
      "Step 15 @ Episode 506/1000 (32.0)\n",
      "Step: 15 \tState: [-0.07001436 -0.57783525  0.2010244   1.17506145] \tAction: [ 4.60228682] \tReward: 1.0\n",
      "TD Error: 1.33654565811 \t( 0 s)\n",
      "====================================================================Episode: 507  started\n",
      "Step 10 @ Episode 507/1000 (16.0)\n",
      "Step: 10 \tState: [-0.09165097 -1.1457333   0.19711693  1.95741605] \tAction: [ 1.94185281] \tReward: 1.0\n",
      "TD Error: 1.25154829025 \t( 0 s)\n",
      "====================================================================Episode: 508  started\n",
      "Step 18 @ Episode 508/1000 (11.0)\n",
      "Step: 18 \tState: [-0.10628116 -0.4514879   0.1920175   1.00745638] \tAction: [-12.84139156] \tReward: 1.0\n",
      "TD Error: 0.767762184143 \t( 0 s)\n",
      "====================================================================Episode: 509  started\n",
      "Step 37 @ Episode 509/1000 (19.0)\n",
      "Step: 37 \tState: [-0.00370256  0.22968813 -0.19993225 -1.12601281] \tAction: [ 5.44151068] \tReward: 1.0\n",
      "TD Error: -2.15247793198 \t( 0 s)\n",
      "====================================================================Episode: 510  started\n",
      "Step 8 @ Episode 510/1000 (38.0)\n",
      "Step: 8 \tState: [-0.08446669 -1.19514337  0.18538824  1.9610428 ] \tAction: [-0.41953123] \tReward: 1.0\n",
      "TD Error: -3.71666200161 \t( 0 s)\n",
      "====================================================================Episode: 511  started\n",
      "Step 9 @ Episode 511/1000 (9.0)\n",
      "Step: 9 \tState: [-0.07915496 -0.99314778  0.18032039  1.65104812] \tAction: [ 6.00598001] \tReward: 1.0\n",
      "TD Error: -1.41101541519 \t( 0 s)\n",
      "====================================================================Episode: 512  started\n",
      "Step 8 @ Episode 512/1000 (10.0)\n",
      "Step: 8 \tState: [-0.06615456 -1.59740738  0.18818067  2.44438242] \tAction: [ 12.45319462] \tReward: 1.0\n",
      "TD Error: 0.299540233612 \t( 0 s)\n",
      "====================================================================Episode: 513  started\n",
      "Step 11 @ Episode 513/1000 (9.0)\n",
      "Step: 11 \tState: [-0.09103949 -1.42234907  0.19924762  2.26490004] \tAction: [ 6.45197344] \tReward: 1.0\n",
      "TD Error: 2.7489528656 \t( 0 s)\n",
      "====================================================================Episode: 514  started\n",
      "Step 18 @ Episode 514/1000 (12.0)\n",
      "Step: 18 \tState: [-0.21714239 -1.17829871  0.20387796  1.87458157] \tAction: [-0.57924151] \tReward: 1.0\n",
      "TD Error: 2.20765953064 \t( 0 s)\n",
      "====================================================================Episode: 515  started\n",
      "Step 29 @ Episode 515/1000 (19.0)\n",
      "Step: 29 \tState: [ 0.01423291 -0.12127047 -0.19885224 -0.71171109] \tAction: [-0.29694787] \tReward: 1.0\n",
      "TD Error: -0.943311405182 \t( 0 s)\n",
      "====================================================================Episode: 516  started\n",
      "Step 17 @ Episode 516/1000 (30.0)\n",
      "Step: 17 \tState: [-0.04576053 -0.57596049  0.20445105  1.24779782] \tAction: [-0.38776848] \tReward: 1.0\n",
      "TD Error: -2.05567079782 \t( 0 s)\n",
      "====================================================================Episode: 517  started\n",
      "Step 13 @ Episode 517/1000 (18.0)\n",
      "Step: 13 \tState: [-0.10920293 -0.5823534   0.20899049  1.20131263] \tAction: [ 7.09226227] \tReward: 1.0\n",
      "TD Error: -0.872141218185 \t( 0 s)\n",
      "====================================================================Episode: 518  started\n",
      "Step 13 @ Episode 518/1000 (14.0)\n",
      "Step: 13 \tState: [ 0.1548926   1.00924412 -0.20343112 -1.80970913] \tAction: [ 2.83890533] \tReward: 1.0\n",
      "TD Error: -4.23390083313 \t( 0 s)\n",
      "====================================================================Episode: 519  started\n",
      "Step 23 @ Episode 519/1000 (14.0)\n",
      "Step: 23 \tState: [ 0.14739497  0.61322267 -0.20021416 -1.31793277] \tAction: [-3.77196026] \tReward: 1.0\n",
      "TD Error: -0.70927324295 \t( 0 s)\n",
      "====================================================================Episode: 520  started\n",
      "Step 10 @ Episode 520/1000 (24.0)\n",
      "Step: 10 \tState: [-0.17777664 -1.21926796  0.1953      1.92295643] \tAction: [-0.17581026] \tReward: 1.0\n",
      "TD Error: -3.61519930363 \t( 0 s)\n",
      "====================================================================Episode: 521  started\n",
      "Step 41 @ Episode 521/1000 (11.0)\n",
      "Step: 41 \tState: [-0.17760768 -0.58436807  0.20361762  1.23490046] \tAction: [ 0.89589572] \tReward: 1.0\n",
      "TD Error: -2.22290539742 \t( 0 s)\n",
      "====================================================================Episode: 522  started\n",
      "Step 9 @ Episode 522/1000 (42.0)\n",
      "Step: 9 \tState: [ 0.1759999   1.40777243 -0.19711125 -2.19200058] \tAction: [ 2.40416908] \tReward: 1.0\n",
      "TD Error: -3.67027578354 \t( 0 s)\n",
      "====================================================================Episode: 523  started\n",
      "Step 24 @ Episode 523/1000 (10.0)\n",
      "Step: 24 \tState: [-0.08609407 -0.75696476  0.19541571  1.46888463] \tAction: [ 7.08545017] \tReward: 1.0\n",
      "TD Error: -2.56749982834 \t( 0 s)\n",
      "====================================================================Episode: 524  started\n",
      "Step 18 @ Episode 524/1000 (25.0)\n",
      "Step: 18 \tState: [-0.16903025 -0.44145542  0.19636578  0.88984893] \tAction: [ 5.18482208] \tReward: 1.0\n",
      "TD Error: 0.47828578949 \t( 0 s)\n",
      "====================================================================Episode: 525  started\n",
      "Step 12 @ Episode 525/1000 (19.0)\n",
      "Step: 12 \tState: [-0.04264353 -0.76209971  0.20892698  1.50086117] \tAction: [ 7.59076214] \tReward: 1.0\n",
      "TD Error: 3.33542957306 \t( 0 s)\n",
      "====================================================================Episode: 526  started\n",
      "Step 31 @ Episode 526/1000 (13.0)\n",
      "Step: 31 \tState: [-0.06233737 -0.9821095   0.18998883  1.9034801 ] \tAction: [-0.34296119] \tReward: 1.0\n",
      "TD Error: 1.89764289856 \t( 0 s)\n",
      "====================================================================Episode: 527  started\n",
      "Step 15 @ Episode 527/1000 (32.0)\n",
      "Step: 15 \tState: [-0.06682108 -0.96981515  0.20097849  1.81011605] \tAction: [-1.80359769] \tReward: 1.0\n",
      "TD Error: 6.76795845032 \t( 0 s)\n",
      "====================================================================Episode: 528  started\n",
      "Step 24 @ Episode 528/1000 (16.0)\n",
      "Step: 24 \tState: [-0.10729175  0.01596021  0.20272706  0.56349883] \tAction: [ 3.94249105] \tReward: 1.0\n",
      "TD Error: 2.93550987244 \t( 0 s)\n",
      "====================================================================Episode: 529  started\n",
      "Step 32 @ Episode 529/1000 (25.0)\n",
      "Step: 32 \tState: [ 0.25660701  1.11027664 -0.19246812 -1.48270164] \tAction: [-6.44334221] \tReward: 1.0\n",
      "TD Error: 3.92797813416 \t( 0 s)\n",
      "====================================================================Episode: 530  started\n",
      "Step 15 @ Episode 530/1000 (33.0)\n",
      "Step: 15 \tState: [-0.1170859  -0.60284006  0.19300379  1.21055136] \tAction: [ 0.12766293] \tReward: 1.0\n",
      "TD Error: -4.904702425 \t( 0 s)\n",
      "====================================================================Episode: 531  started\n",
      "Step 28 @ Episode 531/1000 (16.0)\n",
      "Step: 28 \tState: [ 0.14608111  0.38214296 -0.19779284 -0.81044515] \tAction: [-4.16034174] \tReward: 1.0\n",
      "TD Error: 6.64033889771 \t( 0 s)\n",
      "====================================================================Episode: 532  started\n",
      "Step 31 @ Episode 532/1000 (29.0)\n",
      "Step: 31 \tState: [-0.15202034 -0.93555026  0.20425412  1.62493818] \tAction: [-4.66006422] \tReward: 1.0\n",
      "TD Error: -3.30264101028 \t( 1 s)\n",
      "====================================================================Episode: 533  started\n",
      "Step 19 @ Episode 533/1000 (32.0)\n",
      "Step: 19 \tState: [ 0.04462554  0.19388044 -0.19484978 -0.8705081 ] \tAction: [-0.13457675] \tReward: 1.0\n",
      "TD Error: 2.15131697655 \t( 0 s)\n",
      "====================================================================Episode: 534  started\n",
      "Step 34 @ Episode 534/1000 (20.0)\n",
      "Step: 34 \tState: [-0.03560969  0.00957805  0.20254713  0.63185359] \tAction: [-6.59565306] \tReward: 1.0\n",
      "TD Error: 4.51905670166 \t( 0 s)\n",
      "====================================================================Episode: 535  started\n",
      "Step 11 @ Episode 535/1000 (35.0)\n",
      "Step: 11 \tState: [-0.10018693 -0.95145438  0.20072348  1.6940032 ] \tAction: [-1.59131372] \tReward: 1.0\n",
      "TD Error: 8.15228424072 \t( 0 s)\n",
      "====================================================================Episode: 536  started\n",
      "Step 18 @ Episode 536/1000 (12.0)\n",
      "Step: 18 \tState: [ 0.19184439  1.56685192 -0.17514945 -2.30592542] \tAction: [-0.24837525] \tReward: 1.0\n",
      "TD Error: 2.87614098787 \t( 0 s)\n",
      "====================================================================Episode: 537  started\n",
      "Step 16 @ Episode 537/1000 (19.0)\n",
      "Step: 16 \tState: [-0.12104577 -1.22937804  0.19596126  2.04510631] \tAction: [ 5.82765579] \tReward: 1.0\n",
      "TD Error: 2.26033735275 \t( 0 s)\n",
      "====================================================================Episode: 538  started\n",
      "Step 39 @ Episode 538/1000 (17.0)\n",
      "Step: 39 \tState: [-0.32081731 -1.34403349  0.19572838  1.67428738] \tAction: [-9.83872986] \tReward: 1.0\n",
      "TD Error: 3.92049283981 \t( 1 s)\n",
      "====================================================================Episode: 539  started\n",
      "Step 9 @ Episode 539/1000 (40.0)\n",
      "Step: 9 \tState: [-0.07516697 -0.94608042  0.18660308  1.60663831] \tAction: [ 4.94076967] \tReward: 1.0\n",
      "TD Error: 5.12348451614 \t( 0 s)\n",
      "====================================================================Episode: 540  started\n",
      "Step 16 @ Episode 540/1000 (10.0)\n",
      "Step: 16 \tState: [-0.12436503 -1.16835896  0.19935234  2.01460325] \tAction: [-0.63812006] \tReward: 1.0\n",
      "TD Error: 2.82413568497 \t( 0 s)\n",
      "====================================================================Episode: 541  started\n",
      "Step 11 @ Episode 541/1000 (17.0)\n",
      "Step: 11 \tState: [-0.13062323 -1.00257524  0.1847084   1.67328098] \tAction: [ 7.40616894] \tReward: 1.0\n",
      "TD Error: -1.47193069458 \t( 0 s)\n",
      "====================================================================Episode: 542  started\n",
      "Step 16 @ Episode 542/1000 (12.0)\n",
      "Step: 16 \tState: [-0.08549802 -0.7447597   0.20172674  1.46490024] \tAction: [ 6.20302773] \tReward: 1.0\n",
      "TD Error: -7.09263267517 \t( 0 s)\n",
      "====================================================================Episode: 543  started\n",
      "Step 45 @ Episode 543/1000 (17.0)\n",
      "Step: 45 \tState: [-0.06764023  0.18243759 -0.20781096 -0.94300889] \tAction: [-2.05400991] \tReward: 1.0\n",
      "TD Error: -0.0848507881165 \t( 1 s)\n",
      "====================================================================Episode: 544  started\n",
      "Step 12 @ Episode 544/1000 (46.0)\n",
      "Step: 12 \tState: [ 0.08333599  1.60816499 -0.1880432  -2.4633638 ] \tAction: [ 3.48128152] \tReward: 1.0\n",
      "TD Error: -1.29392967224 \t( 0 s)\n",
      "====================================================================Episode: 545  started\n",
      "Step 15 @ Episode 545/1000 (13.0)\n",
      "Step: 15 \tState: [-0.1689445  -0.54434039  0.19296563  1.04035944] \tAction: [-0.16522965] \tReward: 1.0\n",
      "TD Error: -4.16786413193 \t( 0 s)\n",
      "====================================================================Episode: 546  started\n",
      "Step 10 @ Episode 546/1000 (16.0)\n",
      "Step: 10 \tState: [-0.19678636 -0.82128605  0.20607946  1.32485279] \tAction: [-3.635952] \tReward: 1.0\n",
      "TD Error: -4.82773780823 \t( 0 s)\n",
      "====================================================================Episode: 547  started\n",
      "Step 28 @ Episode 547/1000 (11.0)\n",
      "Step: 28 \tState: [ 0.05113654 -0.39384618 -0.20865857 -0.2658759 ] \tAction: [ 0.76741636] \tReward: 1.0\n",
      "TD Error: -1.70277862549 \t( 0 s)\n",
      "====================================================================Episode: 548  started\n",
      "Step 20 @ Episode 548/1000 (29.0)\n",
      "Step: 20 \tState: [-0.11497245 -0.80829514  0.1901779   1.35842311] \tAction: [-13.78898811] \tReward: 1.0\n",
      "TD Error: -1.36526403427 \t( 0 s)\n",
      "====================================================================Episode: 549  started\n",
      "Step 33 @ Episode 549/1000 (21.0)\n",
      "Step: 33 \tState: [-0.17550593 -1.03121595  0.19831424  1.74757336] \tAction: [-4.15970898] \tReward: 1.0\n",
      "TD Error: -0.0291661739349 \t( 0 s)\n",
      "====================================================================Episode: 550  started\n",
      "Step 11 @ Episode 550/1000 (34.0)\n",
      "Step: 11 \tState: [-0.09532671 -0.97069233  0.19557296  1.65572303] \tAction: [-8.80555916] \tReward: 1.0\n",
      "TD Error: 1.0152557373 \t( 0 s)\n",
      "====================================================================Episode: 551  started\n",
      "Step 18 @ Episode 551/1000 (12.0)\n",
      "Step: 18 \tState: [-0.16611831 -0.76941299  0.20750945  1.47233697] \tAction: [ 0.48024955] \tReward: 1.0\n",
      "TD Error: 1.41381864548 \t( 0 s)\n",
      "====================================================================Episode: 552  started\n",
      "Step 9 @ Episode 552/1000 (19.0)\n",
      "Step: 9 \tState: [ 0.1239148   0.98057174 -0.20178849 -1.60212127] \tAction: [ 4.5449481] \tReward: 1.0\n",
      "TD Error: -5.24786157608 \t( 0 s)\n",
      "====================================================================Episode: 553  started\n",
      "Step 11 @ Episode 553/1000 (10.0)\n",
      "Step: 11 \tState: [ 0.11102193  0.97190177 -0.18008683 -1.60930488] \tAction: [-0.11289489] \tReward: 1.0\n",
      "TD Error: -5.55918388367 \t( 0 s)\n",
      "====================================================================Episode: 554  started\n",
      "Step 20 @ Episode 554/1000 (12.0)\n",
      "Step: 20 \tState: [ 0.07120794  1.12799686 -0.18420977 -1.90372027] \tAction: [ 2.80227566] \tReward: 1.0\n",
      "TD Error: -6.27011680603 \t( 0 s)\n",
      "====================================================================Episode: 555  started\n",
      "Step 17 @ Episode 555/1000 (21.0)\n",
      "Step: 17 \tState: [-0.093971   -0.20985692  0.20780865  0.90498176] \tAction: [-2.42252851] \tReward: 1.0\n",
      "TD Error: -0.0181805372238 \t( 0 s)\n",
      "====================================================================Episode: 556  started\n",
      "Step 9 @ Episode 556/1000 (18.0)\n",
      "Step: 9 \tState: [ 0.13450943  0.96848196 -0.18572333 -1.65588808] \tAction: [-7.58016443] \tReward: 1.0\n",
      "TD Error: -1.00912300348 \t( 0 s)\n",
      "====================================================================Episode: 557  started\n",
      "Step 22 @ Episode 557/1000 (10.0)\n",
      "Step: 22 \tState: [ 0.05114284  0.08465135 -0.20626399 -0.93401405] \tAction: [-2.06559825] \tReward: 1.0\n",
      "TD Error: -1.08294689655 \t( 0 s)\n",
      "====================================================================Episode: 558  started\n",
      "Step 14 @ Episode 558/1000 (23.0)\n",
      "Step: 14 \tState: [-0.16484551 -0.3747419   0.20850589  0.88993657] \tAction: [ 2.3523984] \tReward: 1.0\n",
      "TD Error: -0.585990726948 \t( 0 s)\n",
      "====================================================================Episode: 559  started\n",
      "Step 17 @ Episode 559/1000 (15.0)\n",
      "Step: 17 \tState: [-0.10745073 -0.17506847  0.20370697  0.76315071] \tAction: [-2.11983633] \tReward: 1.0\n",
      "TD Error: -0.940661799908 \t( 0 s)\n",
      "====================================================================Episode: 560  started\n",
      "Step 18 @ Episode 560/1000 (18.0)\n",
      "Step: 18 \tState: [-0.04663564 -0.3757552   0.20259546  1.00704371] \tAction: [ 8.82551861] \tReward: 1.0\n",
      "TD Error: -2.02748155594 \t( 0 s)\n",
      "====================================================================Episode: 561  started\n",
      "Step 17 @ Episode 561/1000 (19.0)\n",
      "Step: 17 \tState: [ 0.1020955   0.26103475 -0.19913401 -0.72338032] \tAction: [ 2.98091054] \tReward: 1.0\n",
      "TD Error: -1.1907702446 \t( 0 s)\n",
      "====================================================================Episode: 562  started\n",
      "Step 21 @ Episode 562/1000 (18.0)\n",
      "Step: 21 \tState: [ 0.12857335  0.97948268 -0.20524397 -1.57515764] \tAction: [-0.33876181] \tReward: 1.0\n",
      "TD Error: -5.07344441414 \t( 0 s)\n",
      "====================================================================Episode: 563  started\n",
      "Step 10 @ Episode 563/1000 (22.0)\n",
      "Step: 10 \tState: [-0.12200634 -0.44045462  0.203661    0.90452425] \tAction: [ 8.7835474] \tReward: 1.0\n",
      "TD Error: -1.13422822952 \t( 0 s)\n",
      "====================================================================Episode: 564  started\n",
      "Step 29 @ Episode 564/1000 (11.0)\n",
      "Step: 29 \tState: [ 0.03973924 -0.20601133 -0.20754913 -0.29367774] \tAction: [ 6.09800148] \tReward: 1.0\n",
      "TD Error: -0.210255002975 \t( 0 s)\n",
      "====================================================================Episode: 565  started\n",
      "Step 26 @ Episode 565/1000 (30.0)\n",
      "Step: 26 \tState: [-0.07099761 -0.39217953  0.19272989  1.05066463] \tAction: [ 1.14622819] \tReward: 1.0\n",
      "TD Error: -0.408555555344 \t( 0 s)\n",
      "====================================================================Episode: 566  started\n",
      "Step 16 @ Episode 566/1000 (27.0)\n",
      "Step: 16 \tState: [-0.14276134 -0.83349269  0.208864    1.38676194] \tAction: [ 1.8543092] \tReward: 1.0\n",
      "TD Error: 2.29045591354 \t( 0 s)\n",
      "====================================================================Episode: 567  started\n",
      "Step 25 @ Episode 567/1000 (17.0)\n",
      "Step: 25 \tState: [-0.09135066 -0.98323615  0.20926826  1.81071418] \tAction: [ 4.2770257] \tReward: 1.0\n",
      "TD Error: 0.812492084503 \t( 0 s)\n",
      "====================================================================Episode: 568  started\n",
      "Step 16 @ Episode 568/1000 (26.0)\n",
      "Step: 16 \tState: [-0.13133099 -1.19794297  0.17772009  1.7168203 ] \tAction: [ 4.48445892] \tReward: 1.0\n",
      "TD Error: -0.301585578918 \t( 0 s)\n",
      "====================================================================Episode: 569  started\n",
      "Step 17 @ Episode 569/1000 (17.0)\n",
      "Step: 17 \tState: [-0.08849272 -1.02709382  0.19357738  1.80696922] \tAction: [ 8.24452496] \tReward: 1.0\n",
      "TD Error: -1.13338594437 \t( 0 s)\n",
      "====================================================================Episode: 570  started\n",
      "Step 19 @ Episode 570/1000 (18.0)\n",
      "Step: 19 \tState: [-0.12825839 -0.99315623  0.19305405  1.63131596] \tAction: [-5.01442194] \tReward: 1.0\n",
      "TD Error: -1.34756546021 \t( 0 s)\n",
      "====================================================================Episode: 571  started\n",
      "Step 12 @ Episode 571/1000 (20.0)\n",
      "Step: 12 \tState: [-0.16014028 -1.57730425  0.1730329   2.34458732] \tAction: [ 5.58672762] \tReward: 1.0\n",
      "TD Error: -2.06683344841 \t( 0 s)\n",
      "====================================================================Episode: 572  started\n",
      "Step 11 @ Episode 572/1000 (13.0)\n",
      "Step: 11 \tState: [-0.13426194 -1.01847729  0.18055215  1.73927488] \tAction: [ 12.1379118] \tReward: 1.0\n",
      "TD Error: -1.57115712166 \t( 0 s)\n",
      "====================================================================Episode: 573  started\n",
      "Step 44 @ Episode 573/1000 (12.0)\n",
      "Step: 44 \tState: [-0.08150084 -0.78396502  0.19188474  1.43693085] \tAction: [ 6.84633827] \tReward: 1.0\n",
      "TD Error: -2.73240795135 \t( 0 s)\n",
      "====================================================================Episode: 574  started\n",
      "Step 24 @ Episode 574/1000 (45.0)\n",
      "Step: 24 \tState: [ 0.17083645  0.74206254 -0.19585223 -1.25468357] \tAction: [-4.59815359] \tReward: 1.0\n",
      "TD Error: -3.40288281441 \t( 0 s)\n",
      "====================================================================Episode: 575  started\n",
      "Step 68 @ Episode 575/1000 (25.0)\n",
      "Step: 68 \tState: [-0.52700795 -1.89073172  0.18984447  1.47087013] \tAction: [ 3.27923918] \tReward: 1.0\n",
      "TD Error: -0.55700814724 \t( 1 s)\n",
      "====================================================================Episode: 576  started\n",
      "Step 13 @ Episode 576/1000 (69.0)\n",
      "Step: 13 \tState: [ 0.11841833  1.0304201  -0.18530093 -1.65714998] \tAction: [-8.83511162] \tReward: 1.0\n",
      "TD Error: -5.41843919754 \t( 0 s)\n",
      "====================================================================Episode: 577  started\n",
      "Step 10 @ Episode 577/1000 (14.0)\n",
      "Step: 10 \tState: [ 0.11780434  1.18309653 -0.20046727 -1.84377063] \tAction: [ 0.32042482] \tReward: 1.0\n",
      "TD Error: -8.77093715668 \t( 0 s)\n",
      "====================================================================Episode: 578  started\n",
      "Step 23 @ Episode 578/1000 (11.0)\n",
      "Step: 23 \tState: [ 0.06857608  0.55872687 -0.18974533 -1.29587713] \tAction: [ 9.37839413] \tReward: 1.0\n",
      "TD Error: -2.63799695969 \t( 0 s)\n",
      "====================================================================Episode: 579  started\n",
      "Step 13 @ Episode 579/1000 (24.0)\n",
      "Step: 13 \tState: [-0.09721225 -0.59968509  0.20711659  1.20958167] \tAction: [-9.44574928] \tReward: 1.0\n",
      "TD Error: 3.09771165848 \t( 0 s)\n",
      "====================================================================Episode: 580  started\n",
      "Step 14 @ Episode 580/1000 (14.0)\n",
      "Step: 14 \tState: [-0.14122626 -1.20178814  0.18203553  1.92983002] \tAction: [ 11.59028625] \tReward: 1.0\n",
      "TD Error: 2.22551336288 \t( 0 s)\n",
      "====================================================================Episode: 581  started\n",
      "Step 21 @ Episode 581/1000 (15.0)\n",
      "Step: 21 \tState: [-0.14075777 -1.73179441  0.16283689  2.51777755] \tAction: [ 12.90299988] \tReward: 1.0\n",
      "TD Error: 2.11036195755 \t( 0 s)\n",
      "====================================================================Episode: 582  started\n",
      "Step 16 @ Episode 582/1000 (22.0)\n",
      "Step: 16 \tState: [-0.09669269 -0.00976964  0.20335962  0.40067179] \tAction: [-9.66397858] \tReward: 1.0\n",
      "TD Error: 3.93106632233 \t( 0 s)\n",
      "====================================================================Episode: 583  started\n",
      "Step 22 @ Episode 583/1000 (17.0)\n",
      "Step: 22 \tState: [ 0.15543246  0.41120997 -0.19245846 -0.88185688] \tAction: [-9.17212963] \tReward: 1.0\n",
      "TD Error: 0.745790672302 \t( 0 s)\n",
      "====================================================================Episode: 584  started\n",
      "Step 11 @ Episode 584/1000 (23.0)\n",
      "Step: 11 \tState: [-0.11165973 -0.99246066  0.17809836  1.60208958] \tAction: [ 12.0014782] \tReward: 1.0\n",
      "TD Error: 1.80379397869 \t( 0 s)\n",
      "====================================================================Episode: 585  started\n",
      "Step 15 @ Episode 585/1000 (12.0)\n",
      "Step: 15 \tState: [-0.21337888 -0.98090834  0.19422998  1.58106369] \tAction: [-1.83756769] \tReward: 1.0\n",
      "TD Error: -1.79273452759 \t( 0 s)\n",
      "====================================================================Episode: 586  started\n",
      "Step 27 @ Episode 586/1000 (16.0)\n",
      "Step: 27 \tState: [ 0.08864206  0.57254302 -0.19878132 -1.25267171] \tAction: [-4.46727324] \tReward: 1.0\n",
      "TD Error: 4.74437217712 \t( 0 s)\n",
      "====================================================================Episode: 587  started\n",
      "Step 10 @ Episode 587/1000 (28.0)\n",
      "Step: 10 \tState: [-0.07746359 -1.17649432  0.18682674  1.92593636] \tAction: [ 9.3825388] \tReward: 1.0\n",
      "TD Error: -3.86499881744 \t( 0 s)\n",
      "====================================================================Episode: 588  started\n",
      "Step 17 @ Episode 588/1000 (11.0)\n",
      "Step: 17 \tState: [ 0.06914286  0.19500706 -0.19292493 -0.85700254] \tAction: [ 1.79614508] \tReward: 1.0\n",
      "TD Error: 4.53985404968 \t( 0 s)\n",
      "====================================================================Episode: 589  started\n",
      "Step 34 @ Episode 589/1000 (18.0)\n",
      "Step: 34 \tState: [ 0.05678563  0.41159933 -0.18598493 -1.36527425] \tAction: [ 3.18891358] \tReward: 1.0\n",
      "TD Error: -1.69332485199 \t( 0 s)\n",
      "====================================================================Episode: 590  started\n",
      "Step 24 @ Episode 590/1000 (35.0)\n",
      "Step: 24 \tState: [ 0.10846368 -0.01956707 -0.20219859 -0.5413401 ] \tAction: [ 7.31421566] \tReward: 1.0\n",
      "TD Error: -1.89351968765 \t( 0 s)\n",
      "====================================================================Episode: 591  started\n",
      "Step 8 @ Episode 591/1000 (25.0)\n",
      "Step: 8 \tState: [ 0.14196078  1.57180475 -0.17589672 -2.44201371] \tAction: [-1.61290586] \tReward: 1.0\n",
      "TD Error: -6.91000518799 \t( 0 s)\n",
      "====================================================================Episode: 592  started\n",
      "Step 14 @ Episode 592/1000 (9.0)\n",
      "Step: 14 \tState: [-0.14122833 -0.83171076  0.20594255  1.47393825] \tAction: [-10.59109974] \tReward: 1.0\n",
      "TD Error: -3.17038536072 \t( 0 s)\n",
      "====================================================================Episode: 593  started\n",
      "Step 12 @ Episode 593/1000 (15.0)\n",
      "Step: 12 \tState: [-0.07799614 -0.41101161  0.19636989  0.8667329 ] \tAction: [ 1.73740757] \tReward: 1.0\n",
      "TD Error: -0.876614928246 \t( 0 s)\n",
      "====================================================================Episode: 594  started\n",
      "Step 22 @ Episode 594/1000 (13.0)\n",
      "Step: 22 \tState: [ 0.15535091  0.44253696 -0.19852319 -1.10405313] \tAction: [-2.37941647] \tReward: 1.0\n",
      "TD Error: -4.43694176674 \t( 0 s)\n",
      "====================================================================Episode: 595  started\n",
      "Step 75 @ Episode 595/1000 (23.0)\n",
      "Step: 75 \tState: [-0.20338724 -1.69597371  0.19319418  1.97840912] \tAction: [ 1.21675742] \tReward: 1.0\n",
      "TD Error: 0.347427350283 \t( 1 s)\n",
      "====================================================================Episode: 596  started\n",
      "Step 11 @ Episode 596/1000 (76.0)\n",
      "Step: 11 \tState: [ 0.19723206  0.95221258 -0.18067023 -1.51609356] \tAction: [-3.82010746] \tReward: 1.0\n",
      "TD Error: -6.58734679222 \t( 0 s)\n",
      "====================================================================Episode: 597  started\n",
      "Step 29 @ Episode 597/1000 (12.0)\n",
      "Step: 29 \tState: [ 0.12351073  0.60227266 -0.19794667 -1.0808658 ] \tAction: [ 6.57663298] \tReward: 1.0\n",
      "TD Error: -3.73606681824 \t( 0 s)\n",
      "====================================================================Episode: 598  started\n",
      "Step 10 @ Episode 598/1000 (30.0)\n",
      "Step: 10 \tState: [ 0.11860581  0.79560073 -0.20918274 -1.29241413] \tAction: [-0.73581767] \tReward: 1.0\n",
      "TD Error: -1.41578941345 \t( 0 s)\n",
      "====================================================================Episode: 599  started\n",
      "Step 23 @ Episode 599/1000 (11.0)\n",
      "Step: 23 \tState: [-0.12966895 -0.21767824  0.20793225  0.77245723] \tAction: [ 3.16514158] \tReward: 1.0\n",
      "TD Error: 0.601107400656 \t( 0 s)\n",
      "====================================================================Episode: 600  started\n",
      "Step 14 @ Episode 600/1000 (24.0)\n",
      "Step: 14 \tState: [ 0.06442363  0.81092158 -0.19225715 -1.4506092 ] \tAction: [ 6.83541965] \tReward: 1.0\n",
      "TD Error: 0.754385375977 \t( 0 s)\n",
      "====================================================================Episode: 601  started\n",
      "Step 12 @ Episode 601/1000 (15.0)\n",
      "Step: 12 \tState: [-0.06412347 -0.7730147   0.18545188  1.49466359] \tAction: [ 6.96952772] \tReward: 1.0\n",
      "TD Error: 0.23920968771 \t( 0 s)\n",
      "====================================================================Episode: 602  started\n",
      "Step 28 @ Episode 602/1000 (13.0)\n",
      "Step: 28 \tState: [ 0.16652327  1.21759153 -0.20316927 -2.13662737] \tAction: [-3.30162215] \tReward: 1.0\n",
      "TD Error: 4.84484901428 \t( 0 s)\n",
      "====================================================================Episode: 603  started\n",
      "Step 18 @ Episode 603/1000 (29.0)\n",
      "Step: 18 \tState: [-0.12267587 -0.81511533  0.1858922   1.48913411] \tAction: [-8.7413559] \tReward: 1.0\n",
      "TD Error: -2.0105158329 \t( 0 s)\n",
      "====================================================================Episode: 604  started\n",
      "Step 30 @ Episode 604/1000 (19.0)\n",
      "Step: 30 \tState: [-0.08593865 -1.2246386   0.18066571  1.93570756] \tAction: [-7.78611135] \tReward: 1.0\n",
      "TD Error: 0.212297558784 \t( 0 s)\n",
      "====================================================================Episode: 605  started\n",
      "Step 24 @ Episode 605/1000 (31.0)\n",
      "Step: 24 \tState: [ 0.07851553  1.20232279 -0.20627582 -2.1914687 ] \tAction: [-10.90620422] \tReward: 1.0\n",
      "TD Error: -0.347722434998 \t( 0 s)\n",
      "====================================================================Episode: 606  started\n",
      "Step 44 @ Episode 606/1000 (25.0)\n",
      "Step: 44 \tState: [-0.10284886 -0.39197375 -0.20568061 -0.3904743 ] \tAction: [-12.2227335] \tReward: 1.0\n",
      "TD Error: 3.85964584351 \t( 0 s)\n",
      "====================================================================Episode: 607  started\n",
      "Step 14 @ Episode 607/1000 (45.0)\n",
      "Step: 14 \tState: [ 0.1068624   1.2001064  -0.19469972 -2.01134551] \tAction: [-1.44955182] \tReward: 1.0\n",
      "TD Error: 5.60830116272 \t( 0 s)\n",
      "====================================================================Episode: 608  started\n",
      "Step 16 @ Episode 608/1000 (15.0)\n",
      "Step: 16 \tState: [-0.12439999 -0.77644867  0.1912562   1.4651765 ] \tAction: [-1.12876606] \tReward: 1.0\n",
      "TD Error: 1.64087471962 \t( 0 s)\n",
      "====================================================================Episode: 609  started\n",
      "Step 12 @ Episode 609/1000 (17.0)\n",
      "Step: 12 \tState: [-0.12582277 -0.76472952  0.1879706   1.30629672] \tAction: [ 2.99455428] \tReward: 1.0\n",
      "TD Error: 0.701996803284 \t( 0 s)\n",
      "====================================================================Episode: 610  started\n",
      "Step 20 @ Episode 610/1000 (13.0)\n",
      "Step: 20 \tState: [-0.12829917 -0.73342435  0.20133374  1.21968056] \tAction: [ 6.43376303] \tReward: 1.0\n",
      "TD Error: 4.4872674942 \t( 0 s)\n",
      "====================================================================Episode: 611  started\n",
      "Step 12 @ Episode 611/1000 (21.0)\n",
      "Step: 12 \tState: [ 0.0834795   0.74029401 -0.19867483 -1.39732146] \tAction: [-1.2466054] \tReward: 1.0\n",
      "TD Error: 3.43419151306 \t( 0 s)\n",
      "====================================================================Episode: 612  started\n",
      "Step 46 @ Episode 612/1000 (13.0)\n",
      "Step: 46 \tState: [ 0.12313499  0.38864167 -0.19261251 -1.04425152] \tAction: [-0.09928196] \tReward: 1.0\n",
      "TD Error: 5.89529838562 \t( 1 s)\n",
      "====================================================================Episode: 613  started\n",
      "Step 51 @ Episode 613/1000 (47.0)\n",
      "Step: 51 \tState: [-0.43458153 -1.7440323   0.18012237  2.00983359] \tAction: [-3.24056268] \tReward: 1.0\n",
      "TD Error: 6.65985956192 \t( 1 s)\n",
      "====================================================================Episode: 614  started\n",
      "Step 14 @ Episode 614/1000 (52.0)\n",
      "Step: 14 \tState: [-0.10483016 -0.36079289  0.20399214  0.913818  ] \tAction: [-4.6009779] \tReward: 1.0\n",
      "TD Error: 6.63117542267 \t( 0 s)\n",
      "====================================================================Episode: 615  started\n",
      "Step 26 @ Episode 615/1000 (15.0)\n",
      "Step: 26 \tState: [-0.17247635 -0.4164916   0.1968678   0.93557371] \tAction: [-2.4992826] \tReward: 1.0\n",
      "TD Error: 3.73086464405 \t( 0 s)\n",
      "====================================================================Episode: 616  started\n",
      "Step 29 @ Episode 616/1000 (27.0)\n",
      "Step: 29 \tState: [ 0.24722143  0.95796064 -0.1934389  -1.22218422] \tAction: [-3.97461414] \tReward: 1.0\n",
      "TD Error: 2.94513101578 \t( 0 s)\n",
      "====================================================================Episode: 617  started\n",
      "Step 12 @ Episode 617/1000 (30.0)\n",
      "Step: 12 \tState: [-0.16301166 -0.78735023  0.20932411  1.43744925] \tAction: [ 11.42026138] \tReward: 1.0\n",
      "TD Error: -5.8786687851 \t( 0 s)\n",
      "====================================================================Episode: 618  started\n",
      "Step 10 @ Episode 618/1000 (13.0)\n",
      "Step: 10 \tState: [ 0.12358573  1.17223364 -0.19064777 -1.95998887] \tAction: [ 3.17503357] \tReward: 1.0\n",
      "TD Error: 5.70884857178 \t( 0 s)\n",
      "====================================================================Episode: 619  started\n",
      "Step 37 @ Episode 619/1000 (11.0)\n",
      "Step: 37 \tState: [-0.35778093 -0.99207622  0.20143995  0.9878561 ] \tAction: [-0.39618385] \tReward: 1.0\n",
      "TD Error: -8.0581577301 \t( 0 s)\n",
      "====================================================================Episode: 620  started\n",
      "Step 15 @ Episode 620/1000 (38.0)\n",
      "Step: 15 \tState: [-0.13652673 -1.35145862  0.20013917  2.14551711] \tAction: [ 2.24560165] \tReward: 1.0\n",
      "TD Error: -16.5950393677 \t( 0 s)\n",
      "====================================================================Episode: 621  started\n",
      "Step 27 @ Episode 621/1000 (16.0)\n",
      "Step: 27 \tState: [ 0.07164964 -0.17633317 -0.20678916 -0.30555898] \tAction: [-1.82999372] \tReward: 1.0\n",
      "TD Error: -0.88296880722 \t( 0 s)\n",
      "====================================================================Episode: 622  started\n",
      "Step 19 @ Episode 622/1000 (28.0)\n",
      "Step: 19 \tState: [-0.15161114 -0.16014215  0.20700375  0.60082282] \tAction: [ 3.56937861] \tReward: 1.0\n",
      "TD Error: -0.240992021561 \t( 0 s)\n",
      "====================================================================Episode: 623  started\n",
      "Step 36 @ Episode 623/1000 (20.0)\n",
      "Step: 36 \tState: [-0.2221093  -1.577712    0.17270906  2.11928851] \tAction: [ 0.36163983] \tReward: 1.0\n",
      "TD Error: -1.0508202076 \t( 0 s)\n",
      "====================================================================Episode: 624  started\n",
      "Step 36 @ Episode 624/1000 (37.0)\n",
      "Step: 36 \tState: [-0.278435   -1.18176867  0.20883958  1.6105512 ] \tAction: [ 10.15066338] \tReward: 1.0\n",
      "TD Error: 3.12996339798 \t( 0 s)\n",
      "====================================================================Episode: 625  started\n",
      "Step 11 @ Episode 625/1000 (37.0)\n",
      "Step: 11 \tState: [ 0.14510677  0.62997253 -0.18960369 -1.11154912] \tAction: [-12.59645081] \tReward: 1.0\n",
      "TD Error: -1.71936130524 \t( 0 s)\n",
      "====================================================================Episode: 626  started\n",
      "Step 14 @ Episode 626/1000 (12.0)\n",
      "Step: 14 \tState: [-0.1154959  -0.3969591   0.19625365  0.79847218] \tAction: [ 4.72960091] \tReward: 1.0\n",
      "TD Error: 1.89772424698 \t( 0 s)\n",
      "====================================================================Episode: 627  started\n",
      "Step 25 @ Episode 627/1000 (15.0)\n",
      "Step: 25 \tState: [ 0.04051681  0.202397    0.20557227  0.51416169] \tAction: [-3.25273895] \tReward: 1.0\n",
      "TD Error: 0.71373090744 \t( 0 s)\n",
      "====================================================================Episode: 628  started\n",
      "Step 7 @ Episode 628/1000 (26.0)\n",
      "Step: 7 \tState: [ 0.10569173  1.38513535 -0.17501408 -2.20063094] \tAction: [ 5.02669001] \tReward: 1.0\n",
      "TD Error: -4.71981430054 \t( 0 s)\n",
      "====================================================================Episode: 629  started\n",
      "Step 12 @ Episode 629/1000 (8.0)\n",
      "Step: 12 \tState: [-0.1357171  -0.82210481  0.19890918  1.4822002 ] \tAction: [ 5.27224541] \tReward: 1.0\n",
      "TD Error: -2.23636853695 \t( 0 s)\n",
      "====================================================================Episode: 630  started\n",
      "Step 23 @ Episode 630/1000 (13.0)\n",
      "Step: 23 \tState: [ 0.09284062  0.23717383 -0.20694517 -0.7463504 ] \tAction: [-1.11387956] \tReward: 1.0\n",
      "TD Error: -6.65464286804 \t( 0 s)\n",
      "====================================================================Episode: 631  started\n",
      "Step 11 @ Episode 631/1000 (24.0)\n",
      "Step: 11 \tState: [ 0.06733278  0.98935274 -0.17857873 -1.72030493] \tAction: [-0.98128891] \tReward: 1.0\n",
      "TD Error: -7.77017822266 \t( 0 s)\n",
      "====================================================================Episode: 632  started\n",
      "Step 15 @ Episode 632/1000 (12.0)\n",
      "Step: 15 \tState: [ 0.12719493  0.55277579 -0.20328978 -1.15142828] \tAction: [ 3.1040535] \tReward: 1.0\n",
      "TD Error: -9.67707023621 \t( 0 s)\n",
      "====================================================================Episode: 633  started\n",
      "Step 18 @ Episode 633/1000 (16.0)\n",
      "Step: 18 \tState: [-0.00611072 -0.37140958  0.19132699  1.11022081] \tAction: [-1.54113972] \tReward: 1.0\n",
      "TD Error: -0.748223114014 \t( 0 s)\n",
      "====================================================================Episode: 634  started\n",
      "Step 19 @ Episode 634/1000 (19.0)\n",
      "Step: 19 \tState: [-0.18548219 -0.99962508  0.18929948  1.61317285] \tAction: [ 0.95599228] \tReward: 1.0\n",
      "TD Error: 2.00565760732 \t( 0 s)\n",
      "====================================================================Episode: 635  started\n",
      "Step 21 @ Episode 635/1000 (20.0)\n",
      "Step: 21 \tState: [ 0.09289522  0.9399312  -0.20051971 -1.81528321] \tAction: [-7.68152189] \tReward: 1.0\n",
      "TD Error: -7.35204906464 \t( 0 s)\n",
      "====================================================================Episode: 636  started\n",
      "Step 43 @ Episode 636/1000 (22.0)\n",
      "Step: 43 \tState: [ 0.03792332 -0.21656033  0.18912352  1.14629128] \tAction: [ 8.61030293] \tReward: 1.0\n",
      "TD Error: -3.55006990433 \t( 1 s)\n",
      "====================================================================Episode: 637  started\n",
      "Step 23 @ Episode 637/1000 (44.0)\n",
      "Step: 23 \tState: [-0.07665343  0.19453064  0.20834004  0.38459307] \tAction: [ 7.40709734] \tReward: 1.0\n",
      "TD Error: -1.8316116333 \t( 0 s)\n",
      "====================================================================Episode: 638  started\n",
      "Step 23 @ Episode 638/1000 (24.0)\n",
      "Step: 23 \tState: [ 0.18642058  0.98489283 -0.19458061 -1.67758928] \tAction: [ 7.02529335] \tReward: 1.0\n",
      "TD Error: -5.54561905861 \t( 0 s)\n",
      "====================================================================Episode: 639  started\n",
      "Step 11 @ Episode 639/1000 (24.0)\n",
      "Step: 11 \tState: [ 0.10304934  1.02440767 -0.19896103 -1.65083437] \tAction: [-3.44886923] \tReward: 1.0\n",
      "TD Error: -3.52623038292 \t( 0 s)\n",
      "====================================================================Episode: 640  started\n",
      "Step 22 @ Episode 640/1000 (12.0)\n",
      "Step: 22 \tState: [ 0.05469248  0.40131774 -0.19634113 -0.91602144] \tAction: [-5.31328201] \tReward: 1.0\n",
      "TD Error: 0.366621589661 \t( 0 s)\n",
      "====================================================================Episode: 641  started\n",
      "Step 15 @ Episode 641/1000 (23.0)\n",
      "Step: 15 \tState: [ 0.09166141  0.99138219 -0.19470646 -1.7021398 ] \tAction: [-1.38920188] \tReward: 1.0\n",
      "TD Error: -0.365944766998 \t( 0 s)\n",
      "====================================================================Episode: 642  started\n",
      "Step 14 @ Episode 642/1000 (16.0)\n",
      "Step: 14 \tState: [ 0.15203189  0.36509927 -0.19742436 -0.88696918] \tAction: [-2.27707887] \tReward: 1.0\n",
      "TD Error: 1.65650615692 \t( 0 s)\n",
      "====================================================================Episode: 643  started\n",
      "Step 25 @ Episode 643/1000 (15.0)\n",
      "Step: 25 \tState: [-0.15362455 -1.0189858   0.18925189  1.69722991] \tAction: [-0.32514504] \tReward: 1.0\n",
      "TD Error: -7.2805683136 \t( 0 s)\n",
      "====================================================================Episode: 644  started\n",
      "Step 33 @ Episode 644/1000 (26.0)\n",
      "Step: 33 \tState: [-0.21868587 -2.07392411  0.18074302  2.47139708] \tAction: [-2.5516789] \tReward: 1.0\n",
      "TD Error: -7.61757221222 \t( 0 s)\n",
      "====================================================================Episode: 645  started\n",
      "Step 25 @ Episode 645/1000 (34.0)\n",
      "Step: 25 \tState: [ 0.08026783  0.58528884 -0.20879042 -1.19744521] \tAction: [ 4.64058733] \tReward: 1.0\n",
      "TD Error: -5.29437503815 \t( 0 s)\n",
      "====================================================================Episode: 646  started\n",
      "Step 10 @ Episode 646/1000 (26.0)\n",
      "Step: 10 \tState: [ 0.0705746   1.17529059 -0.20492291 -2.03897027] \tAction: [-0.32973975] \tReward: 1.0\n",
      "TD Error: -7.21926264763 \t( 0 s)\n",
      "====================================================================Episode: 647  started\n",
      "Step 15 @ Episode 647/1000 (11.0)\n",
      "Step: 15 \tState: [-0.04895621 -0.59062316  0.1991747   1.2378462 ] \tAction: [ 8.87711334] \tReward: 1.0\n",
      "TD Error: -3.05012493134 \t( 0 s)\n",
      "====================================================================Episode: 648  started\n",
      "Step 43 @ Episode 648/1000 (16.0)\n",
      "Step: 43 \tState: [-0.29878278 -0.93960771  0.20167427  1.1827998 ] \tAction: [ 0.71423727] \tReward: 1.0\n",
      "TD Error: -1.48591012955 \t( 1 s)\n",
      "====================================================================Episode: 649  started\n",
      "Step 17 @ Episode 649/1000 (44.0)\n",
      "Step: 17 \tState: [-0.03696515 -0.17564119  0.19973998  0.82534653] \tAction: [ 12.75919056] \tReward: 1.0\n",
      "TD Error: -0.0403443336487 \t( 0 s)\n",
      "====================================================================Episode: 650  started\n",
      "Step 11 @ Episode 650/1000 (18.0)\n",
      "Step: 11 \tState: [ 0.09763657  0.19903865 -0.20039817 -0.55021568] \tAction: [-10.64870358] \tReward: 1.0\n",
      "TD Error: -0.949070167542 \t( 0 s)\n",
      "====================================================================Episode: 651  started\n",
      "Step 11 @ Episode 651/1000 (12.0)\n",
      "Step: 11 \tState: [-0.15006691 -0.99384995  0.18133517  1.67909132] \tAction: [ 2.86561966] \tReward: 1.0\n",
      "TD Error: -0.27422413826 \t( 0 s)\n",
      "====================================================================Episode: 652  started\n",
      "Step 15 @ Episode 652/1000 (12.0)\n",
      "Step: 15 \tState: [-0.16911594 -0.57666067  0.201826    1.0883399 ] \tAction: [ 1.69876313] \tReward: 1.0\n",
      "TD Error: -0.0136365413666 \t( 0 s)\n",
      "====================================================================Episode: 653  started\n",
      "Step 12 @ Episode 653/1000 (16.0)\n",
      "Step: 12 \tState: [-0.07640424 -0.7981106   0.18342983  1.40359502] \tAction: [-3.90033317] \tReward: 1.0\n",
      "TD Error: -1.8077018261 \t( 0 s)\n",
      "====================================================================Episode: 654  started\n",
      "Step 25 @ Episode 654/1000 (13.0)\n",
      "Step: 25 \tState: [-0.12093833 -0.62017071  0.1913115   1.10247447] \tAction: [-7.63465548] \tReward: 1.0\n",
      "TD Error: -1.3221265316 \t( 0 s)\n",
      "====================================================================Episode: 655  started\n",
      "Step 11 @ Episode 655/1000 (26.0)\n",
      "Step: 11 \tState: [-0.10014325 -0.5763695   0.19716483  1.17771714] \tAction: [-6.13239288] \tReward: 1.0\n",
      "TD Error: -0.89706454277 \t( 0 s)\n",
      "====================================================================Episode: 656  started\n",
      "Step 27 @ Episode 656/1000 (12.0)\n",
      "Step: 27 \tState: [-0.06722726 -0.20057774  0.19625606  0.89133676] \tAction: [-6.78207064] \tReward: 1.0\n",
      "TD Error: -1.23139910698 \t( 0 s)\n",
      "====================================================================Episode: 657  started\n",
      "Step 26 @ Episode 657/1000 (28.0)\n",
      "Step: 26 \tState: [ 0.02789405 -0.04695951  0.19742033  0.9080212 ] \tAction: [ 4.43085909] \tReward: 1.0\n",
      "TD Error: -2.04906339645 \t( 0 s)\n",
      "====================================================================Episode: 658  started\n",
      "Step 27 @ Episode 658/1000 (27.0)\n",
      "Step: 27 \tState: [-0.16677717 -0.62864406  0.2032321   1.08939089] \tAction: [ 7.67202425] \tReward: 1.0\n",
      "TD Error: -1.25177474022 \t( 0 s)\n",
      "====================================================================Episode: 659  started\n",
      "Step 15 @ Episode 659/1000 (28.0)\n",
      "Step: 15 \tState: [ 0.15282066  1.3200248  -0.19153285 -2.11659443] \tAction: [ 5.87797403] \tReward: 1.0\n",
      "TD Error: -4.83750457764 \t( 0 s)\n",
      "====================================================================Episode: 660  started\n",
      "Step 15 @ Episode 660/1000 (16.0)\n",
      "Step: 15 \tState: [-0.06926886 -0.2036199   0.20589342  0.85294783] \tAction: [ 5.95802307] \tReward: 1.0\n",
      "TD Error: -0.969401931763 \t( 0 s)\n",
      "====================================================================Episode: 661  started\n",
      "Step 13 @ Episode 661/1000 (16.0)\n",
      "Step: 13 \tState: [ 0.04052051  0.19338033 -0.20816235 -0.67155269] \tAction: [-1.3172648] \tReward: 1.0\n",
      "TD Error: 3.61314888 \t( 0 s)\n",
      "====================================================================Episode: 662  started\n",
      "Step 11 @ Episode 662/1000 (14.0)\n",
      "Step: 11 \tState: [-0.15975671 -1.00723109  0.18452054  1.58919016] \tAction: [-8.28345013] \tReward: 1.0\n",
      "TD Error: -5.1616538763 \t( 0 s)\n",
      "====================================================================Episode: 663  started\n",
      "Step 13 @ Episode 663/1000 (12.0)\n",
      "Step: 13 \tState: [-0.16307531 -0.55446246  0.19840887  1.1850155 ] \tAction: [-4.31499338] \tReward: 1.0\n",
      "TD Error: -3.04389352798 \t( 0 s)\n",
      "====================================================================Episode: 664  started\n",
      "Step 12 @ Episode 664/1000 (14.0)\n",
      "Step: 12 \tState: [ 0.15046448  0.41908937 -0.20493961 -0.80889916] \tAction: [-9.73004341] \tReward: 1.0\n",
      "TD Error: 3.1520986557 \t( 0 s)\n",
      "====================================================================Episode: 665  started\n",
      "Step 76 @ Episode 665/1000 (13.0)\n",
      "Step: 76 \tState: [ 0.56471935 -0.04314316  0.19392505  1.3706475 ] \tAction: [ 5.65654516] \tReward: 1.0\n",
      "TD Error: -6.91348891258 \t( 1 s)\n",
      "====================================================================Episode: 666  started\n",
      "Step 11 @ Episode 666/1000 (77.0)\n",
      "Step: 11 \tState: [ 0.07378084  1.34379951 -0.20925253 -2.29206536] \tAction: [ 6.14108562] \tReward: 1.0\n",
      "TD Error: 4.15055980682 \t( 0 s)\n",
      "====================================================================Episode: 667  started\n",
      "Step 49 @ Episode 667/1000 (12.0)\n",
      "Step: 49 \tState: [-0.42009831 -1.73043577  0.19210747  1.77439504] \tAction: [-3.58364296] \tReward: 1.0\n",
      "TD Error: 0.624719429016 \t( 1 s)\n",
      "====================================================================Episode: 668  started\n",
      "Step 36 @ Episode 668/1000 (50.0)\n",
      "Step: 36 \tState: [ 0.15763522  0.36362752 -0.2059042  -0.62617527] \tAction: [-2.82294559] \tReward: 1.0\n",
      "TD Error: -2.01629500985 \t( 0 s)\n",
      "====================================================================Episode: 669  started\n",
      "Step 16 @ Episode 669/1000 (37.0)\n",
      "Step: 16 \tState: [-0.13593463 -1.17501736  0.19217175  1.92917569] \tAction: [-5.524158] \tReward: 1.0\n",
      "TD Error: -2.41909141541 \t( 0 s)\n",
      "====================================================================Episode: 670  started\n",
      "Step 17 @ Episode 670/1000 (17.0)\n",
      "Step: 17 \tState: [-0.12281247 -1.02387529  0.17914401  1.67904741] \tAction: [ 16.29090118] \tReward: 1.0\n",
      "TD Error: 2.16922416687 \t( 0 s)\n",
      "====================================================================Episode: 671  started\n",
      "Step 18 @ Episode 671/1000 (18.0)\n",
      "Step: 18 \tState: [-0.09485256 -0.79894917  0.19628898  1.50959279] \tAction: [ 4.889328] \tReward: 1.0\n",
      "TD Error: 10.0286678314 \t( 0 s)\n",
      "====================================================================Episode: 672  started\n",
      "Step 20 @ Episode 672/1000 (19.0)\n",
      "Step: 20 \tState: [-0.09583961  0.00298829  0.20167646  0.3885523 ] \tAction: [ 1.85763514] \tReward: 1.0\n",
      "TD Error: 4.89407196045 \t( 0 s)\n",
      "====================================================================Episode: 673  started\n",
      "Step 21 @ Episode 673/1000 (21.0)\n",
      "Step: 21 \tState: [-0.15802789 -0.94375196  0.20452862  1.82427972] \tAction: [-4.50460768] \tReward: 1.0\n",
      "TD Error: 0.91600446701 \t( 0 s)\n",
      "====================================================================Episode: 674  started\n",
      "Step 12 @ Episode 674/1000 (22.0)\n",
      "Step: 12 \tState: [ 0.14703005  0.76295741 -0.20514156 -1.41888793] \tAction: [ 8.2834816] \tReward: 1.0\n",
      "TD Error: 0.090496635437 \t( 0 s)\n",
      "====================================================================Episode: 675  started\n",
      "Step 14 @ Episode 675/1000 (13.0)\n",
      "Step: 14 \tState: [-0.09124787 -0.8364783   0.20082478  1.5010134 ] \tAction: [-6.4422102] \tReward: 1.0\n",
      "TD Error: -2.5019993782 \t( 0 s)\n",
      "====================================================================Episode: 676  started\n",
      "Step 13 @ Episode 676/1000 (15.0)\n",
      "Step: 13 \tState: [-0.0813261  -0.57707267  0.19692159  1.27465266] \tAction: [-7.86109972] \tReward: 1.0\n",
      "TD Error: -2.3241109848 \t( 0 s)\n",
      "====================================================================Episode: 677  started\n",
      "Step 19 @ Episode 677/1000 (14.0)\n",
      "Step: 19 \tState: [-0.17009938 -1.75508809  0.19501544  2.63313837] \tAction: [-0.01603321] \tReward: 1.0\n",
      "TD Error: -2.9215423584 \t( 0 s)\n",
      "====================================================================Episode: 678  started\n",
      "Step 20 @ Episode 678/1000 (20.0)\n",
      "Step: 20 \tState: [ 0.14795378  0.84622904 -0.20197542 -1.56018648] \tAction: [-2.57842803] \tReward: 1.0\n",
      "TD Error: -0.741374874115 \t( 0 s)\n",
      "====================================================================Episode: 679  started\n",
      "Step 21 @ Episode 679/1000 (21.0)\n",
      "Step: 21 \tState: [ 0.09056006  0.60047821 -0.2050069  -1.22711824] \tAction: [-4.30992699] \tReward: 1.0\n",
      "TD Error: 0.705668067932 \t( 0 s)\n",
      "====================================================================Episode: 680  started\n",
      "Step 17 @ Episode 680/1000 (22.0)\n",
      "Step: 17 \tState: [-0.07670314 -1.37230041  0.19084481  2.36595501] \tAction: [-4.65403557] \tReward: 1.0\n",
      "TD Error: -2.12294979095 \t( 0 s)\n",
      "====================================================================Episode: 681  started\n",
      "Step 12 @ Episode 681/1000 (18.0)\n",
      "Step: 12 \tState: [ 0.07229876  0.40816    -0.19815633 -0.8592758 ] \tAction: [-1.46784675] \tReward: 1.0\n",
      "TD Error: 2.80476169586 \t( 0 s)\n",
      "====================================================================Episode: 682  started\n",
      "Step 13 @ Episode 682/1000 (13.0)\n",
      "Step: 13 \tState: [-0.12429685 -0.2095282   0.20224735  0.73713993] \tAction: [-0.05994859] \tReward: 1.0\n",
      "TD Error: 2.6220041275 \t( 0 s)\n",
      "====================================================================Episode: 683  started\n",
      "Step 40 @ Episode 683/1000 (14.0)\n",
      "Step: 40 \tState: [-0.33414739 -1.9573119   0.20108726  2.38961693] \tAction: [ 0.87211138] \tReward: 1.0\n",
      "TD Error: 4.30158901215 \t( 1 s)\n",
      "====================================================================Episode: 684  started\n",
      "Step 22 @ Episode 684/1000 (41.0)\n",
      "Step: 22 \tState: [ 0.19807019  0.45024354 -0.20327666 -0.95249605] \tAction: [-5.17072153] \tReward: 1.0\n",
      "TD Error: -1.9725373745 \t( 0 s)\n",
      "====================================================================Episode: 685  started\n",
      "Step 23 @ Episode 685/1000 (23.0)\n",
      "Step: 23 \tState: [ 0.00207591 -0.62028681  0.18739943  1.53428847] \tAction: [-5.03065968] \tReward: 1.0\n",
      "TD Error: -0.444620513916 \t( 0 s)\n",
      "====================================================================Episode: 686  started\n",
      "Step 9 @ Episode 686/1000 (24.0)\n",
      "Step: 9 \tState: [ 0.15239762  0.9600307  -0.19076487 -1.64198287] \tAction: [-8.60726738] \tReward: 1.0\n",
      "TD Error: -0.450694465637 \t( 0 s)\n",
      "====================================================================Episode: 687  started\n",
      "Step 12 @ Episode 687/1000 (10.0)\n",
      "Step: 12 \tState: [-0.11323469 -0.77589155  0.19104669  1.26980261] \tAction: [ 3.31176448] \tReward: 1.0\n",
      "TD Error: 1.7925825119 \t( 0 s)\n",
      "====================================================================Episode: 688  started\n",
      "Step 45 @ Episode 688/1000 (13.0)\n",
      "Step: 45 \tState: [ 0.31440647  1.76215419 -0.20923596 -2.15136462] \tAction: [-3.05055714] \tReward: 1.0\n",
      "TD Error: -0.302737426758 \t( 1 s)\n",
      "====================================================================Episode: 689  started\n",
      "Step 16 @ Episode 689/1000 (46.0)\n",
      "Step: 16 \tState: [-0.11940262 -0.43076773  0.19508256  0.89190905] \tAction: [-4.89235687] \tReward: 1.0\n",
      "TD Error: -3.31249459982 \t( 0 s)\n",
      "====================================================================Episode: 690  started\n",
      "Step 18 @ Episode 690/1000 (17.0)\n",
      "Step: 18 \tState: [-0.13841642 -0.79455768  0.18323523  1.36058813] \tAction: [ 0.49930549] \tReward: 1.0\n",
      "TD Error: -5.84896920919 \t( 0 s)\n",
      "====================================================================Episode: 691  started\n",
      "Step 19 @ Episode 691/1000 (19.0)\n",
      "Step: 19 \tState: [-0.13824227 -0.97933251  0.20733469  1.85712711] \tAction: [ 4.35424614] \tReward: 1.0\n",
      "TD Error: 0.381835174561 \t( 0 s)\n",
      "====================================================================Episode: 692  started\n",
      "Step 10 @ Episode 692/1000 (20.0)\n",
      "Step: 10 \tState: [-0.15110379 -1.60692319  0.18665929  2.49215282] \tAction: [ 15.98137856] \tReward: 1.0\n",
      "TD Error: 1.23833408356 \t( 0 s)\n",
      "====================================================================Episode: 693  started\n",
      "Step 24 @ Episode 693/1000 (11.0)\n",
      "Step: 24 \tState: [-0.02719043  0.39875265 -0.1871859  -1.23689336] \tAction: [ 2.9938066] \tReward: 1.0\n",
      "TD Error: 1.85704307556 \t( 0 s)\n",
      "====================================================================Episode: 694  started\n",
      "Step 11 @ Episode 694/1000 (25.0)\n",
      "Step: 11 \tState: [ 0.1477402   0.63384555 -0.20756857 -1.07013074] \tAction: [ 0.67092669] \tReward: 1.0\n",
      "TD Error: 1.41106472015 \t( 0 s)\n",
      "====================================================================Episode: 695  started\n",
      "Step 9 @ Episode 695/1000 (12.0)\n",
      "Step: 9 \tState: [-0.12728338 -1.80514417  0.20546408  2.77891255] \tAction: [-0.56595451] \tReward: 1.0\n",
      "TD Error: 12.1518514633 \t( 0 s)\n",
      "====================================================================Episode: 696  started\n",
      "Step 17 @ Episode 696/1000 (10.0)\n",
      "Step: 17 \tState: [ 0.13889927  0.56519392 -0.19914294 -1.101849  ] \tAction: [-2.90285444] \tReward: 1.0\n",
      "TD Error: 4.22782535553 \t( 0 s)\n",
      "====================================================================Episode: 697  started\n",
      "Step 27 @ Episode 697/1000 (18.0)\n",
      "Step: 27 \tState: [-0.02498055 -0.19341232  0.20668175  0.9166579 ] \tAction: [ 3.01845074] \tReward: 1.0\n",
      "TD Error: 3.84538650513 \t( 0 s)\n",
      "====================================================================Episode: 698  started\n",
      "Step 19 @ Episode 698/1000 (28.0)\n",
      "Step: 19 \tState: [ 0.13988736  0.64880696 -0.19371146 -1.28814048] \tAction: [-10.01743221] \tReward: 1.0\n",
      "TD Error: 3.52874221802 \t( 0 s)\n",
      "====================================================================Episode: 699  started\n",
      "Step 14 @ Episode 699/1000 (20.0)\n",
      "Step: 14 \tState: [-0.07561525 -0.42856569  0.20289539  0.94254581] \tAction: [-5.52924776] \tReward: 1.0\n",
      "TD Error: 2.41576328278 \t( 0 s)\n",
      "====================================================================Episode: 700  started\n",
      "Step 25 @ Episode 700/1000 (15.0)\n",
      "Step: 25 \tState: [ 0.00445725  0.13845949  0.20047308  0.52946574] \tAction: [-13.19536686] \tReward: 1.0\n",
      "TD Error: 0.727398490906 \t( 0 s)\n",
      "====================================================================Episode: 701  started\n",
      "Step 15 @ Episode 701/1000 (26.0)\n",
      "Step: 15 \tState: [ 0.16723142  1.02127753 -0.20809033 -1.73122967] \tAction: [-2.63486552] \tReward: 1.0\n",
      "TD Error: 2.74624576569 \t( 0 s)\n",
      "====================================================================Episode: 702  started\n",
      "Step 15 @ Episode 702/1000 (16.0)\n",
      "Step: 15 \tState: [ 0.13943717  1.02359108 -0.20107521 -1.78951085] \tAction: [-8.88876724] \tReward: 1.0\n",
      "TD Error: 3.24824113846 \t( 0 s)\n",
      "====================================================================Episode: 703  started\n",
      "Step 29 @ Episode 703/1000 (16.0)\n",
      "Step: 29 \tState: [-0.05920657 -0.22618932  0.20223613  1.21613748] \tAction: [ 2.31331468] \tReward: 1.0\n",
      "TD Error: -2.5435267508 \t( 0 s)\n",
      "====================================================================Episode: 704  started\n",
      "Step 17 @ Episode 704/1000 (30.0)\n",
      "Step: 17 \tState: [-0.17275949 -1.75620208  0.20769863  2.66919738] \tAction: [-6.63839674] \tReward: 1.0\n",
      "TD Error: -3.65327174664 \t( 0 s)\n",
      "====================================================================Episode: 705  started\n",
      "Step 16 @ Episode 705/1000 (18.0)\n",
      "Step: 16 \tState: [-0.07179401 -1.2175971   0.18260907  1.96562119] \tAction: [ 16.19491768] \tReward: 1.0\n",
      "TD Error: -1.13743476868 \t( 0 s)\n",
      "====================================================================Episode: 706  started\n",
      "Step 24 @ Episode 706/1000 (17.0)\n",
      "Step: 24 \tState: [-0.20711663 -1.58416015  0.16623647  2.26202083] \tAction: [-5.74123764] \tReward: 1.0\n",
      "TD Error: 3.81527786255 \t( 0 s)\n",
      "====================================================================Episode: 707  started\n",
      "Step 32 @ Episode 707/1000 (25.0)\n",
      "Step: 32 \tState: [-0.24765871 -1.54713548  0.18682643  2.11224926] \tAction: [ 16.39678192] \tReward: 1.0\n",
      "TD Error: 6.18793487549 \t( 0 s)\n",
      "====================================================================Episode: 708  started\n",
      "Step 12 @ Episode 708/1000 (33.0)\n",
      "Step: 12 \tState: [-0.13723047 -0.76278536  0.19312609  1.38449018] \tAction: [-6.06399727] \tReward: 1.0\n",
      "TD Error: 3.27584381104 \t( 0 s)\n",
      "====================================================================Episode: 709  started\n",
      "Step 14 @ Episode 709/1000 (13.0)\n",
      "Step: 14 \tState: [-0.13253499 -1.1790865   0.20910828  1.99286205] \tAction: [ 0.68428022] \tReward: 1.0\n",
      "TD Error: -1.17508649826 \t( 0 s)\n",
      "====================================================================Episode: 710  started\n",
      "Step 12 @ Episode 710/1000 (15.0)\n",
      "Step: 12 \tState: [ 0.10504856  0.40252563 -0.19545009 -0.90875661] \tAction: [ 2.75369143] \tReward: 1.0\n",
      "TD Error: 1.85755186081 \t( 0 s)\n",
      "====================================================================Episode: 711  started\n",
      "Step 10 @ Episode 711/1000 (13.0)\n",
      "Step: 10 \tState: [ 0.06320822  1.18340737 -0.18109933 -1.96129054] \tAction: [ 1.39701903] \tReward: 1.0\n",
      "TD Error: 2.26649036407 \t( 0 s)\n",
      "====================================================================Episode: 712  started\n",
      "Step 22 @ Episode 712/1000 (11.0)\n",
      "Step: 22 \tState: [-0.19738226 -0.83703162  0.19150537  1.33681408] \tAction: [ 1.65060449] \tReward: 1.0\n",
      "TD Error: -3.94554810524 \t( 0 s)\n",
      "====================================================================Episode: 713  started\n",
      "Step 12 @ Episode 713/1000 (23.0)\n",
      "Step: 12 \tState: [-0.12206071 -1.13397234  0.2012553   2.02663293] \tAction: [ 0.24797069] \tReward: 1.0\n",
      "TD Error: -8.08010025024 \t( 0 s)\n",
      "====================================================================Episode: 714  started\n",
      "Step 11 @ Episode 714/1000 (13.0)\n",
      "Step: 11 \tState: [-0.11564793 -0.9350212   0.19621645  1.72337426] \tAction: [ 1.47392631] \tReward: 1.0\n",
      "TD Error: -6.43717205524 \t( 0 s)\n",
      "====================================================================Episode: 715  started\n",
      "Step 14 @ Episode 715/1000 (12.0)\n",
      "Step: 14 \tState: [-0.04075621  0.00372337  0.20530369  0.46405707] \tAction: [-1.8200984] \tReward: 1.0\n",
      "TD Error: -0.637271976471 \t( 0 s)\n",
      "====================================================================Episode: 716  started\n",
      "Step 16 @ Episode 716/1000 (15.0)\n",
      "Step: 16 \tState: [-0.0360964  -0.37548094  0.20729945  1.0472759 ] \tAction: [-0.93050194] \tReward: 1.0\n",
      "TD Error: -2.85486898422 \t( 0 s)\n",
      "====================================================================Episode: 717  started\n",
      "Step 13 @ Episode 717/1000 (17.0)\n",
      "Step: 13 \tState: [-0.03927229 -0.6209044   0.19341955  1.31006816] \tAction: [ 0.97498077] \tReward: 1.0\n",
      "TD Error: -3.95135154724 \t( 0 s)\n",
      "====================================================================Episode: 718  started\n",
      "Step 13 @ Episode 718/1000 (14.0)\n",
      "Step: 13 \tState: [-0.13278364 -0.60951663  0.19776789  1.24236529] \tAction: [ 0.29960829] \tReward: 1.0\n",
      "TD Error: -2.53246707916 \t( 0 s)\n",
      "====================================================================Episode: 719  started\n",
      "Step 21 @ Episode 719/1000 (14.0)\n",
      "Step: 21 \tState: [ 0.21866425  1.00062552 -0.18159537 -1.45324812] \tAction: [ 8.83912182] \tReward: 1.0\n",
      "TD Error: -0.787712287903 \t( 0 s)\n",
      "====================================================================Episode: 720  started\n",
      "Step 24 @ Episode 720/1000 (22.0)\n",
      "Step: 24 \tState: [-0.11278805 -0.8103306   0.195073    1.3184564 ] \tAction: [ 11.18078709] \tReward: 1.0\n",
      "TD Error: -3.79174289703 \t( 0 s)\n",
      "====================================================================Episode: 721  started\n",
      "Step 23 @ Episode 721/1000 (25.0)\n",
      "Step: 23 \tState: [ 0.09470053  0.6131564  -0.19906492 -1.33802378] \tAction: [-8.08751965] \tReward: 1.0\n",
      "TD Error: -5.79519309998 \t( 0 s)\n",
      "====================================================================Episode: 722  started\n",
      "Step 12 @ Episode 722/1000 (24.0)\n",
      "Step: 12 \tState: [ 0.06933159  0.80360183 -0.1899121  -1.50381061] \tAction: [-5.95084143] \tReward: 1.0\n",
      "TD Error: -9.92871589661 \t( 0 s)\n",
      "====================================================================Episode: 723  started\n",
      "Step 22 @ Episode 723/1000 (13.0)\n",
      "Step: 22 \tState: [ 0.17444655  1.98280425 -0.17218306 -2.80886311] \tAction: [ 3.30457616] \tReward: 1.0\n",
      "TD Error: -16.4583332062 \t( 0 s)\n",
      "====================================================================Episode: 724  started\n",
      "Step 23 @ Episode 724/1000 (23.0)\n",
      "Step: 23 \tState: [-0.13618394 -0.56616127  0.18901303  1.20847702] \tAction: [ 2.04721665] \tReward: 1.0\n",
      "TD Error: 0.193194961548 \t( 0 s)\n",
      "====================================================================Episode: 725  started\n",
      "Step 13 @ Episode 725/1000 (24.0)\n",
      "Step: 13 \tState: [ 0.18799701  1.41312348 -0.19993361 -2.24940681] \tAction: [ 1.99895954] \tReward: 1.0\n",
      "TD Error: -20.7882549286 \t( 0 s)\n",
      "====================================================================Episode: 726  started\n",
      "Step 16 @ Episode 726/1000 (14.0)\n",
      "Step: 16 \tState: [ 0.14670065  0.43016001 -0.19702309 -0.90406271] \tAction: [-10.61055565] \tReward: 1.0\n",
      "TD Error: -7.14832706451 \t( 0 s)\n",
      "====================================================================Episode: 727  started\n",
      "Step 7 @ Episode 727/1000 (17.0)\n",
      "Step: 7 \tState: [-0.09209274 -1.34307199  0.185712    2.26283262] \tAction: [ 9.92790127] \tReward: 1.0\n",
      "TD Error: -0.350817680359 \t( 0 s)\n",
      "====================================================================Episode: 728  started\n",
      "Step 21 @ Episode 728/1000 (8.0)\n",
      "Step: 21 \tState: [ 0.00624845  0.17833556  0.20313367  0.43780168] \tAction: [ 9.53236771] \tReward: 1.0\n",
      "TD Error: 3.88514022827 \t( 0 s)\n",
      "====================================================================Episode: 729  started\n",
      "Step 18 @ Episode 729/1000 (22.0)\n",
      "Step: 18 \tState: [-0.20335077 -1.1746116   0.20884448  1.95732512] \tAction: [ 22.26819038] \tReward: 1.0\n",
      "TD Error: 5.90908412933 \t( 0 s)\n",
      "====================================================================Episode: 730  started\n",
      "Step 15 @ Episode 730/1000 (19.0)\n",
      "Step: 15 \tState: [ 0.0997775   1.02090006 -0.1891093  -1.76711087] \tAction: [-3.88113403] \tReward: 1.0\n",
      "TD Error: 0.931815290451 \t( 0 s)\n",
      "====================================================================Episode: 731  started\n",
      "Step 9 @ Episode 731/1000 (16.0)\n",
      "Step: 9 \tState: [-0.09637113 -0.5946148   0.20465425  1.1917616 ] \tAction: [-4.54040003] \tReward: 1.0\n",
      "TD Error: -2.10142583847 \t( 0 s)\n",
      "====================================================================Episode: 732  started\n",
      "Step 14 @ Episode 732/1000 (10.0)\n",
      "Step: 14 \tState: [-0.14295958 -0.43702225  0.20261519  1.01241057] \tAction: [-6.35212088] \tReward: 1.0\n",
      "TD Error: -4.31729424 \t( 0 s)\n",
      "====================================================================Episode: 733  started\n",
      "Step 24 @ Episode 733/1000 (15.0)\n",
      "Step: 24 \tState: [-0.1547107  -0.43163265  0.20349561  1.00462237] \tAction: [ 17.19644356] \tReward: 1.0\n",
      "TD Error: -5.81067070961 \t( 0 s)\n",
      "====================================================================Episode: 734  started\n",
      "Step 18 @ Episode 734/1000 (25.0)\n",
      "Step: 18 \tState: [-0.1226158  -0.4460162   0.19694906  0.97699797] \tAction: [ 2.25056601] \tReward: 1.0\n",
      "TD Error: -6.2498623848 \t( 0 s)\n",
      "====================================================================Episode: 735  started\n",
      "Step 39 @ Episode 735/1000 (19.0)\n",
      "Step: 39 \tState: [ 0.14454621  0.59980339 -0.19183344 -1.21562018] \tAction: [-10.10439205] \tReward: 1.0\n",
      "TD Error: 0.603823184967 \t( 0 s)\n",
      "====================================================================Episode: 736  started\n",
      "Step 20 @ Episode 736/1000 (40.0)\n",
      "Step: 20 \tState: [-0.06455414  0.32722273  0.20875412  0.2403113 ] \tAction: [ 5.76451206] \tReward: 1.0\n",
      "TD Error: -0.259308052063 \t( 0 s)\n",
      "====================================================================Episode: 737  started\n",
      "Step 22 @ Episode 737/1000 (21.0)\n",
      "Step: 22 \tState: [-0.10976124 -1.58517934  0.20575291  2.4817952 ] \tAction: [ 7.18719149] \tReward: 1.0\n",
      "TD Error: -9.22007255554 \t( 0 s)\n",
      "====================================================================Episode: 738  started\n",
      "Step 19 @ Episode 738/1000 (23.0)\n",
      "Step: 19 \tState: [-0.16149377 -0.57153126  0.19731486  1.20632955] \tAction: [-0.17500101] \tReward: 1.0\n",
      "TD Error: -3.90136890411 \t( 0 s)\n",
      "====================================================================Episode: 739  started\n",
      "Step 15 @ Episode 739/1000 (20.0)\n",
      "Step: 15 \tState: [ 0.16511719  0.99023291 -0.20243911 -1.52402522] \tAction: [-4.99949169] \tReward: 1.0\n",
      "TD Error: -1.24345440865 \t( 0 s)\n",
      "====================================================================Episode: 740  started\n",
      "Step 12 @ Episode 740/1000 (16.0)\n",
      "Step: 12 \tState: [-0.13163645 -0.41252129  0.19539221  0.85128561] \tAction: [ 0.00814036] \tReward: 1.0\n",
      "TD Error: -1.8733253479 \t( 0 s)\n",
      "====================================================================Episode: 741  started\n",
      "Step 21 @ Episode 741/1000 (13.0)\n",
      "Step: 21 \tState: [ 0.10357276  0.55678058 -0.20264291 -1.14525156] \tAction: [-4.43495083] \tReward: 1.0\n",
      "TD Error: 0.321753740311 \t( 0 s)\n",
      "====================================================================Episode: 742  started\n",
      "Step 28 @ Episode 742/1000 (22.0)\n",
      "Step: 28 \tState: [-0.08636528 -0.84634133  0.18581637  1.73422542] \tAction: [ 12.06974792] \tReward: 1.0\n",
      "TD Error: -7.07428436279 \t( 0 s)\n",
      "====================================================================Episode: 743  started\n",
      "Step 19 @ Episode 743/1000 (29.0)\n",
      "Step: 19 \tState: [ 0.12140243  0.23564435 -0.20142142 -0.63924393] \tAction: [ 2.50943112] \tReward: 1.0\n",
      "TD Error: 0.554756498337 \t( 0 s)\n",
      "====================================================================Episode: 744  started\n",
      "Step 8 @ Episode 744/1000 (20.0)\n",
      "Step: 8 \tState: [-0.0908226  -0.74254213  0.18941846  1.38545511] \tAction: [ 1.27943695] \tReward: 1.0\n",
      "TD Error: -1.60786132812 \t( 0 s)\n",
      "====================================================================Episode: 745  started\n",
      "Step 27 @ Episode 745/1000 (9.0)\n",
      "Step: 27 \tState: [ 0.11239943  0.65100337 -0.18662036 -1.27367634] \tAction: [-16.14344597] \tReward: 1.0\n",
      "TD Error: -0.766303896904 \t( 0 s)\n",
      "====================================================================Episode: 746  started\n",
      "Step 28 @ Episode 746/1000 (28.0)\n",
      "Step: 28 \tState: [-0.18694295 -0.73015915  0.20478368  1.18338593] \tAction: [-19.83672523] \tReward: 1.0\n",
      "TD Error: 8.87124214172 \t( 0 s)\n",
      "====================================================================Episode: 747  started\n",
      "Step 31 @ Episode 747/1000 (29.0)\n",
      "Step: 31 \tState: [-0.1321509  -0.59512275  0.20680046  1.25260605] \tAction: [-2.89604044] \tReward: 1.0\n",
      "TD Error: 7.97690467834 \t( 0 s)\n",
      "====================================================================Episode: 748  started\n",
      "Step 17 @ Episode 748/1000 (32.0)\n",
      "Step: 17 \tState: [-0.11009141 -0.63068009  0.2042891   1.0997104 ] \tAction: [-4.92779398] \tReward: 1.0\n",
      "TD Error: 7.994323349 \t( 0 s)\n",
      "====================================================================Episode: 749  started\n",
      "Step 22 @ Episode 749/1000 (18.0)\n",
      "Step: 22 \tState: [ 0.09949324  0.42757569 -0.18825986 -1.13675963] \tAction: [ 1.89592731] \tReward: 1.0\n",
      "TD Error: -0.85131111145 \t( 0 s)\n",
      "====================================================================Episode: 750  started\n",
      "Step 12 @ Episode 750/1000 (23.0)\n",
      "Step: 12 \tState: [-0.09174793 -1.19592204  0.17582802  1.86733187] \tAction: [ 4.22727966] \tReward: 1.0\n",
      "TD Error: 1.88820228577 \t( 0 s)\n",
      "====================================================================Episode: 751  started\n",
      "Step 14 @ Episode 751/1000 (13.0)\n",
      "Step: 14 \tState: [-0.17006894 -1.16714161  0.18529999  1.87430415] \tAction: [ 0.47328088] \tReward: 1.0\n",
      "TD Error: 8.95093650818 \t( 0 s)\n",
      "====================================================================Episode: 752  started\n",
      "Step 28 @ Episode 752/1000 (15.0)\n",
      "Step: 28 \tState: [ 0.19939769  0.76617399 -0.19388287 -1.41214518] \tAction: [-1.75506079] \tReward: 1.0\n",
      "TD Error: -1.92270974517 \t( 0 s)\n",
      "====================================================================Episode: 753  started\n",
      "Step 14 @ Episode 753/1000 (29.0)\n",
      "Step: 14 \tState: [ 0.05837885  0.77791151 -0.19450418 -1.4897073 ] \tAction: [-0.29981622] \tReward: 1.0\n",
      "TD Error: -1.36308200359 \t( 0 s)\n",
      "====================================================================Episode: 754  started\n",
      "Step 14 @ Episode 754/1000 (15.0)\n",
      "Step: 14 \tState: [-0.09052147 -0.83348097  0.1846605   1.4191659 ] \tAction: [ 6.97142315] \tReward: 1.0\n",
      "TD Error: 1.72824649811 \t( 0 s)\n",
      "====================================================================Episode: 755  started\n",
      "Step 18 @ Episode 755/1000 (15.0)\n",
      "Step: 18 \tState: [ 0.1474669   0.7456519  -0.1883914  -1.37884431] \tAction: [-9.2728653] \tReward: 1.0\n",
      "TD Error: 0.488231277466 \t( 0 s)\n",
      "====================================================================Episode: 756  started\n",
      "Step 15 @ Episode 756/1000 (19.0)\n",
      "Step: 15 \tState: [ 0.07394466  0.6468232  -0.19063649 -1.25438488] \tAction: [-3.82163143] \tReward: 1.0\n",
      "TD Error: 1.73191404343 \t( 0 s)\n",
      "====================================================================Episode: 757  started\n",
      "Step 26 @ Episode 757/1000 (16.0)\n",
      "Step: 26 \tState: [ 0.12479374  1.21297953 -0.20125111 -1.80678101] \tAction: [ 14.63354206] \tReward: 1.0\n",
      "TD Error: -0.720066833496 \t( 0 s)\n",
      "====================================================================Episode: 758  started\n",
      "Step 13 @ Episode 758/1000 (27.0)\n",
      "Step: 13 \tState: [-0.12675247 -0.96608922  0.18775036  1.56397304] \tAction: [ 0.25245166] \tReward: 1.0\n",
      "TD Error: -2.12586717606 \t( 0 s)\n",
      "====================================================================Episode: 759  started\n",
      "Step 20 @ Episode 759/1000 (14.0)\n",
      "Step: 20 \tState: [ 0.05236732  0.7787042  -0.18980328 -1.62285089] \tAction: [-5.33771801] \tReward: 1.0\n",
      "TD Error: 2.66248631477 \t( 0 s)\n",
      "====================================================================Episode: 760  started\n",
      "Step 17 @ Episode 760/1000 (21.0)\n",
      "Step: 17 \tState: [-0.15139509 -1.0300705   0.19556608  1.70868898] \tAction: [ 8.90265179] \tReward: 1.0\n",
      "TD Error: 0.443418502808 \t( 0 s)\n",
      "====================================================================Episode: 761  started\n",
      "Step 9 @ Episode 761/1000 (18.0)\n",
      "Step: 9 \tState: [-0.0554878  -1.01477122  0.19800145  1.72521059] \tAction: [ 8.4973917] \tReward: 1.0\n",
      "TD Error: 0.448759651184 \t( 0 s)\n",
      "====================================================================Episode: 762  started\n",
      "Step 22 @ Episode 762/1000 (10.0)\n",
      "Step: 22 \tState: [-0.10374365 -0.07193225  0.2051412   0.57081277] \tAction: [-5.07876396] \tReward: 1.0\n",
      "TD Error: 1.22307281494 \t( 0 s)\n",
      "====================================================================Episode: 763  started\n",
      "Step 94 @ Episode 763/1000 (23.0)\n",
      "Step: 94 \tState: [ 0.00432953 -1.95844804  0.20316487  2.82197055] \tAction: [ 5.19784498] \tReward: 1.0\n",
      "TD Error: -8.28791456223 \t( 1 s)\n",
      "====================================================================Episode: 764  started\n",
      "Step 8 @ Episode 764/1000 (95.0)\n",
      "Step: 8 \tState: [ 0.13091506  1.13509274 -0.18919957 -1.93314274] \tAction: [-2.51972532] \tReward: 1.0\n",
      "TD Error: -2.48197317123 \t( 0 s)\n",
      "====================================================================Episode: 765  started\n",
      "Step 9 @ Episode 765/1000 (9.0)\n",
      "Step: 9 \tState: [-0.09851956 -1.74687335  0.19002663  2.71883091] \tAction: [-2.18481731] \tReward: 1.0\n",
      "TD Error: 0.0969036102295 \t( 0 s)\n",
      "====================================================================Episode: 766  started\n",
      "Step 22 @ Episode 766/1000 (10.0)\n",
      "Step: 22 \tState: [-0.25456034 -1.98579593  0.18492812  2.67288188] \tAction: [-6.09612942] \tReward: 1.0\n",
      "TD Error: 8.29610748291 \t( 0 s)\n",
      "====================================================================Episode: 767  started\n",
      "Step 37 @ Episode 767/1000 (23.0)\n",
      "Step: 37 \tState: [-0.16274788 -0.99338989  0.20141361  1.62207422] \tAction: [ 8.4324379] \tReward: 1.0\n",
      "TD Error: 4.12807674408 \t( 0 s)\n",
      "====================================================================Episode: 768  started\n",
      "Step 25 @ Episode 768/1000 (38.0)\n",
      "Step: 25 \tState: [ 0.08847795  0.64236571 -0.1897784  -1.3305217 ] \tAction: [-0.76841819] \tReward: 1.0\n",
      "TD Error: -2.55679531097 \t( 0 s)\n",
      "====================================================================Episode: 769  started\n",
      "Step 11 @ Episode 769/1000 (26.0)\n",
      "Step: 11 \tState: [-0.18790324 -1.73493582  0.1885558   2.6838464 ] \tAction: [-7.95315933] \tReward: 1.0\n",
      "TD Error: 2.85389995575 \t( 0 s)\n",
      "====================================================================Episode: 770  started\n",
      "Step 26 @ Episode 770/1000 (12.0)\n",
      "Step: 26 \tState: [ 0.13485798  0.35590927 -0.1972472  -0.90378945] \tAction: [-3.65931535] \tReward: 1.0\n",
      "TD Error: -1.07300453186 \t( 0 s)\n",
      "====================================================================Episode: 771  started\n",
      "Step 61 @ Episode 771/1000 (27.0)\n",
      "Step: 61 \tState: [-0.16778426  1.0243845  -0.18132605 -1.85781993] \tAction: [-3.9265883] \tReward: 1.0\n",
      "TD Error: 0.797060251236 \t( 1 s)\n",
      "====================================================================Episode: 772  started\n",
      "Step 18 @ Episode 772/1000 (62.0)\n",
      "Step: 18 \tState: [ 0.1855792   0.41652538 -0.20288043 -0.90413556] \tAction: [ 3.03065014] \tReward: 1.0\n",
      "TD Error: -1.56956124306 \t( 0 s)\n",
      "====================================================================Episode: 773  started\n",
      "Step 22 @ Episode 773/1000 (19.0)\n",
      "Step: 22 \tState: [-0.10873673 -0.79035309  0.19663882  1.54026607] \tAction: [-7.8671875] \tReward: 1.0\n",
      "TD Error: -4.36157560349 \t( 0 s)\n",
      "====================================================================Episode: 774  started\n",
      "Step 18 @ Episode 774/1000 (23.0)\n",
      "Step: 18 \tState: [-0.08816187 -1.19906976  0.20618939  2.0827127 ] \tAction: [ 1.75859356] \tReward: 1.0\n",
      "TD Error: -2.81844091415 \t( 0 s)\n",
      "====================================================================Episode: 775  started\n",
      "Step 19 @ Episode 775/1000 (19.0)\n",
      "Step: 19 \tState: [-0.04944805  0.16931273  0.2060159   0.33610663] \tAction: [ 0.69966668] \tReward: 1.0\n",
      "TD Error: 1.22095432281 \t( 0 s)\n",
      "====================================================================Episode: 776  started\n",
      "Step 21 @ Episode 776/1000 (20.0)\n",
      "Step: 21 \tState: [-0.05533254 -0.59452758  0.19561674  1.17581264] \tAction: [ 14.5676775] \tReward: 1.0\n",
      "TD Error: -2.70447044373 \t( 0 s)\n",
      "====================================================================Episode: 777  started\n",
      "Step 22 @ Episode 777/1000 (22.0)\n",
      "Step: 22 \tState: [-0.09271764 -1.13638452  0.18611346  2.06693044] \tAction: [-8.80729008] \tReward: 1.0\n",
      "TD Error: -5.58886060715 \t( 0 s)\n",
      "====================================================================Episode: 778  started\n",
      "Step 24 @ Episode 778/1000 (23.0)\n",
      "Step: 24 \tState: [-0.0250004  -0.39236406 -0.20911526 -0.38441237] \tAction: [-8.34760666] \tReward: 1.0\n",
      "TD Error: -0.321539402008 \t( 0 s)\n",
      "====================================================================Episode: 779  started\n",
      "Step 16 @ Episode 779/1000 (25.0)\n",
      "Step: 16 \tState: [-0.05043162 -0.75147022  0.20261578  1.43436623] \tAction: [ 8.25336075] \tReward: 1.0\n",
      "TD Error: -1.60432376862 \t( 0 s)\n",
      "====================================================================Episode: 780  started\n",
      "Step 28 @ Episode 780/1000 (17.0)\n",
      "Step: 28 \tState: [ 0.02224137  0.76581199 -0.17941264 -1.78413807] \tAction: [ 13.37708855] \tReward: 1.0\n",
      "TD Error: -0.561867141724 \t( 0 s)\n",
      "====================================================================Episode: 781  started\n",
      "Step 23 @ Episode 781/1000 (29.0)\n",
      "Step: 23 \tState: [ 0.1839963   0.94888362 -0.19037675 -1.58281525] \tAction: [-6.67189884] \tReward: 1.0\n",
      "TD Error: -6.19695281982 \t( 0 s)\n",
      "====================================================================Episode: 782  started\n",
      "Step 15 @ Episode 782/1000 (24.0)\n",
      "Step: 15 \tState: [ 0.07440655  0.94145059 -0.1868354  -1.63001202] \tAction: [-7.42985725] \tReward: 1.0\n",
      "TD Error: -4.64964513779 \t( 0 s)\n",
      "====================================================================Episode: 783  started\n",
      "Step 15 @ Episode 783/1000 (16.0)\n",
      "Step: 15 \tState: [ 0.12436559  1.39184874 -0.18866665 -2.09026184] \tAction: [-2.64118648] \tReward: 1.0\n",
      "TD Error: -6.11389970779 \t( 0 s)\n",
      "====================================================================Episode: 784  started\n",
      "Step 35 @ Episode 784/1000 (16.0)\n",
      "Step: 35 \tState: [ 0.00191486 -0.25005244  0.1914818   1.13050506] \tAction: [ 5.55091667] \tReward: 1.0\n",
      "TD Error: -1.35814304352 \t( 0 s)\n",
      "====================================================================Episode: 785  started\n",
      "Step 27 @ Episode 785/1000 (36.0)\n",
      "Step: 27 \tState: [-0.13344247 -0.20097808  0.19795281  0.7861256 ] \tAction: [ 2.79686069] \tReward: 1.0\n",
      "TD Error: 0.972560119629 \t( 0 s)\n",
      "====================================================================Episode: 786  started\n",
      "Step 11 @ Episode 786/1000 (28.0)\n",
      "Step: 11 \tState: [-0.08868037 -0.97839542  0.19831221  1.74947066] \tAction: [-9.30085564] \tReward: 1.0\n",
      "TD Error: -1.25668678284 \t( 0 s)\n",
      "====================================================================Episode: 787  started\n",
      "Step 13 @ Episode 787/1000 (12.0)\n",
      "Step: 13 \tState: [-0.06814964 -1.380105    0.20447428  2.295825  ] \tAction: [ 1.78125548] \tReward: 1.0\n",
      "TD Error: 0.288785362244 \t( 0 s)\n",
      "====================================================================Episode: 788  started\n",
      "Step 48 @ Episode 788/1000 (14.0)\n",
      "Step: 48 \tState: [-0.48335    -1.14632324  0.1971915   0.99804493] \tAction: [ 22.42737961] \tReward: 1.0\n",
      "TD Error: 3.22227668762 \t( 1 s)\n",
      "====================================================================Episode: 789  started\n",
      "Step 28 @ Episode 789/1000 (49.0)\n",
      "Step: 28 \tState: [ 0.01579836 -0.41085605  0.18145834  1.45437141] \tAction: [ 13.44215584] \tReward: 1.0\n",
      "TD Error: -5.46597642899 \t( 0 s)\n",
      "====================================================================Episode: 790  started\n",
      "Step 16 @ Episode 790/1000 (29.0)\n",
      "Step: 16 \tState: [-0.11334858 -0.41901954  0.19678235  0.87526   ] \tAction: [-1.28009832] \tReward: 1.0\n",
      "TD Error: -1.81652898788 \t( 0 s)\n",
      "====================================================================Episode: 791  started\n",
      "Step 14 @ Episode 791/1000 (17.0)\n",
      "Step: 14 \tState: [ 0.04268688  0.36815925 -0.2036858  -0.98001779] \tAction: [ 0.09910467] \tReward: 1.0\n",
      "TD Error: -2.54446773529 \t( 0 s)\n",
      "====================================================================Episode: 792  started\n",
      "Step 10 @ Episode 792/1000 (15.0)\n",
      "Step: 10 \tState: [-0.11640568 -0.80159024  0.18111408  1.42341847] \tAction: [-4.56005335] \tReward: 1.0\n",
      "TD Error: -2.45993309021 \t( 0 s)\n",
      "====================================================================Episode: 793  started\n",
      "Step 30 @ Episode 793/1000 (11.0)\n",
      "Step: 30 \tState: [ 0.07382435  0.44065883 -0.19304227 -1.25066582] \tAction: [-1.06632423] \tReward: 1.0\n",
      "TD Error: -3.833568573 \t( 0 s)\n",
      "====================================================================Episode: 794  started\n",
      "Step 22 @ Episode 794/1000 (31.0)\n",
      "Step: 22 \tState: [ 0.11179609 -0.02497715 -0.20735836 -0.36246552] \tAction: [ 8.67291641] \tReward: 1.0\n",
      "TD Error: -2.46176643372 \t( 0 s)\n",
      "====================================================================Episode: 795  started\n",
      "Step 20 @ Episode 795/1000 (23.0)\n",
      "Step: 20 \tState: [-0.18251882 -0.82342213  0.18686963  1.22869844] \tAction: [ 5.99162436] \tReward: 1.0\n",
      "TD Error: 0.605940628052 \t( 0 s)\n",
      "====================================================================Episode: 796  started\n",
      "Step 17 @ Episode 796/1000 (21.0)\n",
      "Step: 17 \tState: [-0.07240008 -1.02049149  0.19536821  1.82383738] \tAction: [-11.07291698] \tReward: 1.0\n",
      "TD Error: 0.458778953552 \t( 0 s)\n",
      "====================================================================Episode: 797  started\n",
      "Step 55 @ Episode 797/1000 (18.0)\n",
      "Step: 55 \tState: [ 0.44296533 -0.22505746  0.18516051  1.61630075] \tAction: [-9.38607407] \tReward: 1.0\n",
      "TD Error: -8.3509680748 \t( 1 s)\n",
      "====================================================================Episode: 798  started\n",
      "Step 16 @ Episode 798/1000 (56.0)\n",
      "Step: 16 \tState: [-0.16121948 -0.74968069  0.20394803  1.46532552] \tAction: [-3.49927831] \tReward: 1.0\n",
      "TD Error: -4.05046024323 \t( 0 s)\n",
      "====================================================================Episode: 799  started\n",
      "Step 23 @ Episode 799/1000 (17.0)\n",
      "Step: 23 \tState: [-0.04780345 -0.24283282  0.19846475  1.10910351] \tAction: [-1.75525045] \tReward: 1.0\n",
      "TD Error: -3.56369409561 \t( 0 s)\n",
      "====================================================================Episode: 800  started\n",
      "Step 9 @ Episode 800/1000 (24.0)\n",
      "Step: 9 \tState: [ 0.11465249  0.61853493 -0.19613988 -1.08448821] \tAction: [ 9.91083145] \tReward: 1.0\n",
      "TD Error: -2.08588533401 \t( 0 s)\n",
      "====================================================================Episode: 801  started\n",
      "Step 14 @ Episode 801/1000 (10.0)\n",
      "Step: 14 \tState: [-0.17693659 -1.21146575  0.18445595  1.93956802] \tAction: [-9.23449802] \tReward: 1.0\n",
      "TD Error: -5.09264535904 \t( 0 s)\n",
      "====================================================================Episode: 802  started\n",
      "Step 86 @ Episode 802/1000 (15.0)\n",
      "Step: 86 \tState: [-0.2488037  -1.51711989  0.20142568  2.14619254] \tAction: [-3.98590899] \tReward: 1.0\n",
      "TD Error: -3.38624210358 \t( 1 s)\n",
      "====================================================================Episode: 803  started\n",
      "Step 20 @ Episode 803/1000 (87.0)\n",
      "Step: 20 \tState: [-0.03598388 -0.45463464  0.20102061  1.13241748] \tAction: [-0.33563334] \tReward: 1.0\n",
      "TD Error: 0.141816329956 \t( 0 s)\n",
      "====================================================================Episode: 804  started\n",
      "Step 23 @ Episode 804/1000 (21.0)\n",
      "Step: 23 \tState: [-0.17612602 -1.40243299  0.19317241  2.06145045] \tAction: [ 16.68102264] \tReward: 1.0\n",
      "TD Error: 1.40036067963 \t( 0 s)\n",
      "====================================================================Episode: 805  started\n",
      "Step 16 @ Episode 805/1000 (24.0)\n",
      "Step: 16 \tState: [-0.06481285 -0.00262807  0.2073344   0.38731319] \tAction: [-5.72354937] \tReward: 1.0\n",
      "TD Error: 2.94100151062 \t( 0 s)\n",
      "====================================================================Episode: 806  started\n",
      "Step 20 @ Episode 806/1000 (17.0)\n",
      "Step: 20 \tState: [-0.11431709 -0.44132705  0.20796635  0.95817756] \tAction: [ 11.35999489] \tReward: 1.0\n",
      "TD Error: 1.44351997375 \t( 0 s)\n",
      "====================================================================Episode: 807  started\n",
      "Step 7 @ Episode 807/1000 (21.0)\n",
      "Step: 7 \tState: [-0.04860748 -1.393276    0.16957897  2.17116842] \tAction: [ 19.15898132] \tReward: 1.0\n",
      "TD Error: -1.08855838776 \t( 0 s)\n",
      "====================================================================Episode: 808  started\n",
      "Step 13 @ Episode 808/1000 (8.0)\n",
      "Step: 13 \tState: [-0.10268646 -0.26209222  0.20213397  0.78582674] \tAction: [-1.1837548] \tReward: 1.0\n",
      "TD Error: 0.397242259979 \t( 0 s)\n",
      "====================================================================Episode: 809  started\n",
      "Step 13 @ Episode 809/1000 (14.0)\n",
      "Step: 13 \tState: [-0.11698596 -0.94905168  0.20479826  1.58826929] \tAction: [-12.93504238] \tReward: 1.0\n",
      "TD Error: -1.73975753784 \t( 0 s)\n",
      "====================================================================Episode: 810  started\n",
      "Step 23 @ Episode 810/1000 (14.0)\n",
      "Step: 23 \tState: [-0.18386506 -1.36206912  0.17354524  1.9433301 ] \tAction: [ 5.94670248] \tReward: 1.0\n",
      "TD Error: -1.94022622108 \t( 0 s)\n",
      "====================================================================Episode: 811  started\n",
      "Step 14 @ Episode 811/1000 (24.0)\n",
      "Step: 14 \tState: [-0.13888235 -0.82527277  0.18242535  1.3694463 ] \tAction: [ 3.71499062] \tReward: 1.0\n",
      "TD Error: -2.61081161499 \t( 0 s)\n",
      "====================================================================Episode: 812  started\n",
      "Step 53 @ Episode 812/1000 (15.0)\n",
      "Step: 53 \tState: [ 0.25573703  0.48718941  0.20064634  0.5276682 ] \tAction: [ 9.86750984] \tReward: 1.0\n",
      "TD Error: -2.04106850624 \t( 1 s)\n",
      "====================================================================Episode: 813  started\n",
      "Step 21 @ Episode 813/1000 (54.0)\n",
      "Step: 21 \tState: [ 0.05296828  0.18966542 -0.20097121 -1.14847808] \tAction: [-7.58630705] \tReward: 1.0\n",
      "TD Error: -4.72043495178 \t( 0 s)\n",
      "====================================================================Episode: 814  started\n",
      "Step 40 @ Episode 814/1000 (22.0)\n",
      "Step: 40 \tState: [ 0.25215471  1.50006165 -0.18308167 -1.77466754] \tAction: [ 3.24071169] \tReward: 1.0\n",
      "TD Error: -4.10852189064 \t( 0 s)\n",
      "====================================================================Episode: 815  started\n",
      "Step 22 @ Episode 815/1000 (41.0)\n",
      "Step: 22 \tState: [-0.12871899 -0.81194624  0.18160108  1.43421133] \tAction: [-2.3552165] \tReward: 1.0\n",
      "TD Error: -7.44782164097 \t( 0 s)\n",
      "====================================================================Episode: 816  started\n",
      "Step 8 @ Episode 816/1000 (23.0)\n",
      "Step: 8 \tState: [-0.11482361 -1.14330849  0.17228708  1.91061984] \tAction: [-2.81150746] \tReward: 1.0\n",
      "TD Error: -6.9899312973 \t( 0 s)\n",
      "====================================================================Episode: 817  started\n",
      "Step 38 @ Episode 817/1000 (9.0)\n",
      "Step: 38 \tState: [-0.06692112  0.00314415 -0.1995012  -0.86482469] \tAction: [ 6.27108812] \tReward: 1.0\n",
      "TD Error: -4.39990177155 \t( 0 s)\n",
      "====================================================================Episode: 818  started\n",
      "Step 27 @ Episode 818/1000 (39.0)\n",
      "Step: 27 \tState: [ 0.0098049  -0.97409865  0.17211013  1.96211694] \tAction: [-5.49988985] \tReward: 1.0\n",
      "TD Error: -5.34804267883 \t( 0 s)\n",
      "====================================================================Episode: 819  started\n",
      "Step 12 @ Episode 819/1000 (28.0)\n",
      "Step: 12 \tState: [ 0.10485104  1.16842911 -0.20889277 -1.95792251] \tAction: [-6.40155172] \tReward: 1.0\n",
      "TD Error: -15.1787436008 \t( 0 s)\n",
      "====================================================================Episode: 820  started\n",
      "Step 16 @ Episode 820/1000 (13.0)\n",
      "Step: 16 \tState: [-0.06331364 -1.19065929  0.18072927  2.08291162] \tAction: [-4.38048124] \tReward: 1.0\n",
      "TD Error: 3.2345161438 \t( 0 s)\n",
      "====================================================================Episode: 821  started\n",
      "Step 45 @ Episode 821/1000 (17.0)\n",
      "Step: 45 \tState: [-0.16745465 -1.03567922  0.19639285  1.72822252] \tAction: [-6.94604254] \tReward: 1.0\n",
      "TD Error: 9.92827033997 \t( 0 s)\n",
      "====================================================================Episode: 822  started\n",
      "Step 16 @ Episode 822/1000 (46.0)\n",
      "Step: 16 \tState: [-0.04053837 -0.45623057  0.1925127   1.11658596] \tAction: [-5.39318323] \tReward: 1.0\n",
      "TD Error: 5.44981117249 \t( 0 s)\n",
      "====================================================================Episode: 823  started\n",
      "Step 27 @ Episode 823/1000 (17.0)\n",
      "Step: 27 \tState: [ 0.0522589  -0.12923637 -0.20332687 -0.54947773] \tAction: [ 6.86820793] \tReward: 1.0\n",
      "TD Error: 0.00922803878784 \t( 0 s)\n",
      "====================================================================Episode: 824  started\n",
      "Step 10 @ Episode 824/1000 (28.0)\n",
      "Step: 10 \tState: [-0.12654389 -0.7512741   0.18693202  1.39013482] \tAction: [ 27.19508362] \tReward: 1.0\n",
      "TD Error: 0.337943553925 \t( 0 s)\n",
      "====================================================================Episode: 825  started\n",
      "Step 31 @ Episode 825/1000 (11.0)\n",
      "Step: 31 \tState: [ 0.08499135  0.65641379 -0.19929393 -1.47142666] \tAction: [-22.43611526] \tReward: 1.0\n",
      "TD Error: -4.48134975433 \t( 0 s)\n",
      "====================================================================Episode: 826  started\n",
      "Step 23 @ Episode 826/1000 (32.0)\n",
      "Step: 23 \tState: [-0.02118558 -0.26225154  0.2051755   0.95983515] \tAction: [-15.59052086] \tReward: 1.0\n",
      "TD Error: -2.03515176773 \t( 0 s)\n",
      "====================================================================Episode: 827  started\n",
      "Step 13 @ Episode 827/1000 (24.0)\n",
      "Step: 13 \tState: [-0.16367718 -0.94054687  0.20679188  1.72174106] \tAction: [ 0.45430082] \tReward: 1.0\n",
      "TD Error: -3.47057222724 \t( 0 s)\n",
      "====================================================================Episode: 828  started\n",
      "Step 22 @ Episode 828/1000 (14.0)\n",
      "Step: 22 \tState: [-0.11350581 -0.43226329  0.20155733  1.142703  ] \tAction: [ 1.47323811] \tReward: 1.0\n",
      "TD Error: -2.70193464756 \t( 0 s)\n",
      "====================================================================Episode: 829  started\n",
      "Step 30 @ Episode 829/1000 (23.0)\n",
      "Step: 30 \tState: [-0.04904679 -0.38571906  0.19173277  1.20474484] \tAction: [-0.94835258] \tReward: 1.0\n",
      "TD Error: -3.84612431526 \t( 0 s)\n",
      "====================================================================Episode: 830  started\n",
      "Step 20 @ Episode 830/1000 (31.0)\n",
      "Step: 20 \tState: [ 0.04972562  0.44652856 -0.20828701 -1.03467099] \tAction: [ 9.07304859] \tReward: 1.0\n",
      "TD Error: -1.17090854645 \t( 0 s)\n",
      "====================================================================Episode: 831  started\n",
      "Step 26 @ Episode 831/1000 (21.0)\n",
      "Step: 26 \tState: [-0.10301536 -0.7925123   0.19423843  1.61932974] \tAction: [ 9.07236004] \tReward: 1.0\n",
      "TD Error: -4.03076725006 \t( 0 s)\n",
      "====================================================================Episode: 832  started\n",
      "Step 14 @ Episode 832/1000 (27.0)\n",
      "Step: 14 \tState: [ 0.05763833  0.37606513 -0.18994793 -1.08809498] \tAction: [ 7.50837326] \tReward: 1.0\n",
      "TD Error: 0.522720718384 \t( 0 s)\n",
      "====================================================================Episode: 833  started\n",
      "Step 15 @ Episode 833/1000 (15.0)\n",
      "Step: 15 \tState: [-0.11249148 -0.97622479  0.1985796   1.62695618] \tAction: [ 9.81937981] \tReward: 1.0\n",
      "TD Error: -1.02707424164 \t( 0 s)\n",
      "====================================================================Episode: 834  started\n",
      "Step 9 @ Episode 834/1000 (16.0)\n",
      "Step: 9 \tState: [-0.1557554  -1.80621824  0.17880287  2.70664466] \tAction: [-0.32299522] \tReward: 1.0\n",
      "TD Error: 0.191695976257 \t( 0 s)\n",
      "====================================================================Episode: 835  started\n",
      "Step 78 @ Episode 835/1000 (10.0)\n",
      "Step: 78 \tState: [-0.15250922 -0.46080427  0.19143778  1.31147048] \tAction: [ 7.94584131] \tReward: 1.0\n",
      "TD Error: -3.47056350708 \t( 1 s)\n",
      "====================================================================Episode: 836  started\n",
      "Step 15 @ Episode 836/1000 (79.0)\n",
      "Step: 15 \tState: [-0.17379691 -1.02784031  0.20153843  1.75304645] \tAction: [ 2.39292455] \tReward: 1.0\n",
      "TD Error: 0.730006217957 \t( 0 s)\n",
      "====================================================================Episode: 837  started\n",
      "Step 17 @ Episode 837/1000 (16.0)\n",
      "Step: 17 \tState: [-0.05787713 -0.56377195  0.19825855  1.36810348] \tAction: [ 11.39691353] \tReward: 1.0\n",
      "TD Error: 2.17118873596 \t( 0 s)\n",
      "====================================================================Episode: 838  started\n",
      "Step 15 @ Episode 838/1000 (18.0)\n",
      "Step: 15 \tState: [-0.13732391 -0.62065969  0.19801683  1.04386668] \tAction: [-2.82670116] \tReward: 1.0\n",
      "TD Error: 3.52517089844 \t( 0 s)\n",
      "====================================================================Episode: 839  started\n",
      "Step 26 @ Episode 839/1000 (16.0)\n",
      "Step: 26 \tState: [-0.19672906 -1.58099144  0.17634751  2.06801348] \tAction: [ 4.23764467] \tReward: 1.0\n",
      "TD Error: 4.8793258667 \t( 0 s)\n",
      "====================================================================Episode: 840  started\n",
      "Step 12 @ Episode 840/1000 (27.0)\n",
      "Step: 12 \tState: [-0.12490834 -1.22049568  0.20572939  1.90417778] \tAction: [ 1.81562126] \tReward: 1.0\n",
      "TD Error: 7.78583850861 \t( 0 s)\n",
      "====================================================================Episode: 841  started\n",
      "Step 10 @ Episode 841/1000 (13.0)\n",
      "Step: 10 \tState: [ 0.10010244  0.39789388 -0.20238918 -0.8480834 ] \tAction: [ 12.60792446] \tReward: 1.0\n",
      "TD Error: -1.10707960129 \t( 0 s)\n",
      "====================================================================Episode: 842  started\n",
      "Step 22 @ Episode 842/1000 (11.0)\n",
      "Step: 22 \tState: [-0.14711265 -1.15951885  0.19911353  1.96414872] \tAction: [-11.43896198] \tReward: 1.0\n",
      "TD Error: 1.48552742004 \t( 0 s)\n",
      "====================================================================Episode: 843  started\n",
      "Step 13 @ Episode 843/1000 (23.0)\n",
      "Step: 13 \tState: [-0.12205502 -1.32842429  0.19919842  2.27196225] \tAction: [ 3.98920774] \tReward: 1.0\n",
      "TD Error: -1.91045064926 \t( 0 s)\n",
      "====================================================================Episode: 844  started\n",
      "Step 29 @ Episode 844/1000 (14.0)\n",
      "Step: 29 \tState: [-0.02002558 -0.1415406  -0.20784056 -0.63008157] \tAction: [ 12.63463211] \tReward: 1.0\n",
      "TD Error: -1.88916703761 \t( 0 s)\n",
      "====================================================================Episode: 845  started\n",
      "Step 14 @ Episode 845/1000 (30.0)\n",
      "Step: 14 \tState: [-0.10106393 -1.13295458  0.20189302  1.86502656] \tAction: [-14.16482925] \tReward: 1.0\n",
      "TD Error: -3.32003750801 \t( 0 s)\n",
      "====================================================================Episode: 846  started\n",
      "Step 26 @ Episode 846/1000 (15.0)\n",
      "Step: 26 \tState: [-0.13430681 -1.56394046  0.20812101  2.648426  ] \tAction: [-3.78333926] \tReward: 1.0\n",
      "TD Error: -4.89806675911 \t( 0 s)\n",
      "====================================================================Episode: 847  started\n",
      "Step 29 @ Episode 847/1000 (27.0)\n",
      "Step: 29 \tState: [ 0.07691325 -0.16396838 -0.2018104  -0.39706907] \tAction: [-3.27079248] \tReward: 1.0\n",
      "TD Error: -0.0885574817657 \t( 1 s)\n",
      "====================================================================Episode: 848  started\n",
      "Step 19 @ Episode 848/1000 (30.0)\n",
      "Step: 19 \tState: [-0.14154526 -0.96452981  0.19798384  1.63836897] \tAction: [-2.53814387] \tReward: 1.0\n",
      "TD Error: -2.59762229919 \t( 0 s)\n",
      "====================================================================Episode: 849  started\n",
      "Step 62 @ Episode 849/1000 (20.0)\n",
      "Step: 62 \tState: [ 0.25265083 -0.03105639  0.20723825  1.15778107] \tAction: [ 9.9297781] \tReward: 1.0\n",
      "TD Error: -3.66396522522 \t( 1 s)\n",
      "====================================================================Episode: 850  started\n",
      "Step 25 @ Episode 850/1000 (63.0)\n",
      "Step: 25 \tState: [ 0.01615198 -0.20717441 -0.20476015 -0.33630142] \tAction: [-8.04357815] \tReward: 1.0\n",
      "TD Error: -0.131044626236 \t( 0 s)\n",
      "====================================================================Episode: 851  started\n",
      "Step 10 @ Episode 851/1000 (26.0)\n",
      "Step: 10 \tState: [-0.17285901 -1.16150732  0.19557798  1.88079374] \tAction: [-5.78801489] \tReward: 1.0\n",
      "TD Error: 2.82968940735 \t( 0 s)\n",
      "====================================================================Episode: 852  started\n",
      "Step 17 @ Episode 852/1000 (11.0)\n",
      "Step: 17 \tState: [ 0.09431467 -0.16340027 -0.20628554 -0.34325048] \tAction: [ 8.42995358] \tReward: 1.0\n",
      "TD Error: -0.278056287766 \t( 0 s)\n",
      "====================================================================Episode: 853  started\n",
      "Step 55 @ Episode 853/1000 (18.0)\n",
      "Step: 55 \tState: [ 0.16583843  1.3140338  -0.17650202 -1.87873297] \tAction: [ 1.84097171] \tReward: 1.0\n",
      "TD Error: -10.0353388548 \t( 1 s)\n",
      "====================================================================Episode: 854  started\n",
      "Step 14 @ Episode 854/1000 (56.0)\n",
      "Step: 14 \tState: [-0.21163265 -0.8345003   0.20837123  1.44381505] \tAction: [-17.14861298] \tReward: 1.0\n",
      "TD Error: 2.97478103638 \t( 0 s)\n",
      "====================================================================Episode: 855  started\n",
      "Step 14 @ Episode 855/1000 (15.0)\n",
      "Step: 14 \tState: [ 0.20392118  1.20445462 -0.19615323 -1.90731879] \tAction: [-21.42057228] \tReward: 1.0\n",
      "TD Error: -4.94547672272 \t( 0 s)\n",
      "====================================================================Episode: 856  started\n",
      "Step 15 @ Episode 856/1000 (15.0)\n",
      "Step: 15 \tState: [ 0.11881438  0.1720834  -0.20485607 -0.72218923] \tAction: [ 5.47834015] \tReward: 1.0\n",
      "TD Error: 0.980171585083 \t( 0 s)\n",
      "====================================================================Episode: 857  started\n",
      "Step 56 @ Episode 857/1000 (16.0)\n",
      "Step: 56 \tState: [-0.45882668 -1.55314042  0.17945998  1.60931597] \tAction: [-4.59111118] \tReward: 1.0\n",
      "TD Error: 1.27992839813 \t( 1 s)\n",
      "====================================================================Episode: 858  started\n",
      "Step 15 @ Episode 858/1000 (57.0)\n",
      "Step: 15 \tState: [ 0.10992951  0.57810862 -0.19568319 -1.17342402] \tAction: [-3.6604073] \tReward: 1.0\n",
      "TD Error: -5.07515258789 \t( 0 s)\n",
      "====================================================================Episode: 859  started\n",
      "Step 15 @ Episode 859/1000 (16.0)\n",
      "Step: 15 \tState: [ 0.12478795  0.94285218 -0.18468262 -1.61505642] \tAction: [-1.17616165] \tReward: 1.0\n",
      "TD Error: -5.05329837799 \t( 0 s)\n",
      "====================================================================Episode: 860  started\n",
      "Step 14 @ Episode 860/1000 (16.0)\n",
      "Step: 14 \tState: [-0.01712729 -0.3823367   0.18860326  1.05548369] \tAction: [-7.78692818] \tReward: 1.0\n",
      "TD Error: 3.02102279663 \t( 0 s)\n",
      "====================================================================Episode: 861  started\n",
      "Step 21 @ Episode 861/1000 (15.0)\n",
      "Step: 21 \tState: [-0.20742349 -1.00089979  0.20485936  1.43721549] \tAction: [-7.65432453] \tReward: 1.0\n",
      "TD Error: 4.94139919281 \t( 0 s)\n",
      "====================================================================Episode: 862  started\n",
      "Step 20 @ Episode 862/1000 (22.0)\n",
      "Step: 20 \tState: [ 0.21166026  1.20800095 -0.20200285 -1.93357095] \tAction: [-0.52749532] \tReward: 1.0\n",
      "TD Error: -2.65590629578 \t( 0 s)\n",
      "====================================================================Episode: 863  started\n",
      "Step 14 @ Episode 863/1000 (21.0)\n",
      "Step: 14 \tState: [-0.0444423  -0.00075873  0.20454825  0.5243812 ] \tAction: [ 14.47967911] \tReward: 1.0\n",
      "TD Error: 2.12296619415 \t( 0 s)\n",
      "====================================================================Episode: 864  started\n",
      "Step 7 @ Episode 864/1000 (15.0)\n",
      "Step: 7 \tState: [-0.12971254 -1.37472692  0.18123256  2.2241503 ] \tAction: [ 12.87226391] \tReward: 1.0\n",
      "TD Error: 0.290709400177 \t( 0 s)\n",
      "====================================================================Episode: 865  started\n",
      "Step 18 @ Episode 865/1000 (8.0)\n",
      "Step: 18 \tState: [ 0.09384001  0.41859972 -0.20070713 -0.99669239] \tAction: [ 2.24263072] \tReward: 1.0\n",
      "TD Error: 4.02242851257 \t( 0 s)\n",
      "====================================================================Episode: 866  started\n",
      "Step 16 @ Episode 866/1000 (19.0)\n",
      "Step: 16 \tState: [ 0.12647401  0.44590642 -0.20126575 -1.000242  ] \tAction: [ 4.56038666] \tReward: 1.0\n",
      "TD Error: 6.30485839844 \t( 0 s)\n",
      "====================================================================Episode: 867  started\n",
      "Step 17 @ Episode 867/1000 (17.0)\n",
      "Step: 17 \tState: [-0.1758561  -1.38232566  0.20830814  2.19201945] \tAction: [ 0.0215931] \tReward: 1.0\n",
      "TD Error: -2.60959444046 \t( 0 s)\n",
      "====================================================================Episode: 868  started\n",
      "Step 19 @ Episode 868/1000 (18.0)\n",
      "Step: 19 \tState: [ 0.1357375   0.9521076  -0.19577221 -1.56926697] \tAction: [-10.07873344] \tReward: 1.0\n",
      "TD Error: 5.97484741211 \t( 0 s)\n",
      "====================================================================Episode: 869  started\n",
      "Step 25 @ Episode 869/1000 (20.0)\n",
      "Step: 25 \tState: [-0.033182   -0.1839317   0.2030405   0.72200027] \tAction: [-1.73332679] \tReward: 1.0\n",
      "TD Error: -1.4817407608 \t( 0 s)\n",
      "====================================================================Episode: 870  started\n",
      "Step 24 @ Episode 870/1000 (26.0)\n",
      "Step: 24 \tState: [-0.0980689  -0.75795905  0.20910703  1.47584094] \tAction: [ 1.51160812] \tReward: 1.0\n",
      "TD Error: -2.40973386765 \t( 0 s)\n",
      "====================================================================Episode: 871  started\n",
      "Step 10 @ Episode 871/1000 (25.0)\n",
      "Step: 10 \tState: [ 0.13420851  0.4457545  -0.20432908 -0.90642849] \tAction: [-10.72430134] \tReward: 1.0\n",
      "TD Error: 5.16336174011 \t( 0 s)\n",
      "====================================================================Episode: 872  started\n",
      "Step 28 @ Episode 872/1000 (11.0)\n",
      "Step: 28 \tState: [-0.0924997  -0.46504023  0.20298125  1.22547619] \tAction: [-6.54425955] \tReward: 1.0\n",
      "TD Error: 0.729424667358 \t( 0 s)\n",
      "====================================================================Episode: 873  started\n",
      "Step 11 @ Episode 873/1000 (29.0)\n",
      "Step: 11 \tState: [ 0.15463981  0.64707485 -0.20464561 -1.17497987] \tAction: [ 1.02246928] \tReward: 1.0\n",
      "TD Error: 6.72043075562 \t( 0 s)\n",
      "====================================================================Episode: 874  started\n",
      "Step 14 @ Episode 874/1000 (12.0)\n",
      "Step: 14 \tState: [ 0.06214614  0.39683531 -0.1937472  -1.05863416] \tAction: [ 3.01803684] \tReward: 1.0\n",
      "TD Error: 4.59338340759 \t( 0 s)\n",
      "====================================================================Episode: 875  started\n",
      "Step 15 @ Episode 875/1000 (15.0)\n",
      "Step: 15 \tState: [ 0.14109137  1.34110815 -0.19955283 -2.26448159] \tAction: [ 1.09889436] \tReward: 1.0\n",
      "TD Error: -4.51605873108 \t( 0 s)\n",
      "====================================================================Episode: 876  started\n",
      "Step 25 @ Episode 876/1000 (16.0)\n",
      "Step: 25 \tState: [-0.14099352 -0.96256605  0.18804375  1.51758328] \tAction: [-17.2816143] \tReward: 1.0\n",
      "TD Error: 4.02307395935 \t( 0 s)\n",
      "====================================================================Episode: 877  started\n",
      "Step 21 @ Episode 877/1000 (26.0)\n",
      "Step: 21 \tState: [ 0.11559469  0.59444381 -0.20935616 -1.41772102] \tAction: [-4.18655252] \tReward: 1.0\n",
      "TD Error: -9.11245908737 \t( 0 s)\n",
      "====================================================================Episode: 878  started\n",
      "Step 91 @ Episode 878/1000 (22.0)\n",
      "Step: 91 \tState: [ 0.83415718  0.95248528 -0.20373617 -0.94284842] \tAction: [-15.50802994] \tReward: 1.0\n",
      "TD Error: -3.90337018967 \t( 1 s)\n",
      "====================================================================Episode: 879  started\n",
      "Step 10 @ Episode 879/1000 (92.0)\n",
      "Step: 10 \tState: [-0.10801497 -1.13179538  0.18988807  1.94169142] \tAction: [-3.3125658] \tReward: 1.0\n",
      "TD Error: -4.00780029297 \t( 0 s)\n",
      "====================================================================Episode: 880  started\n",
      "Step 8 @ Episode 880/1000 (11.0)\n",
      "Step: 8 \tState: [-0.13980599 -0.75651806  0.20024069  1.39208713] \tAction: [-3.81030989] \tReward: 1.0\n",
      "TD Error: -0.058595085144 \t( 0 s)\n",
      "====================================================================Episode: 881  started\n",
      "Step 21 @ Episode 881/1000 (9.0)\n",
      "Step: 21 \tState: [-0.05426543  0.16402153  0.20290655  0.4565721 ] \tAction: [ 13.13309669] \tReward: 1.0\n",
      "TD Error: 1.52989711761 \t( 0 s)\n",
      "====================================================================Episode: 882  started\n",
      "Step 29 @ Episode 882/1000 (22.0)\n",
      "Step: 29 \tState: [ 0.19226049  0.62592054 -0.20231877 -0.94775825] \tAction: [-13.24991608] \tReward: 1.0\n",
      "TD Error: -5.20922107697 \t( 0 s)\n",
      "====================================================================Episode: 883  started\n",
      "Step 28 @ Episode 883/1000 (30.0)\n",
      "Step: 28 \tState: [-0.04367422  0.79042086 -0.18281283 -1.78159682] \tAction: [-11.61852932] \tReward: 1.0\n",
      "TD Error: -8.89618625641 \t( 0 s)\n",
      "====================================================================Episode: 884  started\n",
      "Step 10 @ Episode 884/1000 (29.0)\n",
      "Step: 10 \tState: [ 0.0792916   0.83850953 -0.18427668 -1.37983595] \tAction: [-7.26486826] \tReward: 1.0\n",
      "TD Error: -7.26129894257 \t( 0 s)\n",
      "====================================================================Episode: 885  started\n",
      "Step 22 @ Episode 885/1000 (11.0)\n",
      "Step: 22 \tState: [ 0.1373921   1.20183747 -0.19513916 -1.82633738] \tAction: [ 7.21622992] \tReward: 1.0\n",
      "TD Error: -12.055735445 \t( 0 s)\n",
      "====================================================================Episode: 886  started\n",
      "Step 10 @ Episode 886/1000 (23.0)\n",
      "Step: 10 \tState: [-0.11683658 -0.78839766  0.19774073  1.48843536] \tAction: [-6.53886604] \tReward: 1.0\n",
      "TD Error: 0.208134555817 \t( 0 s)\n",
      "====================================================================Episode: 887  started\n",
      "Step 13 @ Episode 887/1000 (11.0)\n",
      "Step: 13 \tState: [ 0.0563831   1.00580999 -0.17552586 -1.71026914] \tAction: [ 3.94374609] \tReward: 1.0\n",
      "TD Error: -6.40805840492 \t( 0 s)\n",
      "====================================================================Episode: 888  started\n",
      "Step 15 @ Episode 888/1000 (14.0)\n",
      "Step: 15 \tState: [-0.10952073 -1.0059111   0.18111008  1.7294364 ] \tAction: [ 1.50391138] \tReward: 1.0\n",
      "TD Error: 2.0144797802 \t( 0 s)\n",
      "====================================================================Episode: 889  started\n",
      "Step 42 @ Episode 889/1000 (16.0)\n",
      "Step: 42 \tState: [ 0.12476577  0.46364279 -0.20737411 -1.15654417] \tAction: [-3.55862951] \tReward: 1.0\n",
      "TD Error: -6.93347258568 \t( 0 s)\n",
      "====================================================================Episode: 890  started\n",
      "Step 22 @ Episode 890/1000 (43.0)\n",
      "Step: 22 \tState: [ 0.13460093  0.4237069  -0.19993577 -0.91598342] \tAction: [ 2.5520432] \tReward: 1.0\n",
      "TD Error: -3.67607707977 \t( 0 s)\n",
      "====================================================================Episode: 891  started\n",
      "Step 14 @ Episode 891/1000 (23.0)\n",
      "Step: 14 \tState: [-0.06003245 -0.74543127  0.19227818  1.43653139] \tAction: [ 3.41041923] \tReward: 1.0\n",
      "TD Error: 1.42892110348 \t( 0 s)\n",
      "====================================================================Episode: 892  started\n",
      "Step 34 @ Episode 892/1000 (15.0)\n",
      "Step: 34 \tState: [-0.02792028 -0.4065734   0.19674493  1.14159727] \tAction: [-10.4369812] \tReward: 1.0\n",
      "TD Error: -0.911084270477 \t( 0 s)\n",
      "====================================================================Episode: 893  started\n",
      "Step 15 @ Episode 893/1000 (35.0)\n",
      "Step: 15 \tState: [ 0.18031778  0.93925017 -0.20868756 -1.64847508] \tAction: [ 3.82278919] \tReward: 1.0\n",
      "TD Error: -6.29127502441 \t( 0 s)\n",
      "====================================================================Episode: 894  started\n",
      "Step 10 @ Episode 894/1000 (16.0)\n",
      "Step: 10 \tState: [-0.14785714 -1.14529384  0.19906745  1.98938433] \tAction: [ 10.22520065] \tReward: 1.0\n",
      "TD Error: 0.47649936676 \t( 0 s)\n",
      "====================================================================Episode: 895  started\n",
      "Step 21 @ Episode 895/1000 (11.0)\n",
      "Step: 21 \tState: [-0.07329946 -0.58784793  0.19074391  1.50180956] \tAction: [ 1.79961681] \tReward: 1.0\n",
      "TD Error: -2.24266853333 \t( 0 s)\n",
      "====================================================================Episode: 896  started\n",
      "Step 17 @ Episode 896/1000 (22.0)\n",
      "Step: 17 \tState: [-0.10711908 -0.60866893  0.2090503   1.28826872] \tAction: [ 2.26080966] \tReward: 1.0\n",
      "TD Error: -3.03533115387 \t( 0 s)\n",
      "====================================================================Episode: 897  started\n",
      "Step 10 @ Episode 897/1000 (18.0)\n",
      "Step: 10 \tState: [-0.06134898 -1.17197369  0.18114281  1.99560866] \tAction: [-20.08017349] \tReward: 1.0\n",
      "TD Error: -3.29066367149 \t( 0 s)\n",
      "====================================================================Episode: 898  started\n",
      "Step 27 @ Episode 898/1000 (11.0)\n",
      "Step: 27 \tState: [ 0.14244231  0.21996929 -0.20657824 -0.85263285] \tAction: [ 6.47050762] \tReward: 1.0\n",
      "TD Error: -0.22205581665 \t( 0 s)\n",
      "====================================================================Episode: 899  started\n",
      "Step 22 @ Episode 899/1000 (28.0)\n",
      "Step: 22 \tState: [-0.11780163 -0.79288899  0.205218    1.36142933] \tAction: [ 11.10985374] \tReward: 1.0\n",
      "TD Error: -0.890159153938 \t( 0 s)\n",
      "====================================================================Episode: 900  started\n",
      "Step 21 @ Episode 900/1000 (23.0)\n",
      "Step: 21 \tState: [ 0.11428562  0.23908638 -0.19827551 -0.71261319] \tAction: [-2.52590823] \tReward: 1.0\n",
      "TD Error: -0.385841560364 \t( 0 s)\n",
      "====================================================================Episode: 901  started\n",
      "Step 23 @ Episode 901/1000 (22.0)\n",
      "Step: 23 \tState: [-0.12592764 -0.59059141  0.18637285  1.28855542] \tAction: [ 6.30949879] \tReward: 1.0\n",
      "TD Error: -0.251259613037 \t( 0 s)\n",
      "====================================================================Episode: 902  started\n",
      "Step 13 @ Episode 902/1000 (24.0)\n",
      "Step: 13 \tState: [-0.11780905 -1.38449814  0.1821242   2.06079998] \tAction: [ 1.76609468] \tReward: 1.0\n",
      "TD Error: -0.833615708351 \t( 0 s)\n",
      "====================================================================Episode: 903  started\n",
      "Step 17 @ Episode 903/1000 (14.0)\n",
      "Step: 17 \tState: [ 0.11623934  1.79903876 -0.15843779 -2.63757937] \tAction: [-2.76436329] \tReward: 1.0\n",
      "TD Error: -10.8314710617 \t( 0 s)\n",
      "====================================================================Episode: 904  started\n",
      "Step 12 @ Episode 904/1000 (18.0)\n",
      "Step: 12 \tState: [-0.11636421 -1.15085554  0.19019521  1.93777599] \tAction: [-8.46067047] \tReward: 1.0\n",
      "TD Error: 2.46403369904 \t( 0 s)\n",
      "====================================================================Episode: 905  started\n",
      "Step 13 @ Episode 905/1000 (13.0)\n",
      "Step: 13 \tState: [ 0.06124808  0.55654975 -0.19287228 -1.1708572 ] \tAction: [-6.75392199] \tReward: 1.0\n",
      "TD Error: -2.21512546539 \t( 0 s)\n",
      "====================================================================Episode: 906  started\n",
      "Step 14 @ Episode 906/1000 (14.0)\n",
      "Step: 14 \tState: [-0.1114119  -1.22624006  0.18454293  1.90675411] \tAction: [ 5.13546133] \tReward: 1.0\n",
      "TD Error: 2.87480883598 \t( 0 s)\n",
      "====================================================================Episode: 907  started\n",
      "Step 18 @ Episode 907/1000 (15.0)\n",
      "Step: 18 \tState: [-0.033995   -0.43445109  0.20534132  1.11827105] \tAction: [-15.84350395] \tReward: 1.0\n",
      "TD Error: 0.99317240715 \t( 0 s)\n",
      "====================================================================Episode: 908  started\n",
      "Step 11 @ Episode 908/1000 (19.0)\n",
      "Step: 11 \tState: [ 0.17528966  0.95966472 -0.19021586 -1.62186807] \tAction: [ 7.59197998] \tReward: 1.0\n",
      "TD Error: -2.273021698 \t( 0 s)\n",
      "====================================================================Episode: 909  started\n",
      "Step 16 @ Episode 909/1000 (12.0)\n",
      "Step: 16 \tState: [-0.13437435 -0.45708487  0.1934659   1.01308252] \tAction: [ 5.56668139] \tReward: 1.0\n",
      "TD Error: 0.423549032211 \t( 0 s)\n",
      "====================================================================Episode: 910  started\n",
      "Step 15 @ Episode 910/1000 (17.0)\n",
      "Step: 15 \tState: [-0.06466798 -0.59146517  0.20806484  1.22402345] \tAction: [-3.69356799] \tReward: 1.0\n",
      "TD Error: -2.78293361664 \t( 0 s)\n",
      "====================================================================Episode: 911  started\n",
      "Step 14 @ Episode 911/1000 (16.0)\n",
      "Step: 14 \tState: [-0.11214671 -0.36519499  0.19808108  0.82396042] \tAction: [-11.68179703] \tReward: 1.0\n",
      "TD Error: -2.29729642868 \t( 0 s)\n",
      "====================================================================Episode: 912  started\n",
      "Step 11 @ Episode 912/1000 (15.0)\n",
      "Step: 11 \tState: [ 0.1821044   1.0118016  -0.19476136 -1.63483266] \tAction: [ 2.75017214] \tReward: 1.0\n",
      "TD Error: -0.768406677246 \t( 0 s)\n",
      "====================================================================Episode: 913  started\n",
      "Step 21 @ Episode 913/1000 (12.0)\n",
      "Step: 21 \tState: [ 0.13489583  0.26166147 -0.20490723 -0.65648456] \tAction: [ 9.65937614] \tReward: 1.0\n",
      "TD Error: 3.60495376587 \t( 0 s)\n",
      "====================================================================Episode: 914  started\n",
      "Step 25 @ Episode 914/1000 (22.0)\n",
      "Step: 25 \tState: [ 0.08840566  0.17191147 -0.19615755 -0.75269232] \tAction: [ 12.67643166] \tReward: 1.0\n",
      "TD Error: -2.66509943008 \t( 0 s)\n",
      "====================================================================Episode: 915  started\n",
      "Step 16 @ Episode 915/1000 (26.0)\n",
      "Step: 16 \tState: [ 0.04652181  0.37281301 -0.19594741 -0.93669355] \tAction: [ 7.90595198] \tReward: 1.0\n",
      "TD Error: -4.64851446152 \t( 0 s)\n",
      "====================================================================Episode: 916  started\n",
      "Step 10 @ Episode 916/1000 (17.0)\n",
      "Step: 10 \tState: [-0.0614525  -0.79516423  0.19854141  1.44458701] \tAction: [ 1.29057789] \tReward: 1.0\n",
      "TD Error: 1.12030341625 \t( 0 s)\n",
      "====================================================================Episode: 917  started\n",
      "Step 10 @ Episode 917/1000 (11.0)\n",
      "Step: 10 \tState: [-0.15217421 -1.13860315  0.1745451   1.92467211] \tAction: [-1.52120781] \tReward: 1.0\n",
      "TD Error: 3.62592463493 \t( 0 s)\n",
      "====================================================================Episode: 918  started\n",
      "Step 30 @ Episode 918/1000 (11.0)\n",
      "Step: 30 \tState: [-0.17937497 -1.19992101  0.18688062  1.60169851] \tAction: [ 5.8030777] \tReward: 1.0\n",
      "TD Error: 2.16237313747 \t( 0 s)\n",
      "====================================================================Episode: 919  started\n",
      "Step 20 @ Episode 919/1000 (31.0)\n",
      "Step: 20 \tState: [-0.16469777 -1.58462544  0.18816434  2.3776084 ] \tAction: [-8.10763645] \tReward: 1.0\n",
      "TD Error: 1.46038930416 \t( 0 s)\n",
      "====================================================================Episode: 920  started\n",
      "Step 16 @ Episode 920/1000 (21.0)\n",
      "Step: 16 \tState: [ 0.08223147  0.06797559 -0.20605878 -0.50441357] \tAction: [-11.76296902] \tReward: 1.0\n",
      "TD Error: -1.75124816895 \t( 0 s)\n",
      "====================================================================Episode: 921  started\n",
      "Step 10 @ Episode 921/1000 (17.0)\n",
      "Step: 10 \tState: [ 0.14063965  0.78013438 -0.20862813 -1.37730331] \tAction: [ 1.62607598] \tReward: 1.0\n",
      "TD Error: -6.85936489105 \t( 0 s)\n",
      "====================================================================Episode: 922  started\n",
      "Step 15 @ Episode 922/1000 (11.0)\n",
      "Step: 15 \tState: [-0.1826778  -1.40493387  0.20473026  2.13668637] \tAction: [-4.98173094] \tReward: 1.0\n",
      "TD Error: -0.847334098816 \t( 0 s)\n",
      "====================================================================Episode: 923  started\n",
      "Step 9 @ Episode 923/1000 (16.0)\n",
      "Step: 9 \tState: [-0.10481166 -1.3834489   0.18460151  2.21414647] \tAction: [-9.11953926] \tReward: 1.0\n",
      "TD Error: -2.07186374664 \t( 0 s)\n",
      "====================================================================Episode: 924  started\n",
      "Step 10 @ Episode 924/1000 (10.0)\n",
      "Step: 10 \tState: [ 0.1001485   0.4354245  -0.20492577 -0.95324209] \tAction: [-8.98648548] \tReward: 1.0\n",
      "TD Error: -1.45986156464 \t( 0 s)\n",
      "====================================================================Episode: 925  started\n",
      "Step 42 @ Episode 925/1000 (11.0)\n",
      "Step: 42 \tState: [-0.20935146 -0.83623896  0.20371055  1.44504725] \tAction: [ 4.03154993] \tReward: 1.0\n",
      "TD Error: -5.9031457901 \t( 0 s)\n",
      "====================================================================Episode: 926  started\n",
      "Step 35 @ Episode 926/1000 (43.0)\n",
      "Step: 35 \tState: [ 0.15870901  1.40774999 -0.20261048 -2.13432137] \tAction: [ 7.48532009] \tReward: 1.0\n",
      "TD Error: -4.85770492554 \t( 0 s)\n",
      "====================================================================Episode: 927  started\n",
      "Step 14 @ Episode 927/1000 (36.0)\n",
      "Step: 14 \tState: [ 0.14243122  0.4549641  -0.20228664 -0.96278812] \tAction: [-7.02780819] \tReward: 1.0\n",
      "TD Error: 5.14081535339 \t( 0 s)\n",
      "====================================================================Episode: 928  started\n",
      "Step 31 @ Episode 928/1000 (15.0)\n",
      "Step: 31 \tState: [ 0.04353442  0.23807077 -0.20453111 -1.32200276] \tAction: [-7.34424925] \tReward: 1.0\n",
      "TD Error: -2.69809293747 \t( 0 s)\n",
      "====================================================================Episode: 929  started\n",
      "Step 23 @ Episode 929/1000 (32.0)\n",
      "Step: 23 \tState: [ 0.01271395  0.64632408 -0.18842823 -1.61054923] \tAction: [-20.81941986] \tReward: 1.0\n",
      "TD Error: -11.1463150024 \t( 0 s)\n",
      "====================================================================Episode: 930  started\n",
      "Step 27 @ Episode 930/1000 (24.0)\n",
      "Step: 27 \tState: [-0.08761012 -0.94538664  0.17865005  1.79368432] \tAction: [-0.14556478] \tReward: 1.0\n",
      "TD Error: -1.03918886185 \t( 0 s)\n",
      "====================================================================Episode: 931  started\n",
      "Step 11 @ Episode 931/1000 (28.0)\n",
      "Step: 11 \tState: [-0.14968269 -1.33518753  0.17992081  2.20276107] \tAction: [ 18.26731682] \tReward: 1.0\n",
      "TD Error: -1.57454242706 \t( 0 s)\n",
      "====================================================================Episode: 932  started\n",
      "Step 45 @ Episode 932/1000 (12.0)\n",
      "Step: 45 \tState: [-0.04094768 -0.65165882  0.20224701  1.48666146] \tAction: [-4.27525377] \tReward: 1.0\n",
      "TD Error: -3.3429664135 \t( 0 s)\n",
      "====================================================================Episode: 933  started\n",
      "Step 13 @ Episode 933/1000 (46.0)\n",
      "Step: 13 \tState: [ 0.18349417  1.00390412 -0.19939724 -1.67769857] \tAction: [-0.76398098] \tReward: 1.0\n",
      "TD Error: -15.5873608589 \t( 0 s)\n",
      "====================================================================Episode: 934  started\n",
      "Step 9 @ Episode 934/1000 (14.0)\n",
      "Step: 9 \tState: [-0.09967779 -0.54809301  0.20189011  1.20777684] \tAction: [ 13.71986389] \tReward: 1.0\n",
      "TD Error: -1.83245983124 \t( 0 s)\n",
      "====================================================================Episode: 935  started\n",
      "Step 21 @ Episode 935/1000 (10.0)\n",
      "Step: 21 \tState: [ 0.06275636  0.57502522 -0.20739935 -1.31659815] \tAction: [ 0.53848976] \tReward: 1.0\n",
      "TD Error: -12.4286711216 \t( 0 s)\n",
      "====================================================================Episode: 936  started\n",
      "Step 23 @ Episode 936/1000 (22.0)\n",
      "Step: 23 \tState: [-0.16123618 -0.2146865   0.20869261  0.63862569] \tAction: [ 18.19410515] \tReward: 1.0\n",
      "TD Error: -0.868176078796 \t( 0 s)\n",
      "====================================================================Episode: 937  started\n",
      "Step 14 @ Episode 937/1000 (24.0)\n",
      "Step: 14 \tState: [-0.13067117 -1.1964078   0.20703142  1.91319254] \tAction: [ 7.03933191] \tReward: 1.0\n",
      "TD Error: -4.5611623764 \t( 0 s)\n",
      "====================================================================Episode: 938  started\n",
      "Step 10 @ Episode 938/1000 (15.0)\n",
      "Step: 10 \tState: [ 0.08960641  1.14690637 -0.20758188 -1.94528679] \tAction: [ 0.665061] \tReward: 1.0\n",
      "TD Error: -14.6021572113 \t( 0 s)\n",
      "====================================================================Episode: 939  started\n",
      "Step 21 @ Episode 939/1000 (11.0)\n",
      "Step: 21 \tState: [-0.15852101 -0.61365295  0.19605118  1.14189986] \tAction: [-8.60418415] \tReward: 1.0\n",
      "TD Error: -2.38261070251 \t( 0 s)\n",
      "====================================================================Episode: 940  started\n",
      "Step 11 @ Episode 940/1000 (22.0)\n",
      "Step: 11 \tState: [-0.10305134 -0.63064591  0.20839591  1.0991219 ] \tAction: [ 4.69483757] \tReward: 1.0\n",
      "TD Error: -4.0225564003 \t( 0 s)\n",
      "====================================================================Episode: 941  started\n",
      "Step 78 @ Episode 941/1000 (12.0)\n",
      "Step: 78 \tState: [ 0.86283588  0.37549729 -0.20810964 -0.08206406] \tAction: [ 4.34043694] \tReward: 1.0\n",
      "TD Error: 2.52783203125 \t( 1 s)\n",
      "====================================================================Episode: 942  started\n",
      "Step 11 @ Episode 942/1000 (79.0)\n",
      "Step: 11 \tState: [ 0.08913009  0.60694302 -0.19060249 -1.17041806] \tAction: [ 5.23616838] \tReward: 1.0\n",
      "TD Error: -4.54857501984 \t( 0 s)\n",
      "====================================================================Episode: 943  started\n",
      "Step 22 @ Episode 943/1000 (12.0)\n",
      "Step: 22 \tState: [ 0.11989918  1.12888719 -0.1865066  -1.89527855] \tAction: [-5.57478857] \tReward: 1.0\n",
      "TD Error: -11.8074701786 \t( 0 s)\n",
      "====================================================================Episode: 944  started\n",
      "Step 34 @ Episode 944/1000 (23.0)\n",
      "Step: 34 \tState: [-0.03582846  0.80036012 -0.19164776 -1.89339161] \tAction: [ 9.62108898] \tReward: 1.0\n",
      "TD Error: -14.0594583511 \t( 0 s)\n",
      "====================================================================Episode: 945  started\n",
      "Step 23 @ Episode 945/1000 (35.0)\n",
      "Step: 23 \tState: [ 0.04129143  0.20247614 -0.20537106 -0.93035412] \tAction: [ 8.99499512] \tReward: 1.0\n",
      "TD Error: -4.01528778076 \t( 0 s)\n",
      "====================================================================Episode: 946  started\n",
      "Step 37 @ Episode 946/1000 (24.0)\n",
      "Step: 37 \tState: [-0.32276635 -1.36669586  0.20629489  1.56597391] \tAction: [ 3.89287829] \tReward: 1.0\n",
      "TD Error: -3.4059387207 \t( 0 s)\n",
      "====================================================================Episode: 947  started\n",
      "Step 27 @ Episode 947/1000 (38.0)\n",
      "Step: 27 \tState: [-0.08345186 -0.21663154  0.1945512   0.88900389] \tAction: [-26.04322243] \tReward: 1.0\n",
      "TD Error: -1.03238801956 \t( 0 s)\n",
      "====================================================================Episode: 948  started\n",
      "Step 29 @ Episode 948/1000 (28.0)\n",
      "Step: 29 \tState: [-0.06350771  0.26397916 -0.18913806 -1.5019984 ] \tAction: [-0.23633976] \tReward: 1.0\n",
      "TD Error: -12.1905060768 \t( 0 s)\n",
      "====================================================================Episode: 949  started\n",
      "Step 20 @ Episode 949/1000 (30.0)\n",
      "Step: 20 \tState: [ 0.12991801  0.83115052 -0.18144332 -1.41128258] \tAction: [-2.72599506] \tReward: 1.0\n",
      "TD Error: -8.66989498138 \t( 0 s)\n",
      "====================================================================Episode: 950  started\n",
      "Step 26 @ Episode 950/1000 (21.0)\n",
      "Step: 26 \tState: [-0.1891155  -1.18244123  0.18740587  1.78407186] \tAction: [ 4.10539484] \tReward: 1.0\n",
      "TD Error: -1.70142412186 \t( 0 s)\n",
      "====================================================================Episode: 951  started\n",
      "Step 20 @ Episode 951/1000 (27.0)\n",
      "Step: 20 \tState: [ 0.17258062  0.39050365 -0.20435943 -0.95384599] \tAction: [-10.21160412] \tReward: 1.0\n",
      "TD Error: -2.58177032471 \t( 0 s)\n",
      "====================================================================Episode: 952  started\n",
      "Step 21 @ Episode 952/1000 (21.0)\n",
      "Step: 21 \tState: [ 0.02503977 -0.19969487 -0.19961042 -0.49174227] \tAction: [-10.89724159] \tReward: 1.0\n",
      "TD Error: 2.25062789917 \t( 0 s)\n",
      "====================================================================Episode: 953  started\n",
      "Step 8 @ Episode 953/1000 (22.0)\n",
      "Step: 8 \tState: [-0.15233309 -1.17598995  0.20553732  1.90814819] \tAction: [ 4.13581133] \tReward: 1.0\n",
      "TD Error: -3.98277440071 \t( 0 s)\n",
      "====================================================================Episode: 954  started\n",
      "Step 18 @ Episode 954/1000 (9.0)\n",
      "Step: 18 \tState: [-0.08810953 -1.20234496  0.2049983   2.00085809] \tAction: [ 3.55458689] \tReward: 1.0\n",
      "TD Error: -8.53348283768 \t( 0 s)\n",
      "====================================================================Episode: 955  started\n",
      "Step 14 @ Episode 955/1000 (19.0)\n",
      "Step: 14 \tState: [ 0.06193689  1.14047204 -0.18635493 -1.9665211 ] \tAction: [-3.79834175] \tReward: 1.0\n",
      "TD Error: -10.0864675522 \t( 0 s)\n",
      "====================================================================Episode: 956  started\n",
      "Step 11 @ Episode 956/1000 (15.0)\n",
      "Step: 11 \tState: [ 0.07680541  0.93901809 -0.19534769 -1.70633029] \tAction: [ 9.64053345] \tReward: 1.0\n",
      "TD Error: -2.83287162781 \t( 0 s)\n",
      "====================================================================Episode: 957  started\n",
      "Step 12 @ Episode 957/1000 (12.0)\n",
      "Step: 12 \tState: [-0.09866162 -0.81773048  0.18626379  1.38004308] \tAction: [-9.55212402] \tReward: 1.0\n",
      "TD Error: -4.63025131226 \t( 0 s)\n",
      "====================================================================Episode: 958  started\n",
      "Step 15 @ Episode 958/1000 (13.0)\n",
      "Step: 15 \tState: [-0.11026065 -0.56288313  0.18965457  1.13855482] \tAction: [ 5.74299145] \tReward: 1.0\n",
      "TD Error: -5.67346687317 \t( 0 s)\n",
      "====================================================================Episode: 959  started\n",
      "Step 11 @ Episode 959/1000 (16.0)\n",
      "Step: 11 \tState: [-0.06671109 -1.03247883  0.1923189   1.70614118] \tAction: [ 5.38576603] \tReward: 1.0\n",
      "TD Error: -4.80294961929 \t( 0 s)\n",
      "====================================================================Episode: 960  started\n",
      "Step 86 @ Episode 960/1000 (12.0)\n",
      "Step: 86 \tState: [ 0.34817735 -0.00878958  0.20559117  1.19606235] \tAction: [-0.9750039] \tReward: 1.0\n",
      "TD Error: 3.06447525024 \t( 1 s)\n",
      "====================================================================Episode: 961  started\n",
      "Step 21 @ Episode 961/1000 (87.0)\n",
      "Step: 21 \tState: [ 0.11431061  0.64352281 -0.20323163 -1.37511539] \tAction: [ 3.43381882] \tReward: 1.0\n",
      "TD Error: -4.59392204285 \t( 0 s)\n",
      "====================================================================Episode: 962  started\n",
      "Step 8 @ Episode 962/1000 (22.0)\n",
      "Step: 8 \tState: [-0.10968478 -1.22360716  0.17747045  1.92588705] \tAction: [ 9.83135891] \tReward: 1.0\n",
      "TD Error: 5.1274766922 \t( 0 s)\n",
      "====================================================================Episode: 963  started\n",
      "Step 15 @ Episode 963/1000 (9.0)\n",
      "Step: 15 \tState: [ 0.00771462  0.95101332 -0.19372295 -1.92163202] \tAction: [ 11.66689014] \tReward: 1.0\n",
      "TD Error: -4.99285850525 \t( 0 s)\n",
      "====================================================================Episode: 964  started\n",
      "Step 13 @ Episode 964/1000 (16.0)\n",
      "Step: 13 \tState: [ 0.09344246  0.55378052 -0.20230333 -1.24597982] \tAction: [ 9.4695282] \tReward: 1.0\n",
      "TD Error: 0.628127670288 \t( 0 s)\n",
      "====================================================================Episode: 965  started\n",
      "Step 29 @ Episode 965/1000 (14.0)\n",
      "Step: 29 \tState: [-0.22496934 -1.31403026  0.1948896   1.99841813] \tAction: [-11.32820034] \tReward: 1.0\n",
      "TD Error: 8.43186683655 \t( 0 s)\n",
      "====================================================================Episode: 966  started\n",
      "Step 29 @ Episode 966/1000 (30.0)\n",
      "Step: 29 \tState: [-0.02457032 -0.10218452 -0.20823257 -0.75077312] \tAction: [-7.08309984] \tReward: 1.0\n",
      "TD Error: 0.782591629028 \t( 0 s)\n",
      "====================================================================Episode: 967  started\n",
      "Step 14 @ Episode 967/1000 (30.0)\n",
      "Step: 14 \tState: [ 0.14412914  0.82058856 -0.19810674 -1.36999094] \tAction: [-19.99436569] \tReward: 1.0\n",
      "TD Error: -3.37121620178 \t( 0 s)\n",
      "====================================================================Episode: 968  started\n",
      "Step 35 @ Episode 968/1000 (15.0)\n",
      "Step: 35 \tState: [ 0.00441061 -0.65939156  0.20016969  1.6309621 ] \tAction: [-5.50423956] \tReward: 1.0\n",
      "TD Error: 3.18721199036 \t( 0 s)\n",
      "====================================================================Episode: 969  started\n",
      "Step 13 @ Episode 969/1000 (36.0)\n",
      "Step: 13 \tState: [ 0.17220591  0.95891723 -0.20201606 -1.58472688] \tAction: [-4.14400768] \tReward: 1.0\n",
      "TD Error: 1.22715988159 \t( 0 s)\n",
      "====================================================================Episode: 970  started\n",
      "Step 17 @ Episode 970/1000 (14.0)\n",
      "Step: 17 \tState: [-0.13255671 -0.94564877  0.20660586  1.80468544] \tAction: [-0.78277141] \tReward: 1.0\n",
      "TD Error: 4.50797157288 \t( 0 s)\n",
      "====================================================================Episode: 971  started\n",
      "Step 17 @ Episode 971/1000 (18.0)\n",
      "Step: 17 \tState: [-0.16629799 -1.01492409  0.20468381  1.68370294] \tAction: [-0.94535387] \tReward: 1.0\n",
      "TD Error: 0.780496931076 \t( 0 s)\n",
      "====================================================================Episode: 972  started\n",
      "Step 28 @ Episode 972/1000 (18.0)\n",
      "Step: 28 \tState: [-0.15454141 -1.20116047  0.20836657  2.07755199] \tAction: [ 7.25351238] \tReward: 1.0\n",
      "TD Error: 0.0611115455627 \t( 0 s)\n",
      "====================================================================Episode: 973  started\n",
      "Step 11 @ Episode 973/1000 (29.0)\n",
      "Step: 11 \tState: [-0.1049781  -0.95753923  0.18871213  1.71132987] \tAction: [-10.71391487] \tReward: 1.0\n",
      "TD Error: 2.50110912323 \t( 0 s)\n",
      "====================================================================Episode: 974  started\n",
      "Step 8 @ Episode 974/1000 (12.0)\n",
      "Step: 8 \tState: [ 0.0687413   1.18476813 -0.17342628 -1.87354535] \tAction: [-1.9884789] \tReward: 1.0\n",
      "TD Error: 1.95330886841 \t( 0 s)\n",
      "====================================================================Episode: 975  started\n",
      "Step 10 @ Episode 975/1000 (9.0)\n",
      "Step: 10 \tState: [-0.10644874 -0.83715878  0.18792866  1.38843893] \tAction: [ 5.62921095] \tReward: 1.0\n",
      "TD Error: 4.93510227203 \t( 0 s)\n",
      "====================================================================Episode: 976  started\n",
      "Step 17 @ Episode 976/1000 (11.0)\n",
      "Step: 17 \tState: [ 0.04883215  0.62624517 -0.20523495 -1.36637663] \tAction: [ 21.67224503] \tReward: 1.0\n",
      "TD Error: 9.04647064209 \t( 0 s)\n",
      "====================================================================Episode: 977  started\n",
      "Step 17 @ Episode 977/1000 (18.0)\n",
      "Step: 17 \tState: [ 0.21168661  1.02921881 -0.2077702  -1.62398479] \tAction: [ 0.42898479] \tReward: 1.0\n",
      "TD Error: 9.51287155151 \t( 0 s)\n",
      "====================================================================Episode: 978  started\n",
      "Step 16 @ Episode 978/1000 (18.0)\n",
      "Step: 16 \tState: [-0.05295702 -0.01564027  0.20198178  0.48253604] \tAction: [-13.88304329] \tReward: 1.0\n",
      "TD Error: 0.910014224052 \t( 0 s)\n",
      "====================================================================Episode: 979  started\n",
      "Step 37 @ Episode 979/1000 (17.0)\n",
      "Step: 37 \tState: [ 0.2450708   1.70231486 -0.17684147 -2.14201759] \tAction: [-10.03508854] \tReward: 1.0\n",
      "TD Error: 10.0370716095 \t( 0 s)\n",
      "====================================================================Episode: 980  started\n",
      "Step 16 @ Episode 980/1000 (38.0)\n",
      "Step: 16 \tState: [-0.10197966 -1.19169477  0.19529148  1.95986456] \tAction: [-12.62324429] \tReward: 1.0\n",
      "TD Error: -3.98664236069 \t( 0 s)\n",
      "====================================================================Episode: 981  started\n",
      "Step 15 @ Episode 981/1000 (17.0)\n",
      "Step: 15 \tState: [ 0.13229006  0.6031009  -0.20313929 -1.25488955] \tAction: [ 17.96844292] \tReward: 1.0\n",
      "TD Error: 4.92549781799 \t( 0 s)\n",
      "====================================================================Episode: 982  started\n",
      "Step 11 @ Episode 982/1000 (16.0)\n",
      "Step: 11 \tState: [-0.15075898 -0.9960046   0.17820348  1.57235538] \tAction: [ 8.23153973] \tReward: 1.0\n",
      "TD Error: -6.06171798706 \t( 0 s)\n",
      "====================================================================Episode: 983  started\n",
      "Step 20 @ Episode 983/1000 (12.0)\n",
      "Step: 20 \tState: [ 0.0180884   0.75420266 -0.18467197 -1.50977375] \tAction: [ 4.99679375] \tReward: 1.0\n",
      "TD Error: -0.73116569519 \t( 0 s)\n",
      "====================================================================Episode: 984  started\n",
      "Step 15 @ Episode 984/1000 (21.0)\n",
      "Step: 15 \tState: [ 0.10848165  1.00127112 -0.20101372 -1.79484542] \tAction: [ 7.26184416] \tReward: 1.0\n",
      "TD Error: 0.746464538574 \t( 0 s)\n",
      "====================================================================Episode: 985  started\n",
      "Step 31 @ Episode 985/1000 (16.0)\n",
      "Step: 31 \tState: [ 0.11679071  0.19838952 -0.19851358 -0.78790722] \tAction: [ 5.24848366] \tReward: 1.0\n",
      "TD Error: 0.759130477905 \t( 0 s)\n",
      "====================================================================Episode: 986  started\n",
      "Step 16 @ Episode 986/1000 (32.0)\n",
      "Step: 16 \tState: [ 0.11836008  0.77382965 -0.19112483 -1.4979277 ] \tAction: [-4.63670063] \tReward: 1.0\n",
      "TD Error: -5.53551921844 \t( 0 s)\n",
      "====================================================================Episode: 987  started\n",
      "Step 18 @ Episode 987/1000 (17.0)\n",
      "Step: 18 \tState: [-0.1640602  -0.76547462  0.19668911  1.31569895] \tAction: [ 18.20176125] \tReward: 1.0\n",
      "TD Error: -0.907730746269 \t( 0 s)\n",
      "====================================================================Episode: 988  started\n",
      "Step 12 @ Episode 988/1000 (19.0)\n",
      "Step: 12 \tState: [-0.05757536 -1.15734916  0.18811079  1.95296462] \tAction: [ 1.43298316] \tReward: 1.0\n",
      "TD Error: 4.51104269028 \t( 0 s)\n",
      "====================================================================Episode: 989  started\n",
      "Step 41 @ Episode 989/1000 (13.0)\n",
      "Step: 41 \tState: [ 0.05262416  0.14276973  0.19799464  0.8871327 ] \tAction: [-3.29340649] \tReward: 1.0\n",
      "TD Error: 4.15868015289 \t( 0 s)\n",
      "====================================================================Episode: 990  started\n",
      "Step 10 @ Episode 990/1000 (42.0)\n",
      "Step: 10 \tState: [ 0.11006003  1.21841293 -0.19508501 -1.96094644] \tAction: [ 6.38526869] \tReward: 1.0\n",
      "TD Error: -13.0141066551 \t( 0 s)\n",
      "====================================================================Episode: 991  started\n",
      "Step 9 @ Episode 991/1000 (11.0)\n",
      "Step: 9 \tState: [ 0.18479966  1.35266808 -0.17073104 -2.07889879] \tAction: [ 1.44087231] \tReward: 1.0\n",
      "TD Error: -7.11245508194 \t( 0 s)\n",
      "====================================================================Episode: 992  started\n",
      "Step 14 @ Episode 992/1000 (10.0)\n",
      "Step: 14 \tState: [-0.13458268 -1.15963097  0.1880339   1.87646343] \tAction: [-7.80911303] \tReward: 1.0\n",
      "TD Error: 3.4867824018 \t( 0 s)\n",
      "====================================================================Episode: 993  started\n",
      "Step 39 @ Episode 993/1000 (15.0)\n",
      "Step: 39 \tState: [-0.19369201 -0.14955273 -0.18933154 -1.15627276] \tAction: [-3.46973157] \tReward: 1.0\n",
      "TD Error: -10.5216736794 \t( 0 s)\n",
      "====================================================================Episode: 994  started\n",
      "Step 42 @ Episode 994/1000 (40.0)\n",
      "Step: 42 \tState: [-0.17731898 -0.42815431  0.20656372  1.24576312] \tAction: [ 7.13483477] \tReward: 1.0\n",
      "TD Error: 0.621926736832 \t( 0 s)\n",
      "====================================================================Episode: 995  started\n",
      "Step 16 @ Episode 995/1000 (43.0)\n",
      "Step: 16 \tState: [ 0.11703394  0.41213289 -0.2083427  -0.99113788] \tAction: [ 0.86593449] \tReward: 1.0\n",
      "TD Error: -7.49146623611 \t( 0 s)\n",
      "====================================================================Episode: 996  started\n",
      "Step 18 @ Episode 996/1000 (17.0)\n",
      "Step: 18 \tState: [ 0.13331158  1.53369372 -0.18663601 -2.21644234] \tAction: [ 3.12335491] \tReward: 1.0\n",
      "TD Error: -15.0529973984 \t( 0 s)\n",
      "====================================================================Episode: 997  started\n",
      "Step 26 @ Episode 997/1000 (19.0)\n",
      "Step: 26 \tState: [-0.17101255 -1.53697034  0.16761388  2.17162159] \tAction: [-3.61395955] \tReward: 1.0\n",
      "TD Error: 6.48918571472 \t( 0 s)\n",
      "====================================================================Episode: 998  started\n",
      "Step 12 @ Episode 998/1000 (27.0)\n",
      "Step: 12 \tState: [-0.0454107  -1.20990359  0.17189719  2.00387998] \tAction: [-1.02435601] \tReward: 1.0\n",
      "TD Error: 5.30260047913 \t( 0 s)\n",
      "====================================================================Episode: 999  started\n",
      "Step 13 @ Episode 999/1000 (13.0)\n",
      "Step: 13 \tState: [-0.08191217 -1.3843649   0.17858922  2.17965551] \tAction: [-2.15506577] \tReward: 1.0\n",
      "TD Error: 3.37046203613 \t( 0 s)\n",
      "====================================================================Episode: 1000  started\n",
      "Step 17 @ Episode 1000/1000 (14.0)\n",
      "Step: 17 \tState: [-0.15082172 -0.95135196  0.19446719  1.59685033] \tAction: [-6.73316097] \tReward: 1.0\n",
      "TD Error: -1.93453769684 \t( 0 s)\n",
      "-------------------------------------------------------------------------->DONE!\n",
      "i: 0 \tReward: 16.0 \tLength: 15.0\n",
      "i: 1 \tReward: 22.0 \tLength: 21.0\n",
      "i: 2 \tReward: 34.0 \tLength: 33.0\n",
      "i: 3 \tReward: 17.0 \tLength: 16.0\n",
      "i: 4 \tReward: 18.0 \tLength: 17.0\n",
      "i: 5 \tReward: 24.0 \tLength: 23.0\n",
      "i: 6 \tReward: 16.0 \tLength: 15.0\n",
      "i: 7 \tReward: 12.0 \tLength: 11.0\n",
      "i: 8 \tReward: 13.0 \tLength: 12.0\n",
      "i: 9 \tReward: 15.0 \tLength: 14.0\n",
      "i: 10 \tReward: 26.0 \tLength: 25.0\n",
      "i: 11 \tReward: 16.0 \tLength: 15.0\n",
      "i: 12 \tReward: 11.0 \tLength: 10.0\n",
      "i: 13 \tReward: 13.0 \tLength: 12.0\n",
      "i: 14 \tReward: 16.0 \tLength: 15.0\n",
      "i: 15 \tReward: 11.0 \tLength: 10.0\n",
      "i: 16 \tReward: 11.0 \tLength: 10.0\n",
      "i: 17 \tReward: 18.0 \tLength: 17.0\n",
      "i: 18 \tReward: 17.0 \tLength: 16.0\n",
      "i: 19 \tReward: 11.0 \tLength: 10.0\n",
      "i: 20 \tReward: 20.0 \tLength: 19.0\n",
      "i: 21 \tReward: 15.0 \tLength: 14.0\n",
      "i: 22 \tReward: 12.0 \tLength: 11.0\n",
      "i: 23 \tReward: 20.0 \tLength: 19.0\n",
      "i: 24 \tReward: 12.0 \tLength: 11.0\n",
      "i: 25 \tReward: 22.0 \tLength: 21.0\n",
      "i: 26 \tReward: 16.0 \tLength: 15.0\n",
      "i: 27 \tReward: 12.0 \tLength: 11.0\n",
      "i: 28 \tReward: 15.0 \tLength: 14.0\n",
      "i: 29 \tReward: 10.0 \tLength: 9.0\n",
      "i: 30 \tReward: 17.0 \tLength: 16.0\n",
      "i: 31 \tReward: 11.0 \tLength: 10.0\n",
      "i: 32 \tReward: 11.0 \tLength: 10.0\n",
      "i: 33 \tReward: 13.0 \tLength: 12.0\n",
      "i: 34 \tReward: 18.0 \tLength: 17.0\n",
      "i: 35 \tReward: 14.0 \tLength: 13.0\n",
      "i: 36 \tReward: 11.0 \tLength: 10.0\n",
      "i: 37 \tReward: 15.0 \tLength: 14.0\n",
      "i: 38 \tReward: 11.0 \tLength: 10.0\n",
      "i: 39 \tReward: 12.0 \tLength: 11.0\n",
      "i: 40 \tReward: 12.0 \tLength: 11.0\n",
      "i: 41 \tReward: 10.0 \tLength: 9.0\n",
      "i: 42 \tReward: 17.0 \tLength: 16.0\n",
      "i: 43 \tReward: 10.0 \tLength: 9.0\n",
      "i: 44 \tReward: 11.0 \tLength: 10.0\n",
      "i: 45 \tReward: 16.0 \tLength: 15.0\n",
      "i: 46 \tReward: 21.0 \tLength: 20.0\n",
      "i: 47 \tReward: 16.0 \tLength: 15.0\n",
      "i: 48 \tReward: 15.0 \tLength: 14.0\n",
      "i: 49 \tReward: 15.0 \tLength: 14.0\n",
      "i: 50 \tReward: 13.0 \tLength: 12.0\n",
      "i: 51 \tReward: 14.0 \tLength: 13.0\n",
      "i: 52 \tReward: 10.0 \tLength: 9.0\n",
      "i: 53 \tReward: 9.0 \tLength: 8.0\n",
      "i: 54 \tReward: 18.0 \tLength: 17.0\n",
      "i: 55 \tReward: 15.0 \tLength: 14.0\n",
      "i: 56 \tReward: 25.0 \tLength: 24.0\n",
      "i: 57 \tReward: 19.0 \tLength: 18.0\n",
      "i: 58 \tReward: 10.0 \tLength: 9.0\n",
      "i: 59 \tReward: 10.0 \tLength: 9.0\n",
      "i: 60 \tReward: 11.0 \tLength: 10.0\n",
      "i: 61 \tReward: 15.0 \tLength: 14.0\n",
      "i: 62 \tReward: 15.0 \tLength: 14.0\n",
      "i: 63 \tReward: 11.0 \tLength: 10.0\n",
      "i: 64 \tReward: 12.0 \tLength: 11.0\n",
      "i: 65 \tReward: 14.0 \tLength: 13.0\n",
      "i: 66 \tReward: 10.0 \tLength: 9.0\n",
      "i: 67 \tReward: 21.0 \tLength: 20.0\n",
      "i: 68 \tReward: 17.0 \tLength: 16.0\n",
      "i: 69 \tReward: 10.0 \tLength: 9.0\n",
      "i: 70 \tReward: 23.0 \tLength: 22.0\n",
      "i: 71 \tReward: 12.0 \tLength: 11.0\n",
      "i: 72 \tReward: 11.0 \tLength: 10.0\n",
      "i: 73 \tReward: 23.0 \tLength: 22.0\n",
      "i: 74 \tReward: 19.0 \tLength: 18.0\n",
      "i: 75 \tReward: 13.0 \tLength: 12.0\n",
      "i: 76 \tReward: 18.0 \tLength: 17.0\n",
      "i: 77 \tReward: 15.0 \tLength: 14.0\n",
      "i: 78 \tReward: 13.0 \tLength: 12.0\n",
      "i: 79 \tReward: 17.0 \tLength: 16.0\n",
      "i: 80 \tReward: 12.0 \tLength: 11.0\n",
      "i: 81 \tReward: 33.0 \tLength: 32.0\n",
      "i: 82 \tReward: 15.0 \tLength: 14.0\n",
      "i: 83 \tReward: 17.0 \tLength: 16.0\n",
      "i: 84 \tReward: 21.0 \tLength: 20.0\n",
      "i: 85 \tReward: 19.0 \tLength: 18.0\n",
      "i: 86 \tReward: 34.0 \tLength: 33.0\n",
      "i: 87 \tReward: 15.0 \tLength: 14.0\n",
      "i: 88 \tReward: 24.0 \tLength: 23.0\n",
      "i: 89 \tReward: 16.0 \tLength: 15.0\n",
      "i: 90 \tReward: 22.0 \tLength: 21.0\n",
      "i: 91 \tReward: 26.0 \tLength: 25.0\n",
      "i: 92 \tReward: 22.0 \tLength: 21.0\n",
      "i: 93 \tReward: 16.0 \tLength: 15.0\n",
      "i: 94 \tReward: 22.0 \tLength: 21.0\n",
      "i: 95 \tReward: 22.0 \tLength: 21.0\n",
      "i: 96 \tReward: 18.0 \tLength: 17.0\n",
      "i: 97 \tReward: 12.0 \tLength: 11.0\n",
      "i: 98 \tReward: 20.0 \tLength: 19.0\n",
      "i: 99 \tReward: 10.0 \tLength: 9.0\n",
      "i: 100 \tReward: 28.0 \tLength: 27.0\n",
      "i: 101 \tReward: 12.0 \tLength: 11.0\n",
      "i: 102 \tReward: 45.0 \tLength: 44.0\n",
      "i: 103 \tReward: 18.0 \tLength: 17.0\n",
      "i: 104 \tReward: 12.0 \tLength: 11.0\n",
      "i: 105 \tReward: 15.0 \tLength: 14.0\n",
      "i: 106 \tReward: 20.0 \tLength: 19.0\n",
      "i: 107 \tReward: 12.0 \tLength: 11.0\n",
      "i: 108 \tReward: 37.0 \tLength: 36.0\n",
      "i: 109 \tReward: 19.0 \tLength: 18.0\n",
      "i: 110 \tReward: 17.0 \tLength: 16.0\n",
      "i: 111 \tReward: 26.0 \tLength: 25.0\n",
      "i: 112 \tReward: 16.0 \tLength: 15.0\n",
      "i: 113 \tReward: 18.0 \tLength: 17.0\n",
      "i: 114 \tReward: 16.0 \tLength: 15.0\n",
      "i: 115 \tReward: 51.0 \tLength: 50.0\n",
      "i: 116 \tReward: 24.0 \tLength: 23.0\n",
      "i: 117 \tReward: 11.0 \tLength: 10.0\n",
      "i: 118 \tReward: 24.0 \tLength: 23.0\n",
      "i: 119 \tReward: 21.0 \tLength: 20.0\n",
      "i: 120 \tReward: 11.0 \tLength: 10.0\n",
      "i: 121 \tReward: 19.0 \tLength: 18.0\n",
      "i: 122 \tReward: 10.0 \tLength: 9.0\n",
      "i: 123 \tReward: 14.0 \tLength: 13.0\n",
      "i: 124 \tReward: 15.0 \tLength: 14.0\n",
      "i: 125 \tReward: 22.0 \tLength: 21.0\n",
      "i: 126 \tReward: 26.0 \tLength: 25.0\n",
      "i: 127 \tReward: 11.0 \tLength: 10.0\n",
      "i: 128 \tReward: 16.0 \tLength: 15.0\n",
      "i: 129 \tReward: 27.0 \tLength: 26.0\n",
      "i: 130 \tReward: 16.0 \tLength: 15.0\n",
      "i: 131 \tReward: 10.0 \tLength: 9.0\n",
      "i: 132 \tReward: 14.0 \tLength: 13.0\n",
      "i: 133 \tReward: 11.0 \tLength: 10.0\n",
      "i: 134 \tReward: 13.0 \tLength: 12.0\n",
      "i: 135 \tReward: 21.0 \tLength: 20.0\n",
      "i: 136 \tReward: 13.0 \tLength: 12.0\n",
      "i: 137 \tReward: 17.0 \tLength: 16.0\n",
      "i: 138 \tReward: 19.0 \tLength: 18.0\n",
      "i: 139 \tReward: 10.0 \tLength: 9.0\n",
      "i: 140 \tReward: 36.0 \tLength: 35.0\n",
      "i: 141 \tReward: 18.0 \tLength: 17.0\n",
      "i: 142 \tReward: 9.0 \tLength: 8.0\n",
      "i: 143 \tReward: 13.0 \tLength: 12.0\n",
      "i: 144 \tReward: 17.0 \tLength: 16.0\n",
      "i: 145 \tReward: 17.0 \tLength: 16.0\n",
      "i: 146 \tReward: 13.0 \tLength: 12.0\n",
      "i: 147 \tReward: 21.0 \tLength: 20.0\n",
      "i: 148 \tReward: 21.0 \tLength: 20.0\n",
      "i: 149 \tReward: 13.0 \tLength: 12.0\n",
      "i: 150 \tReward: 20.0 \tLength: 19.0\n",
      "i: 151 \tReward: 12.0 \tLength: 11.0\n",
      "i: 152 \tReward: 39.0 \tLength: 38.0\n",
      "i: 153 \tReward: 12.0 \tLength: 11.0\n",
      "i: 154 \tReward: 13.0 \tLength: 12.0\n",
      "i: 155 \tReward: 18.0 \tLength: 17.0\n",
      "i: 156 \tReward: 9.0 \tLength: 8.0\n",
      "i: 157 \tReward: 21.0 \tLength: 20.0\n",
      "i: 158 \tReward: 15.0 \tLength: 14.0\n",
      "i: 159 \tReward: 25.0 \tLength: 24.0\n",
      "i: 160 \tReward: 16.0 \tLength: 15.0\n",
      "i: 161 \tReward: 12.0 \tLength: 11.0\n",
      "i: 162 \tReward: 20.0 \tLength: 19.0\n",
      "i: 163 \tReward: 13.0 \tLength: 12.0\n",
      "i: 164 \tReward: 11.0 \tLength: 10.0\n",
      "i: 165 \tReward: 10.0 \tLength: 9.0\n",
      "i: 166 \tReward: 12.0 \tLength: 11.0\n",
      "i: 167 \tReward: 12.0 \tLength: 11.0\n",
      "i: 168 \tReward: 10.0 \tLength: 9.0\n",
      "i: 169 \tReward: 13.0 \tLength: 12.0\n",
      "i: 170 \tReward: 13.0 \tLength: 12.0\n",
      "i: 171 \tReward: 14.0 \tLength: 13.0\n",
      "i: 172 \tReward: 20.0 \tLength: 19.0\n",
      "i: 173 \tReward: 13.0 \tLength: 12.0\n",
      "i: 174 \tReward: 16.0 \tLength: 15.0\n",
      "i: 175 \tReward: 45.0 \tLength: 44.0\n",
      "i: 176 \tReward: 32.0 \tLength: 31.0\n",
      "i: 177 \tReward: 13.0 \tLength: 12.0\n",
      "i: 178 \tReward: 16.0 \tLength: 15.0\n",
      "i: 179 \tReward: 17.0 \tLength: 16.0\n",
      "i: 180 \tReward: 14.0 \tLength: 13.0\n",
      "i: 181 \tReward: 12.0 \tLength: 11.0\n",
      "i: 182 \tReward: 14.0 \tLength: 13.0\n",
      "i: 183 \tReward: 15.0 \tLength: 14.0\n",
      "i: 184 \tReward: 16.0 \tLength: 15.0\n",
      "i: 185 \tReward: 19.0 \tLength: 18.0\n",
      "i: 186 \tReward: 12.0 \tLength: 11.0\n",
      "i: 187 \tReward: 12.0 \tLength: 11.0\n",
      "i: 188 \tReward: 55.0 \tLength: 54.0\n",
      "i: 189 \tReward: 27.0 \tLength: 26.0\n",
      "i: 190 \tReward: 15.0 \tLength: 14.0\n",
      "i: 191 \tReward: 19.0 \tLength: 18.0\n",
      "i: 192 \tReward: 31.0 \tLength: 30.0\n",
      "i: 193 \tReward: 12.0 \tLength: 11.0\n",
      "i: 194 \tReward: 9.0 \tLength: 8.0\n",
      "i: 195 \tReward: 11.0 \tLength: 10.0\n",
      "i: 196 \tReward: 14.0 \tLength: 13.0\n",
      "i: 197 \tReward: 40.0 \tLength: 39.0\n",
      "i: 198 \tReward: 37.0 \tLength: 36.0\n",
      "i: 199 \tReward: 31.0 \tLength: 30.0\n",
      "i: 200 \tReward: 11.0 \tLength: 10.0\n",
      "i: 201 \tReward: 15.0 \tLength: 14.0\n",
      "i: 202 \tReward: 17.0 \tLength: 16.0\n",
      "i: 203 \tReward: 10.0 \tLength: 9.0\n",
      "i: 204 \tReward: 13.0 \tLength: 12.0\n",
      "i: 205 \tReward: 27.0 \tLength: 26.0\n",
      "i: 206 \tReward: 14.0 \tLength: 13.0\n",
      "i: 207 \tReward: 43.0 \tLength: 42.0\n",
      "i: 208 \tReward: 10.0 \tLength: 9.0\n",
      "i: 209 \tReward: 19.0 \tLength: 18.0\n",
      "i: 210 \tReward: 13.0 \tLength: 12.0\n",
      "i: 211 \tReward: 12.0 \tLength: 11.0\n",
      "i: 212 \tReward: 9.0 \tLength: 8.0\n",
      "i: 213 \tReward: 15.0 \tLength: 14.0\n",
      "i: 214 \tReward: 16.0 \tLength: 15.0\n",
      "i: 215 \tReward: 10.0 \tLength: 9.0\n",
      "i: 216 \tReward: 13.0 \tLength: 12.0\n",
      "i: 217 \tReward: 20.0 \tLength: 19.0\n",
      "i: 218 \tReward: 26.0 \tLength: 25.0\n",
      "i: 219 \tReward: 19.0 \tLength: 18.0\n",
      "i: 220 \tReward: 43.0 \tLength: 42.0\n",
      "i: 221 \tReward: 17.0 \tLength: 16.0\n",
      "i: 222 \tReward: 14.0 \tLength: 13.0\n",
      "i: 223 \tReward: 10.0 \tLength: 9.0\n",
      "i: 224 \tReward: 31.0 \tLength: 30.0\n",
      "i: 225 \tReward: 18.0 \tLength: 17.0\n",
      "i: 226 \tReward: 29.0 \tLength: 28.0\n",
      "i: 227 \tReward: 25.0 \tLength: 24.0\n",
      "i: 228 \tReward: 22.0 \tLength: 21.0\n",
      "i: 229 \tReward: 24.0 \tLength: 23.0\n",
      "i: 230 \tReward: 15.0 \tLength: 14.0\n",
      "i: 231 \tReward: 17.0 \tLength: 16.0\n",
      "i: 232 \tReward: 21.0 \tLength: 20.0\n",
      "i: 233 \tReward: 21.0 \tLength: 20.0\n",
      "i: 234 \tReward: 40.0 \tLength: 39.0\n",
      "i: 235 \tReward: 21.0 \tLength: 20.0\n",
      "i: 236 \tReward: 20.0 \tLength: 19.0\n",
      "i: 237 \tReward: 13.0 \tLength: 12.0\n",
      "i: 238 \tReward: 11.0 \tLength: 10.0\n",
      "i: 239 \tReward: 14.0 \tLength: 13.0\n",
      "i: 240 \tReward: 46.0 \tLength: 45.0\n",
      "i: 241 \tReward: 12.0 \tLength: 11.0\n",
      "i: 242 \tReward: 29.0 \tLength: 28.0\n",
      "i: 243 \tReward: 24.0 \tLength: 23.0\n",
      "i: 244 \tReward: 25.0 \tLength: 24.0\n",
      "i: 245 \tReward: 33.0 \tLength: 32.0\n",
      "i: 246 \tReward: 22.0 \tLength: 21.0\n",
      "i: 247 \tReward: 26.0 \tLength: 25.0\n",
      "i: 248 \tReward: 12.0 \tLength: 11.0\n",
      "i: 249 \tReward: 20.0 \tLength: 19.0\n",
      "i: 250 \tReward: 18.0 \tLength: 17.0\n",
      "i: 251 \tReward: 16.0 \tLength: 15.0\n",
      "i: 252 \tReward: 13.0 \tLength: 12.0\n",
      "i: 253 \tReward: 11.0 \tLength: 10.0\n",
      "i: 254 \tReward: 26.0 \tLength: 25.0\n",
      "i: 255 \tReward: 14.0 \tLength: 13.0\n",
      "i: 256 \tReward: 61.0 \tLength: 60.0\n",
      "i: 257 \tReward: 26.0 \tLength: 25.0\n",
      "i: 258 \tReward: 18.0 \tLength: 17.0\n",
      "i: 259 \tReward: 10.0 \tLength: 9.0\n",
      "i: 260 \tReward: 41.0 \tLength: 40.0\n",
      "i: 261 \tReward: 21.0 \tLength: 20.0\n",
      "i: 262 \tReward: 27.0 \tLength: 26.0\n",
      "i: 263 \tReward: 12.0 \tLength: 11.0\n",
      "i: 264 \tReward: 38.0 \tLength: 37.0\n",
      "i: 265 \tReward: 33.0 \tLength: 32.0\n",
      "i: 266 \tReward: 21.0 \tLength: 20.0\n",
      "i: 267 \tReward: 15.0 \tLength: 14.0\n",
      "i: 268 \tReward: 34.0 \tLength: 33.0\n",
      "i: 269 \tReward: 40.0 \tLength: 39.0\n",
      "i: 270 \tReward: 49.0 \tLength: 48.0\n",
      "i: 271 \tReward: 13.0 \tLength: 12.0\n",
      "i: 272 \tReward: 28.0 \tLength: 27.0\n",
      "i: 273 \tReward: 16.0 \tLength: 15.0\n",
      "i: 274 \tReward: 50.0 \tLength: 49.0\n",
      "i: 275 \tReward: 14.0 \tLength: 13.0\n",
      "i: 276 \tReward: 17.0 \tLength: 16.0\n",
      "i: 277 \tReward: 43.0 \tLength: 42.0\n",
      "i: 278 \tReward: 12.0 \tLength: 11.0\n",
      "i: 279 \tReward: 12.0 \tLength: 11.0\n",
      "i: 280 \tReward: 26.0 \tLength: 25.0\n",
      "i: 281 \tReward: 23.0 \tLength: 22.0\n",
      "i: 282 \tReward: 26.0 \tLength: 25.0\n",
      "i: 283 \tReward: 13.0 \tLength: 12.0\n",
      "i: 284 \tReward: 15.0 \tLength: 14.0\n",
      "i: 285 \tReward: 12.0 \tLength: 11.0\n",
      "i: 286 \tReward: 19.0 \tLength: 18.0\n",
      "i: 287 \tReward: 18.0 \tLength: 17.0\n",
      "i: 288 \tReward: 16.0 \tLength: 15.0\n",
      "i: 289 \tReward: 30.0 \tLength: 29.0\n",
      "i: 290 \tReward: 14.0 \tLength: 13.0\n",
      "i: 291 \tReward: 11.0 \tLength: 10.0\n",
      "i: 292 \tReward: 18.0 \tLength: 17.0\n",
      "i: 293 \tReward: 15.0 \tLength: 14.0\n",
      "i: 294 \tReward: 10.0 \tLength: 9.0\n",
      "i: 295 \tReward: 13.0 \tLength: 12.0\n",
      "i: 296 \tReward: 20.0 \tLength: 19.0\n",
      "i: 297 \tReward: 21.0 \tLength: 20.0\n",
      "i: 298 \tReward: 11.0 \tLength: 10.0\n",
      "i: 299 \tReward: 18.0 \tLength: 17.0\n",
      "i: 300 \tReward: 44.0 \tLength: 43.0\n",
      "i: 301 \tReward: 30.0 \tLength: 29.0\n",
      "i: 302 \tReward: 13.0 \tLength: 12.0\n",
      "i: 303 \tReward: 12.0 \tLength: 11.0\n",
      "i: 304 \tReward: 17.0 \tLength: 16.0\n",
      "i: 305 \tReward: 13.0 \tLength: 12.0\n",
      "i: 306 \tReward: 11.0 \tLength: 10.0\n",
      "i: 307 \tReward: 16.0 \tLength: 15.0\n",
      "i: 308 \tReward: 18.0 \tLength: 17.0\n",
      "i: 309 \tReward: 13.0 \tLength: 12.0\n",
      "i: 310 \tReward: 18.0 \tLength: 17.0\n",
      "i: 311 \tReward: 12.0 \tLength: 11.0\n",
      "i: 312 \tReward: 11.0 \tLength: 10.0\n",
      "i: 313 \tReward: 32.0 \tLength: 31.0\n",
      "i: 314 \tReward: 43.0 \tLength: 42.0\n",
      "i: 315 \tReward: 10.0 \tLength: 9.0\n",
      "i: 316 \tReward: 22.0 \tLength: 21.0\n",
      "i: 317 \tReward: 10.0 \tLength: 9.0\n",
      "i: 318 \tReward: 21.0 \tLength: 20.0\n",
      "i: 319 \tReward: 21.0 \tLength: 20.0\n",
      "i: 320 \tReward: 27.0 \tLength: 26.0\n",
      "i: 321 \tReward: 29.0 \tLength: 28.0\n",
      "i: 322 \tReward: 14.0 \tLength: 13.0\n",
      "i: 323 \tReward: 13.0 \tLength: 12.0\n",
      "i: 324 \tReward: 18.0 \tLength: 17.0\n",
      "i: 325 \tReward: 18.0 \tLength: 17.0\n",
      "i: 326 \tReward: 57.0 \tLength: 56.0\n",
      "i: 327 \tReward: 34.0 \tLength: 33.0\n",
      "i: 328 \tReward: 22.0 \tLength: 21.0\n",
      "i: 329 \tReward: 31.0 \tLength: 30.0\n",
      "i: 330 \tReward: 43.0 \tLength: 42.0\n",
      "i: 331 \tReward: 25.0 \tLength: 24.0\n",
      "i: 332 \tReward: 20.0 \tLength: 19.0\n",
      "i: 333 \tReward: 39.0 \tLength: 38.0\n",
      "i: 334 \tReward: 49.0 \tLength: 48.0\n",
      "i: 335 \tReward: 24.0 \tLength: 23.0\n",
      "i: 336 \tReward: 31.0 \tLength: 30.0\n",
      "i: 337 \tReward: 15.0 \tLength: 14.0\n",
      "i: 338 \tReward: 27.0 \tLength: 26.0\n",
      "i: 339 \tReward: 10.0 \tLength: 9.0\n",
      "i: 340 \tReward: 27.0 \tLength: 26.0\n",
      "i: 341 \tReward: 22.0 \tLength: 21.0\n",
      "i: 342 \tReward: 24.0 \tLength: 23.0\n",
      "i: 343 \tReward: 15.0 \tLength: 14.0\n",
      "i: 344 \tReward: 11.0 \tLength: 10.0\n",
      "i: 345 \tReward: 22.0 \tLength: 21.0\n",
      "i: 346 \tReward: 23.0 \tLength: 22.0\n",
      "i: 347 \tReward: 26.0 \tLength: 25.0\n",
      "i: 348 \tReward: 13.0 \tLength: 12.0\n",
      "i: 349 \tReward: 21.0 \tLength: 20.0\n",
      "i: 350 \tReward: 60.0 \tLength: 59.0\n",
      "i: 351 \tReward: 21.0 \tLength: 20.0\n",
      "i: 352 \tReward: 17.0 \tLength: 16.0\n",
      "i: 353 \tReward: 29.0 \tLength: 28.0\n",
      "i: 354 \tReward: 14.0 \tLength: 13.0\n",
      "i: 355 \tReward: 20.0 \tLength: 19.0\n",
      "i: 356 \tReward: 25.0 \tLength: 24.0\n",
      "i: 357 \tReward: 10.0 \tLength: 9.0\n",
      "i: 358 \tReward: 59.0 \tLength: 58.0\n",
      "i: 359 \tReward: 17.0 \tLength: 16.0\n",
      "i: 360 \tReward: 17.0 \tLength: 16.0\n",
      "i: 361 \tReward: 42.0 \tLength: 41.0\n",
      "i: 362 \tReward: 18.0 \tLength: 17.0\n",
      "i: 363 \tReward: 24.0 \tLength: 23.0\n",
      "i: 364 \tReward: 34.0 \tLength: 33.0\n",
      "i: 365 \tReward: 13.0 \tLength: 12.0\n",
      "i: 366 \tReward: 36.0 \tLength: 35.0\n",
      "i: 367 \tReward: 36.0 \tLength: 35.0\n",
      "i: 368 \tReward: 25.0 \tLength: 24.0\n",
      "i: 369 \tReward: 20.0 \tLength: 19.0\n",
      "i: 370 \tReward: 30.0 \tLength: 29.0\n",
      "i: 371 \tReward: 16.0 \tLength: 15.0\n",
      "i: 372 \tReward: 47.0 \tLength: 46.0\n",
      "i: 373 \tReward: 16.0 \tLength: 15.0\n",
      "i: 374 \tReward: 15.0 \tLength: 14.0\n",
      "i: 375 \tReward: 21.0 \tLength: 20.0\n",
      "i: 376 \tReward: 46.0 \tLength: 45.0\n",
      "i: 377 \tReward: 15.0 \tLength: 14.0\n",
      "i: 378 \tReward: 29.0 \tLength: 28.0\n",
      "i: 379 \tReward: 27.0 \tLength: 26.0\n",
      "i: 380 \tReward: 8.0 \tLength: 7.0\n",
      "i: 381 \tReward: 30.0 \tLength: 29.0\n",
      "i: 382 \tReward: 8.0 \tLength: 7.0\n",
      "i: 383 \tReward: 15.0 \tLength: 14.0\n",
      "i: 384 \tReward: 24.0 \tLength: 23.0\n",
      "i: 385 \tReward: 58.0 \tLength: 57.0\n",
      "i: 386 \tReward: 19.0 \tLength: 18.0\n",
      "i: 387 \tReward: 16.0 \tLength: 15.0\n",
      "i: 388 \tReward: 23.0 \tLength: 22.0\n",
      "i: 389 \tReward: 18.0 \tLength: 17.0\n",
      "i: 390 \tReward: 60.0 \tLength: 59.0\n",
      "i: 391 \tReward: 14.0 \tLength: 13.0\n",
      "i: 392 \tReward: 20.0 \tLength: 19.0\n",
      "i: 393 \tReward: 35.0 \tLength: 34.0\n",
      "i: 394 \tReward: 22.0 \tLength: 21.0\n",
      "i: 395 \tReward: 38.0 \tLength: 37.0\n",
      "i: 396 \tReward: 10.0 \tLength: 9.0\n",
      "i: 397 \tReward: 16.0 \tLength: 15.0\n",
      "i: 398 \tReward: 33.0 \tLength: 32.0\n",
      "i: 399 \tReward: 16.0 \tLength: 15.0\n",
      "i: 400 \tReward: 14.0 \tLength: 13.0\n",
      "i: 401 \tReward: 10.0 \tLength: 9.0\n",
      "i: 402 \tReward: 39.0 \tLength: 38.0\n",
      "i: 403 \tReward: 22.0 \tLength: 21.0\n",
      "i: 404 \tReward: 32.0 \tLength: 31.0\n",
      "i: 405 \tReward: 24.0 \tLength: 23.0\n",
      "i: 406 \tReward: 21.0 \tLength: 20.0\n",
      "i: 407 \tReward: 11.0 \tLength: 10.0\n",
      "i: 408 \tReward: 49.0 \tLength: 48.0\n",
      "i: 409 \tReward: 14.0 \tLength: 13.0\n",
      "i: 410 \tReward: 23.0 \tLength: 22.0\n",
      "i: 411 \tReward: 40.0 \tLength: 39.0\n",
      "i: 412 \tReward: 12.0 \tLength: 11.0\n",
      "i: 413 \tReward: 20.0 \tLength: 19.0\n",
      "i: 414 \tReward: 13.0 \tLength: 12.0\n",
      "i: 415 \tReward: 17.0 \tLength: 16.0\n",
      "i: 416 \tReward: 13.0 \tLength: 12.0\n",
      "i: 417 \tReward: 15.0 \tLength: 14.0\n",
      "i: 418 \tReward: 50.0 \tLength: 49.0\n",
      "i: 419 \tReward: 23.0 \tLength: 22.0\n",
      "i: 420 \tReward: 32.0 \tLength: 31.0\n",
      "i: 421 \tReward: 35.0 \tLength: 34.0\n",
      "i: 422 \tReward: 10.0 \tLength: 9.0\n",
      "i: 423 \tReward: 14.0 \tLength: 13.0\n",
      "i: 424 \tReward: 18.0 \tLength: 17.0\n",
      "i: 425 \tReward: 17.0 \tLength: 16.0\n",
      "i: 426 \tReward: 24.0 \tLength: 23.0\n",
      "i: 427 \tReward: 11.0 \tLength: 10.0\n",
      "i: 428 \tReward: 13.0 \tLength: 12.0\n",
      "i: 429 \tReward: 19.0 \tLength: 18.0\n",
      "i: 430 \tReward: 22.0 \tLength: 21.0\n",
      "i: 431 \tReward: 19.0 \tLength: 18.0\n",
      "i: 432 \tReward: 12.0 \tLength: 11.0\n",
      "i: 433 \tReward: 42.0 \tLength: 41.0\n",
      "i: 434 \tReward: 11.0 \tLength: 10.0\n",
      "i: 435 \tReward: 38.0 \tLength: 37.0\n",
      "i: 436 \tReward: 27.0 \tLength: 26.0\n",
      "i: 437 \tReward: 48.0 \tLength: 47.0\n",
      "i: 438 \tReward: 40.0 \tLength: 39.0\n",
      "i: 439 \tReward: 13.0 \tLength: 12.0\n",
      "i: 440 \tReward: 13.0 \tLength: 12.0\n",
      "i: 441 \tReward: 11.0 \tLength: 10.0\n",
      "i: 442 \tReward: 9.0 \tLength: 8.0\n",
      "i: 443 \tReward: 31.0 \tLength: 30.0\n",
      "i: 444 \tReward: 35.0 \tLength: 34.0\n",
      "i: 445 \tReward: 34.0 \tLength: 33.0\n",
      "i: 446 \tReward: 16.0 \tLength: 15.0\n",
      "i: 447 \tReward: 24.0 \tLength: 23.0\n",
      "i: 448 \tReward: 16.0 \tLength: 15.0\n",
      "i: 449 \tReward: 15.0 \tLength: 14.0\n",
      "i: 450 \tReward: 9.0 \tLength: 8.0\n",
      "i: 451 \tReward: 16.0 \tLength: 15.0\n",
      "i: 452 \tReward: 15.0 \tLength: 14.0\n",
      "i: 453 \tReward: 17.0 \tLength: 16.0\n",
      "i: 454 \tReward: 36.0 \tLength: 35.0\n",
      "i: 455 \tReward: 12.0 \tLength: 11.0\n",
      "i: 456 \tReward: 57.0 \tLength: 56.0\n",
      "i: 457 \tReward: 14.0 \tLength: 13.0\n",
      "i: 458 \tReward: 26.0 \tLength: 25.0\n",
      "i: 459 \tReward: 49.0 \tLength: 48.0\n",
      "i: 460 \tReward: 18.0 \tLength: 17.0\n",
      "i: 461 \tReward: 21.0 \tLength: 20.0\n",
      "i: 462 \tReward: 11.0 \tLength: 10.0\n",
      "i: 463 \tReward: 17.0 \tLength: 16.0\n",
      "i: 464 \tReward: 25.0 \tLength: 24.0\n",
      "i: 465 \tReward: 12.0 \tLength: 11.0\n",
      "i: 466 \tReward: 20.0 \tLength: 19.0\n",
      "i: 467 \tReward: 19.0 \tLength: 18.0\n",
      "i: 468 \tReward: 27.0 \tLength: 26.0\n",
      "i: 469 \tReward: 33.0 \tLength: 32.0\n",
      "i: 470 \tReward: 66.0 \tLength: 65.0\n",
      "i: 471 \tReward: 16.0 \tLength: 15.0\n",
      "i: 472 \tReward: 53.0 \tLength: 52.0\n",
      "i: 473 \tReward: 48.0 \tLength: 47.0\n",
      "i: 474 \tReward: 12.0 \tLength: 11.0\n",
      "i: 475 \tReward: 15.0 \tLength: 14.0\n",
      "i: 476 \tReward: 23.0 \tLength: 22.0\n",
      "i: 477 \tReward: 23.0 \tLength: 22.0\n",
      "i: 478 \tReward: 35.0 \tLength: 34.0\n",
      "i: 479 \tReward: 19.0 \tLength: 18.0\n",
      "i: 480 \tReward: 14.0 \tLength: 13.0\n",
      "i: 481 \tReward: 31.0 \tLength: 30.0\n",
      "i: 482 \tReward: 18.0 \tLength: 17.0\n",
      "i: 483 \tReward: 13.0 \tLength: 12.0\n",
      "i: 484 \tReward: 13.0 \tLength: 12.0\n",
      "i: 485 \tReward: 15.0 \tLength: 14.0\n",
      "i: 486 \tReward: 22.0 \tLength: 21.0\n",
      "i: 487 \tReward: 15.0 \tLength: 14.0\n",
      "i: 488 \tReward: 14.0 \tLength: 13.0\n",
      "i: 489 \tReward: 33.0 \tLength: 32.0\n",
      "i: 490 \tReward: 14.0 \tLength: 13.0\n",
      "i: 491 \tReward: 16.0 \tLength: 15.0\n",
      "i: 492 \tReward: 16.0 \tLength: 15.0\n",
      "i: 493 \tReward: 14.0 \tLength: 13.0\n",
      "i: 494 \tReward: 22.0 \tLength: 21.0\n",
      "i: 495 \tReward: 13.0 \tLength: 12.0\n",
      "i: 496 \tReward: 12.0 \tLength: 11.0\n",
      "i: 497 \tReward: 15.0 \tLength: 14.0\n",
      "i: 498 \tReward: 14.0 \tLength: 13.0\n",
      "i: 499 \tReward: 21.0 \tLength: 20.0\n",
      "i: 500 \tReward: 12.0 \tLength: 11.0\n",
      "i: 501 \tReward: 18.0 \tLength: 17.0\n",
      "i: 502 \tReward: 14.0 \tLength: 13.0\n",
      "i: 503 \tReward: 15.0 \tLength: 14.0\n",
      "i: 504 \tReward: 32.0 \tLength: 31.0\n",
      "i: 505 \tReward: 16.0 \tLength: 15.0\n",
      "i: 506 \tReward: 11.0 \tLength: 10.0\n",
      "i: 507 \tReward: 19.0 \tLength: 18.0\n",
      "i: 508 \tReward: 38.0 \tLength: 37.0\n",
      "i: 509 \tReward: 9.0 \tLength: 8.0\n",
      "i: 510 \tReward: 10.0 \tLength: 9.0\n",
      "i: 511 \tReward: 9.0 \tLength: 8.0\n",
      "i: 512 \tReward: 12.0 \tLength: 11.0\n",
      "i: 513 \tReward: 19.0 \tLength: 18.0\n",
      "i: 514 \tReward: 30.0 \tLength: 29.0\n",
      "i: 515 \tReward: 18.0 \tLength: 17.0\n",
      "i: 516 \tReward: 14.0 \tLength: 13.0\n",
      "i: 517 \tReward: 14.0 \tLength: 13.0\n",
      "i: 518 \tReward: 24.0 \tLength: 23.0\n",
      "i: 519 \tReward: 11.0 \tLength: 10.0\n",
      "i: 520 \tReward: 42.0 \tLength: 41.0\n",
      "i: 521 \tReward: 10.0 \tLength: 9.0\n",
      "i: 522 \tReward: 25.0 \tLength: 24.0\n",
      "i: 523 \tReward: 19.0 \tLength: 18.0\n",
      "i: 524 \tReward: 13.0 \tLength: 12.0\n",
      "i: 525 \tReward: 32.0 \tLength: 31.0\n",
      "i: 526 \tReward: 16.0 \tLength: 15.0\n",
      "i: 527 \tReward: 25.0 \tLength: 24.0\n",
      "i: 528 \tReward: 33.0 \tLength: 32.0\n",
      "i: 529 \tReward: 16.0 \tLength: 15.0\n",
      "i: 530 \tReward: 29.0 \tLength: 28.0\n",
      "i: 531 \tReward: 32.0 \tLength: 31.0\n",
      "i: 532 \tReward: 20.0 \tLength: 19.0\n",
      "i: 533 \tReward: 35.0 \tLength: 34.0\n",
      "i: 534 \tReward: 12.0 \tLength: 11.0\n",
      "i: 535 \tReward: 19.0 \tLength: 18.0\n",
      "i: 536 \tReward: 17.0 \tLength: 16.0\n",
      "i: 537 \tReward: 40.0 \tLength: 39.0\n",
      "i: 538 \tReward: 10.0 \tLength: 9.0\n",
      "i: 539 \tReward: 17.0 \tLength: 16.0\n",
      "i: 540 \tReward: 12.0 \tLength: 11.0\n",
      "i: 541 \tReward: 17.0 \tLength: 16.0\n",
      "i: 542 \tReward: 46.0 \tLength: 45.0\n",
      "i: 543 \tReward: 13.0 \tLength: 12.0\n",
      "i: 544 \tReward: 16.0 \tLength: 15.0\n",
      "i: 545 \tReward: 11.0 \tLength: 10.0\n",
      "i: 546 \tReward: 29.0 \tLength: 28.0\n",
      "i: 547 \tReward: 21.0 \tLength: 20.0\n",
      "i: 548 \tReward: 34.0 \tLength: 33.0\n",
      "i: 549 \tReward: 12.0 \tLength: 11.0\n",
      "i: 550 \tReward: 19.0 \tLength: 18.0\n",
      "i: 551 \tReward: 10.0 \tLength: 9.0\n",
      "i: 552 \tReward: 12.0 \tLength: 11.0\n",
      "i: 553 \tReward: 21.0 \tLength: 20.0\n",
      "i: 554 \tReward: 18.0 \tLength: 17.0\n",
      "i: 555 \tReward: 10.0 \tLength: 9.0\n",
      "i: 556 \tReward: 23.0 \tLength: 22.0\n",
      "i: 557 \tReward: 15.0 \tLength: 14.0\n",
      "i: 558 \tReward: 18.0 \tLength: 17.0\n",
      "i: 559 \tReward: 19.0 \tLength: 18.0\n",
      "i: 560 \tReward: 18.0 \tLength: 17.0\n",
      "i: 561 \tReward: 22.0 \tLength: 21.0\n",
      "i: 562 \tReward: 11.0 \tLength: 10.0\n",
      "i: 563 \tReward: 30.0 \tLength: 29.0\n",
      "i: 564 \tReward: 27.0 \tLength: 26.0\n",
      "i: 565 \tReward: 17.0 \tLength: 16.0\n",
      "i: 566 \tReward: 26.0 \tLength: 25.0\n",
      "i: 567 \tReward: 17.0 \tLength: 16.0\n",
      "i: 568 \tReward: 18.0 \tLength: 17.0\n",
      "i: 569 \tReward: 20.0 \tLength: 19.0\n",
      "i: 570 \tReward: 13.0 \tLength: 12.0\n",
      "i: 571 \tReward: 12.0 \tLength: 11.0\n",
      "i: 572 \tReward: 45.0 \tLength: 44.0\n",
      "i: 573 \tReward: 25.0 \tLength: 24.0\n",
      "i: 574 \tReward: 69.0 \tLength: 68.0\n",
      "i: 575 \tReward: 14.0 \tLength: 13.0\n",
      "i: 576 \tReward: 11.0 \tLength: 10.0\n",
      "i: 577 \tReward: 24.0 \tLength: 23.0\n",
      "i: 578 \tReward: 14.0 \tLength: 13.0\n",
      "i: 579 \tReward: 15.0 \tLength: 14.0\n",
      "i: 580 \tReward: 22.0 \tLength: 21.0\n",
      "i: 581 \tReward: 17.0 \tLength: 16.0\n",
      "i: 582 \tReward: 23.0 \tLength: 22.0\n",
      "i: 583 \tReward: 12.0 \tLength: 11.0\n",
      "i: 584 \tReward: 16.0 \tLength: 15.0\n",
      "i: 585 \tReward: 28.0 \tLength: 27.0\n",
      "i: 586 \tReward: 11.0 \tLength: 10.0\n",
      "i: 587 \tReward: 18.0 \tLength: 17.0\n",
      "i: 588 \tReward: 35.0 \tLength: 34.0\n",
      "i: 589 \tReward: 25.0 \tLength: 24.0\n",
      "i: 590 \tReward: 9.0 \tLength: 8.0\n",
      "i: 591 \tReward: 15.0 \tLength: 14.0\n",
      "i: 592 \tReward: 13.0 \tLength: 12.0\n",
      "i: 593 \tReward: 23.0 \tLength: 22.0\n",
      "i: 594 \tReward: 76.0 \tLength: 75.0\n",
      "i: 595 \tReward: 12.0 \tLength: 11.0\n",
      "i: 596 \tReward: 30.0 \tLength: 29.0\n",
      "i: 597 \tReward: 11.0 \tLength: 10.0\n",
      "i: 598 \tReward: 24.0 \tLength: 23.0\n",
      "i: 599 \tReward: 15.0 \tLength: 14.0\n",
      "i: 600 \tReward: 13.0 \tLength: 12.0\n",
      "i: 601 \tReward: 29.0 \tLength: 28.0\n",
      "i: 602 \tReward: 19.0 \tLength: 18.0\n",
      "i: 603 \tReward: 31.0 \tLength: 30.0\n",
      "i: 604 \tReward: 25.0 \tLength: 24.0\n",
      "i: 605 \tReward: 45.0 \tLength: 44.0\n",
      "i: 606 \tReward: 15.0 \tLength: 14.0\n",
      "i: 607 \tReward: 17.0 \tLength: 16.0\n",
      "i: 608 \tReward: 13.0 \tLength: 12.0\n",
      "i: 609 \tReward: 21.0 \tLength: 20.0\n",
      "i: 610 \tReward: 13.0 \tLength: 12.0\n",
      "i: 611 \tReward: 47.0 \tLength: 46.0\n",
      "i: 612 \tReward: 52.0 \tLength: 51.0\n",
      "i: 613 \tReward: 15.0 \tLength: 14.0\n",
      "i: 614 \tReward: 27.0 \tLength: 26.0\n",
      "i: 615 \tReward: 30.0 \tLength: 29.0\n",
      "i: 616 \tReward: 13.0 \tLength: 12.0\n",
      "i: 617 \tReward: 11.0 \tLength: 10.0\n",
      "i: 618 \tReward: 38.0 \tLength: 37.0\n",
      "i: 619 \tReward: 16.0 \tLength: 15.0\n",
      "i: 620 \tReward: 28.0 \tLength: 27.0\n",
      "i: 621 \tReward: 20.0 \tLength: 19.0\n",
      "i: 622 \tReward: 37.0 \tLength: 36.0\n",
      "i: 623 \tReward: 37.0 \tLength: 36.0\n",
      "i: 624 \tReward: 12.0 \tLength: 11.0\n",
      "i: 625 \tReward: 15.0 \tLength: 14.0\n",
      "i: 626 \tReward: 26.0 \tLength: 25.0\n",
      "i: 627 \tReward: 8.0 \tLength: 7.0\n",
      "i: 628 \tReward: 13.0 \tLength: 12.0\n",
      "i: 629 \tReward: 24.0 \tLength: 23.0\n",
      "i: 630 \tReward: 12.0 \tLength: 11.0\n",
      "i: 631 \tReward: 16.0 \tLength: 15.0\n",
      "i: 632 \tReward: 19.0 \tLength: 18.0\n",
      "i: 633 \tReward: 20.0 \tLength: 19.0\n",
      "i: 634 \tReward: 22.0 \tLength: 21.0\n",
      "i: 635 \tReward: 44.0 \tLength: 43.0\n",
      "i: 636 \tReward: 24.0 \tLength: 23.0\n",
      "i: 637 \tReward: 24.0 \tLength: 23.0\n",
      "i: 638 \tReward: 12.0 \tLength: 11.0\n",
      "i: 639 \tReward: 23.0 \tLength: 22.0\n",
      "i: 640 \tReward: 16.0 \tLength: 15.0\n",
      "i: 641 \tReward: 15.0 \tLength: 14.0\n",
      "i: 642 \tReward: 26.0 \tLength: 25.0\n",
      "i: 643 \tReward: 34.0 \tLength: 33.0\n",
      "i: 644 \tReward: 26.0 \tLength: 25.0\n",
      "i: 645 \tReward: 11.0 \tLength: 10.0\n",
      "i: 646 \tReward: 16.0 \tLength: 15.0\n",
      "i: 647 \tReward: 44.0 \tLength: 43.0\n",
      "i: 648 \tReward: 18.0 \tLength: 17.0\n",
      "i: 649 \tReward: 12.0 \tLength: 11.0\n",
      "i: 650 \tReward: 12.0 \tLength: 11.0\n",
      "i: 651 \tReward: 16.0 \tLength: 15.0\n",
      "i: 652 \tReward: 13.0 \tLength: 12.0\n",
      "i: 653 \tReward: 26.0 \tLength: 25.0\n",
      "i: 654 \tReward: 12.0 \tLength: 11.0\n",
      "i: 655 \tReward: 28.0 \tLength: 27.0\n",
      "i: 656 \tReward: 27.0 \tLength: 26.0\n",
      "i: 657 \tReward: 28.0 \tLength: 27.0\n",
      "i: 658 \tReward: 16.0 \tLength: 15.0\n",
      "i: 659 \tReward: 16.0 \tLength: 15.0\n",
      "i: 660 \tReward: 14.0 \tLength: 13.0\n",
      "i: 661 \tReward: 12.0 \tLength: 11.0\n",
      "i: 662 \tReward: 14.0 \tLength: 13.0\n",
      "i: 663 \tReward: 13.0 \tLength: 12.0\n",
      "i: 664 \tReward: 77.0 \tLength: 76.0\n",
      "i: 665 \tReward: 12.0 \tLength: 11.0\n",
      "i: 666 \tReward: 50.0 \tLength: 49.0\n",
      "i: 667 \tReward: 37.0 \tLength: 36.0\n",
      "i: 668 \tReward: 17.0 \tLength: 16.0\n",
      "i: 669 \tReward: 18.0 \tLength: 17.0\n",
      "i: 670 \tReward: 19.0 \tLength: 18.0\n",
      "i: 671 \tReward: 21.0 \tLength: 20.0\n",
      "i: 672 \tReward: 22.0 \tLength: 21.0\n",
      "i: 673 \tReward: 13.0 \tLength: 12.0\n",
      "i: 674 \tReward: 15.0 \tLength: 14.0\n",
      "i: 675 \tReward: 14.0 \tLength: 13.0\n",
      "i: 676 \tReward: 20.0 \tLength: 19.0\n",
      "i: 677 \tReward: 21.0 \tLength: 20.0\n",
      "i: 678 \tReward: 22.0 \tLength: 21.0\n",
      "i: 679 \tReward: 18.0 \tLength: 17.0\n",
      "i: 680 \tReward: 13.0 \tLength: 12.0\n",
      "i: 681 \tReward: 14.0 \tLength: 13.0\n",
      "i: 682 \tReward: 41.0 \tLength: 40.0\n",
      "i: 683 \tReward: 23.0 \tLength: 22.0\n",
      "i: 684 \tReward: 24.0 \tLength: 23.0\n",
      "i: 685 \tReward: 10.0 \tLength: 9.0\n",
      "i: 686 \tReward: 13.0 \tLength: 12.0\n",
      "i: 687 \tReward: 46.0 \tLength: 45.0\n",
      "i: 688 \tReward: 17.0 \tLength: 16.0\n",
      "i: 689 \tReward: 19.0 \tLength: 18.0\n",
      "i: 690 \tReward: 20.0 \tLength: 19.0\n",
      "i: 691 \tReward: 11.0 \tLength: 10.0\n",
      "i: 692 \tReward: 25.0 \tLength: 24.0\n",
      "i: 693 \tReward: 12.0 \tLength: 11.0\n",
      "i: 694 \tReward: 10.0 \tLength: 9.0\n",
      "i: 695 \tReward: 18.0 \tLength: 17.0\n",
      "i: 696 \tReward: 28.0 \tLength: 27.0\n",
      "i: 697 \tReward: 20.0 \tLength: 19.0\n",
      "i: 698 \tReward: 15.0 \tLength: 14.0\n",
      "i: 699 \tReward: 26.0 \tLength: 25.0\n",
      "i: 700 \tReward: 16.0 \tLength: 15.0\n",
      "i: 701 \tReward: 16.0 \tLength: 15.0\n",
      "i: 702 \tReward: 30.0 \tLength: 29.0\n",
      "i: 703 \tReward: 18.0 \tLength: 17.0\n",
      "i: 704 \tReward: 17.0 \tLength: 16.0\n",
      "i: 705 \tReward: 25.0 \tLength: 24.0\n",
      "i: 706 \tReward: 33.0 \tLength: 32.0\n",
      "i: 707 \tReward: 13.0 \tLength: 12.0\n",
      "i: 708 \tReward: 15.0 \tLength: 14.0\n",
      "i: 709 \tReward: 13.0 \tLength: 12.0\n",
      "i: 710 \tReward: 11.0 \tLength: 10.0\n",
      "i: 711 \tReward: 23.0 \tLength: 22.0\n",
      "i: 712 \tReward: 13.0 \tLength: 12.0\n",
      "i: 713 \tReward: 12.0 \tLength: 11.0\n",
      "i: 714 \tReward: 15.0 \tLength: 14.0\n",
      "i: 715 \tReward: 17.0 \tLength: 16.0\n",
      "i: 716 \tReward: 14.0 \tLength: 13.0\n",
      "i: 717 \tReward: 14.0 \tLength: 13.0\n",
      "i: 718 \tReward: 22.0 \tLength: 21.0\n",
      "i: 719 \tReward: 25.0 \tLength: 24.0\n",
      "i: 720 \tReward: 24.0 \tLength: 23.0\n",
      "i: 721 \tReward: 13.0 \tLength: 12.0\n",
      "i: 722 \tReward: 23.0 \tLength: 22.0\n",
      "i: 723 \tReward: 24.0 \tLength: 23.0\n",
      "i: 724 \tReward: 14.0 \tLength: 13.0\n",
      "i: 725 \tReward: 17.0 \tLength: 16.0\n",
      "i: 726 \tReward: 8.0 \tLength: 7.0\n",
      "i: 727 \tReward: 22.0 \tLength: 21.0\n",
      "i: 728 \tReward: 19.0 \tLength: 18.0\n",
      "i: 729 \tReward: 16.0 \tLength: 15.0\n",
      "i: 730 \tReward: 10.0 \tLength: 9.0\n",
      "i: 731 \tReward: 15.0 \tLength: 14.0\n",
      "i: 732 \tReward: 25.0 \tLength: 24.0\n",
      "i: 733 \tReward: 19.0 \tLength: 18.0\n",
      "i: 734 \tReward: 40.0 \tLength: 39.0\n",
      "i: 735 \tReward: 21.0 \tLength: 20.0\n",
      "i: 736 \tReward: 23.0 \tLength: 22.0\n",
      "i: 737 \tReward: 20.0 \tLength: 19.0\n",
      "i: 738 \tReward: 16.0 \tLength: 15.0\n",
      "i: 739 \tReward: 13.0 \tLength: 12.0\n",
      "i: 740 \tReward: 22.0 \tLength: 21.0\n",
      "i: 741 \tReward: 29.0 \tLength: 28.0\n",
      "i: 742 \tReward: 20.0 \tLength: 19.0\n",
      "i: 743 \tReward: 9.0 \tLength: 8.0\n",
      "i: 744 \tReward: 28.0 \tLength: 27.0\n",
      "i: 745 \tReward: 29.0 \tLength: 28.0\n",
      "i: 746 \tReward: 32.0 \tLength: 31.0\n",
      "i: 747 \tReward: 18.0 \tLength: 17.0\n",
      "i: 748 \tReward: 23.0 \tLength: 22.0\n",
      "i: 749 \tReward: 13.0 \tLength: 12.0\n",
      "i: 750 \tReward: 15.0 \tLength: 14.0\n",
      "i: 751 \tReward: 29.0 \tLength: 28.0\n",
      "i: 752 \tReward: 15.0 \tLength: 14.0\n",
      "i: 753 \tReward: 15.0 \tLength: 14.0\n",
      "i: 754 \tReward: 19.0 \tLength: 18.0\n",
      "i: 755 \tReward: 16.0 \tLength: 15.0\n",
      "i: 756 \tReward: 27.0 \tLength: 26.0\n",
      "i: 757 \tReward: 14.0 \tLength: 13.0\n",
      "i: 758 \tReward: 21.0 \tLength: 20.0\n",
      "i: 759 \tReward: 18.0 \tLength: 17.0\n",
      "i: 760 \tReward: 10.0 \tLength: 9.0\n",
      "i: 761 \tReward: 23.0 \tLength: 22.0\n",
      "i: 762 \tReward: 95.0 \tLength: 94.0\n",
      "i: 763 \tReward: 9.0 \tLength: 8.0\n",
      "i: 764 \tReward: 10.0 \tLength: 9.0\n",
      "i: 765 \tReward: 23.0 \tLength: 22.0\n",
      "i: 766 \tReward: 38.0 \tLength: 37.0\n",
      "i: 767 \tReward: 26.0 \tLength: 25.0\n",
      "i: 768 \tReward: 12.0 \tLength: 11.0\n",
      "i: 769 \tReward: 27.0 \tLength: 26.0\n",
      "i: 770 \tReward: 62.0 \tLength: 61.0\n",
      "i: 771 \tReward: 19.0 \tLength: 18.0\n",
      "i: 772 \tReward: 23.0 \tLength: 22.0\n",
      "i: 773 \tReward: 19.0 \tLength: 18.0\n",
      "i: 774 \tReward: 20.0 \tLength: 19.0\n",
      "i: 775 \tReward: 22.0 \tLength: 21.0\n",
      "i: 776 \tReward: 23.0 \tLength: 22.0\n",
      "i: 777 \tReward: 25.0 \tLength: 24.0\n",
      "i: 778 \tReward: 17.0 \tLength: 16.0\n",
      "i: 779 \tReward: 29.0 \tLength: 28.0\n",
      "i: 780 \tReward: 24.0 \tLength: 23.0\n",
      "i: 781 \tReward: 16.0 \tLength: 15.0\n",
      "i: 782 \tReward: 16.0 \tLength: 15.0\n",
      "i: 783 \tReward: 36.0 \tLength: 35.0\n",
      "i: 784 \tReward: 28.0 \tLength: 27.0\n",
      "i: 785 \tReward: 12.0 \tLength: 11.0\n",
      "i: 786 \tReward: 14.0 \tLength: 13.0\n",
      "i: 787 \tReward: 49.0 \tLength: 48.0\n",
      "i: 788 \tReward: 29.0 \tLength: 28.0\n",
      "i: 789 \tReward: 17.0 \tLength: 16.0\n",
      "i: 790 \tReward: 15.0 \tLength: 14.0\n",
      "i: 791 \tReward: 11.0 \tLength: 10.0\n",
      "i: 792 \tReward: 31.0 \tLength: 30.0\n",
      "i: 793 \tReward: 23.0 \tLength: 22.0\n",
      "i: 794 \tReward: 21.0 \tLength: 20.0\n",
      "i: 795 \tReward: 18.0 \tLength: 17.0\n",
      "i: 796 \tReward: 56.0 \tLength: 55.0\n",
      "i: 797 \tReward: 17.0 \tLength: 16.0\n",
      "i: 798 \tReward: 24.0 \tLength: 23.0\n",
      "i: 799 \tReward: 10.0 \tLength: 9.0\n",
      "i: 800 \tReward: 15.0 \tLength: 14.0\n",
      "i: 801 \tReward: 87.0 \tLength: 86.0\n",
      "i: 802 \tReward: 21.0 \tLength: 20.0\n",
      "i: 803 \tReward: 24.0 \tLength: 23.0\n",
      "i: 804 \tReward: 17.0 \tLength: 16.0\n",
      "i: 805 \tReward: 21.0 \tLength: 20.0\n",
      "i: 806 \tReward: 8.0 \tLength: 7.0\n",
      "i: 807 \tReward: 14.0 \tLength: 13.0\n",
      "i: 808 \tReward: 14.0 \tLength: 13.0\n",
      "i: 809 \tReward: 24.0 \tLength: 23.0\n",
      "i: 810 \tReward: 15.0 \tLength: 14.0\n",
      "i: 811 \tReward: 54.0 \tLength: 53.0\n",
      "i: 812 \tReward: 22.0 \tLength: 21.0\n",
      "i: 813 \tReward: 41.0 \tLength: 40.0\n",
      "i: 814 \tReward: 23.0 \tLength: 22.0\n",
      "i: 815 \tReward: 9.0 \tLength: 8.0\n",
      "i: 816 \tReward: 39.0 \tLength: 38.0\n",
      "i: 817 \tReward: 28.0 \tLength: 27.0\n",
      "i: 818 \tReward: 13.0 \tLength: 12.0\n",
      "i: 819 \tReward: 17.0 \tLength: 16.0\n",
      "i: 820 \tReward: 46.0 \tLength: 45.0\n",
      "i: 821 \tReward: 17.0 \tLength: 16.0\n",
      "i: 822 \tReward: 28.0 \tLength: 27.0\n",
      "i: 823 \tReward: 11.0 \tLength: 10.0\n",
      "i: 824 \tReward: 32.0 \tLength: 31.0\n",
      "i: 825 \tReward: 24.0 \tLength: 23.0\n",
      "i: 826 \tReward: 14.0 \tLength: 13.0\n",
      "i: 827 \tReward: 23.0 \tLength: 22.0\n",
      "i: 828 \tReward: 31.0 \tLength: 30.0\n",
      "i: 829 \tReward: 21.0 \tLength: 20.0\n",
      "i: 830 \tReward: 27.0 \tLength: 26.0\n",
      "i: 831 \tReward: 15.0 \tLength: 14.0\n",
      "i: 832 \tReward: 16.0 \tLength: 15.0\n",
      "i: 833 \tReward: 10.0 \tLength: 9.0\n",
      "i: 834 \tReward: 79.0 \tLength: 78.0\n",
      "i: 835 \tReward: 16.0 \tLength: 15.0\n",
      "i: 836 \tReward: 18.0 \tLength: 17.0\n",
      "i: 837 \tReward: 16.0 \tLength: 15.0\n",
      "i: 838 \tReward: 27.0 \tLength: 26.0\n",
      "i: 839 \tReward: 13.0 \tLength: 12.0\n",
      "i: 840 \tReward: 11.0 \tLength: 10.0\n",
      "i: 841 \tReward: 23.0 \tLength: 22.0\n",
      "i: 842 \tReward: 14.0 \tLength: 13.0\n",
      "i: 843 \tReward: 30.0 \tLength: 29.0\n",
      "i: 844 \tReward: 15.0 \tLength: 14.0\n",
      "i: 845 \tReward: 27.0 \tLength: 26.0\n",
      "i: 846 \tReward: 30.0 \tLength: 29.0\n",
      "i: 847 \tReward: 20.0 \tLength: 19.0\n",
      "i: 848 \tReward: 63.0 \tLength: 62.0\n",
      "i: 849 \tReward: 26.0 \tLength: 25.0\n",
      "i: 850 \tReward: 11.0 \tLength: 10.0\n",
      "i: 851 \tReward: 18.0 \tLength: 17.0\n",
      "i: 852 \tReward: 56.0 \tLength: 55.0\n",
      "i: 853 \tReward: 15.0 \tLength: 14.0\n",
      "i: 854 \tReward: 15.0 \tLength: 14.0\n",
      "i: 855 \tReward: 16.0 \tLength: 15.0\n",
      "i: 856 \tReward: 57.0 \tLength: 56.0\n",
      "i: 857 \tReward: 16.0 \tLength: 15.0\n",
      "i: 858 \tReward: 16.0 \tLength: 15.0\n",
      "i: 859 \tReward: 15.0 \tLength: 14.0\n",
      "i: 860 \tReward: 22.0 \tLength: 21.0\n",
      "i: 861 \tReward: 21.0 \tLength: 20.0\n",
      "i: 862 \tReward: 15.0 \tLength: 14.0\n",
      "i: 863 \tReward: 8.0 \tLength: 7.0\n",
      "i: 864 \tReward: 19.0 \tLength: 18.0\n",
      "i: 865 \tReward: 17.0 \tLength: 16.0\n",
      "i: 866 \tReward: 18.0 \tLength: 17.0\n",
      "i: 867 \tReward: 20.0 \tLength: 19.0\n",
      "i: 868 \tReward: 26.0 \tLength: 25.0\n",
      "i: 869 \tReward: 25.0 \tLength: 24.0\n",
      "i: 870 \tReward: 11.0 \tLength: 10.0\n",
      "i: 871 \tReward: 29.0 \tLength: 28.0\n",
      "i: 872 \tReward: 12.0 \tLength: 11.0\n",
      "i: 873 \tReward: 15.0 \tLength: 14.0\n",
      "i: 874 \tReward: 16.0 \tLength: 15.0\n",
      "i: 875 \tReward: 26.0 \tLength: 25.0\n",
      "i: 876 \tReward: 22.0 \tLength: 21.0\n",
      "i: 877 \tReward: 92.0 \tLength: 91.0\n",
      "i: 878 \tReward: 11.0 \tLength: 10.0\n",
      "i: 879 \tReward: 9.0 \tLength: 8.0\n",
      "i: 880 \tReward: 22.0 \tLength: 21.0\n",
      "i: 881 \tReward: 30.0 \tLength: 29.0\n",
      "i: 882 \tReward: 29.0 \tLength: 28.0\n",
      "i: 883 \tReward: 11.0 \tLength: 10.0\n",
      "i: 884 \tReward: 23.0 \tLength: 22.0\n",
      "i: 885 \tReward: 11.0 \tLength: 10.0\n",
      "i: 886 \tReward: 14.0 \tLength: 13.0\n",
      "i: 887 \tReward: 16.0 \tLength: 15.0\n",
      "i: 888 \tReward: 43.0 \tLength: 42.0\n",
      "i: 889 \tReward: 23.0 \tLength: 22.0\n",
      "i: 890 \tReward: 15.0 \tLength: 14.0\n",
      "i: 891 \tReward: 35.0 \tLength: 34.0\n",
      "i: 892 \tReward: 16.0 \tLength: 15.0\n",
      "i: 893 \tReward: 11.0 \tLength: 10.0\n",
      "i: 894 \tReward: 22.0 \tLength: 21.0\n",
      "i: 895 \tReward: 18.0 \tLength: 17.0\n",
      "i: 896 \tReward: 11.0 \tLength: 10.0\n",
      "i: 897 \tReward: 28.0 \tLength: 27.0\n",
      "i: 898 \tReward: 23.0 \tLength: 22.0\n",
      "i: 899 \tReward: 22.0 \tLength: 21.0\n",
      "i: 900 \tReward: 24.0 \tLength: 23.0\n",
      "i: 901 \tReward: 14.0 \tLength: 13.0\n",
      "i: 902 \tReward: 18.0 \tLength: 17.0\n",
      "i: 903 \tReward: 13.0 \tLength: 12.0\n",
      "i: 904 \tReward: 14.0 \tLength: 13.0\n",
      "i: 905 \tReward: 15.0 \tLength: 14.0\n",
      "i: 906 \tReward: 19.0 \tLength: 18.0\n",
      "i: 907 \tReward: 12.0 \tLength: 11.0\n",
      "i: 908 \tReward: 17.0 \tLength: 16.0\n",
      "i: 909 \tReward: 16.0 \tLength: 15.0\n",
      "i: 910 \tReward: 15.0 \tLength: 14.0\n",
      "i: 911 \tReward: 12.0 \tLength: 11.0\n",
      "i: 912 \tReward: 22.0 \tLength: 21.0\n",
      "i: 913 \tReward: 26.0 \tLength: 25.0\n",
      "i: 914 \tReward: 17.0 \tLength: 16.0\n",
      "i: 915 \tReward: 11.0 \tLength: 10.0\n",
      "i: 916 \tReward: 11.0 \tLength: 10.0\n",
      "i: 917 \tReward: 31.0 \tLength: 30.0\n",
      "i: 918 \tReward: 21.0 \tLength: 20.0\n",
      "i: 919 \tReward: 17.0 \tLength: 16.0\n",
      "i: 920 \tReward: 11.0 \tLength: 10.0\n",
      "i: 921 \tReward: 16.0 \tLength: 15.0\n",
      "i: 922 \tReward: 10.0 \tLength: 9.0\n",
      "i: 923 \tReward: 11.0 \tLength: 10.0\n",
      "i: 924 \tReward: 43.0 \tLength: 42.0\n",
      "i: 925 \tReward: 36.0 \tLength: 35.0\n",
      "i: 926 \tReward: 15.0 \tLength: 14.0\n",
      "i: 927 \tReward: 32.0 \tLength: 31.0\n",
      "i: 928 \tReward: 24.0 \tLength: 23.0\n",
      "i: 929 \tReward: 28.0 \tLength: 27.0\n",
      "i: 930 \tReward: 12.0 \tLength: 11.0\n",
      "i: 931 \tReward: 46.0 \tLength: 45.0\n",
      "i: 932 \tReward: 14.0 \tLength: 13.0\n",
      "i: 933 \tReward: 10.0 \tLength: 9.0\n",
      "i: 934 \tReward: 22.0 \tLength: 21.0\n",
      "i: 935 \tReward: 24.0 \tLength: 23.0\n",
      "i: 936 \tReward: 15.0 \tLength: 14.0\n",
      "i: 937 \tReward: 11.0 \tLength: 10.0\n",
      "i: 938 \tReward: 22.0 \tLength: 21.0\n",
      "i: 939 \tReward: 12.0 \tLength: 11.0\n",
      "i: 940 \tReward: 79.0 \tLength: 78.0\n",
      "i: 941 \tReward: 12.0 \tLength: 11.0\n",
      "i: 942 \tReward: 23.0 \tLength: 22.0\n",
      "i: 943 \tReward: 35.0 \tLength: 34.0\n",
      "i: 944 \tReward: 24.0 \tLength: 23.0\n",
      "i: 945 \tReward: 38.0 \tLength: 37.0\n",
      "i: 946 \tReward: 28.0 \tLength: 27.0\n",
      "i: 947 \tReward: 30.0 \tLength: 29.0\n",
      "i: 948 \tReward: 21.0 \tLength: 20.0\n",
      "i: 949 \tReward: 27.0 \tLength: 26.0\n",
      "i: 950 \tReward: 21.0 \tLength: 20.0\n",
      "i: 951 \tReward: 22.0 \tLength: 21.0\n",
      "i: 952 \tReward: 9.0 \tLength: 8.0\n",
      "i: 953 \tReward: 19.0 \tLength: 18.0\n",
      "i: 954 \tReward: 15.0 \tLength: 14.0\n",
      "i: 955 \tReward: 12.0 \tLength: 11.0\n",
      "i: 956 \tReward: 13.0 \tLength: 12.0\n",
      "i: 957 \tReward: 16.0 \tLength: 15.0\n",
      "i: 958 \tReward: 12.0 \tLength: 11.0\n",
      "i: 959 \tReward: 87.0 \tLength: 86.0\n",
      "i: 960 \tReward: 22.0 \tLength: 21.0\n",
      "i: 961 \tReward: 9.0 \tLength: 8.0\n",
      "i: 962 \tReward: 16.0 \tLength: 15.0\n",
      "i: 963 \tReward: 14.0 \tLength: 13.0\n",
      "i: 964 \tReward: 30.0 \tLength: 29.0\n",
      "i: 965 \tReward: 30.0 \tLength: 29.0\n",
      "i: 966 \tReward: 15.0 \tLength: 14.0\n",
      "i: 967 \tReward: 36.0 \tLength: 35.0\n",
      "i: 968 \tReward: 14.0 \tLength: 13.0\n",
      "i: 969 \tReward: 18.0 \tLength: 17.0\n",
      "i: 970 \tReward: 18.0 \tLength: 17.0\n",
      "i: 971 \tReward: 29.0 \tLength: 28.0\n",
      "i: 972 \tReward: 12.0 \tLength: 11.0\n",
      "i: 973 \tReward: 9.0 \tLength: 8.0\n",
      "i: 974 \tReward: 11.0 \tLength: 10.0\n",
      "i: 975 \tReward: 18.0 \tLength: 17.0\n",
      "i: 976 \tReward: 18.0 \tLength: 17.0\n",
      "i: 977 \tReward: 17.0 \tLength: 16.0\n",
      "i: 978 \tReward: 38.0 \tLength: 37.0\n",
      "i: 979 \tReward: 17.0 \tLength: 16.0\n",
      "i: 980 \tReward: 16.0 \tLength: 15.0\n",
      "i: 981 \tReward: 12.0 \tLength: 11.0\n",
      "i: 982 \tReward: 21.0 \tLength: 20.0\n",
      "i: 983 \tReward: 16.0 \tLength: 15.0\n",
      "i: 984 \tReward: 32.0 \tLength: 31.0\n",
      "i: 985 \tReward: 17.0 \tLength: 16.0\n",
      "i: 986 \tReward: 19.0 \tLength: 18.0\n",
      "i: 987 \tReward: 13.0 \tLength: 12.0\n",
      "i: 988 \tReward: 42.0 \tLength: 41.0\n",
      "i: 989 \tReward: 11.0 \tLength: 10.0\n",
      "i: 990 \tReward: 10.0 \tLength: 9.0\n",
      "i: 991 \tReward: 15.0 \tLength: 14.0\n",
      "i: 992 \tReward: 40.0 \tLength: 39.0\n",
      "i: 993 \tReward: 43.0 \tLength: 42.0\n",
      "i: 994 \tReward: 17.0 \tLength: 16.0\n",
      "i: 995 \tReward: 19.0 \tLength: 18.0\n",
      "i: 996 \tReward: 27.0 \tLength: 26.0\n",
      "i: 997 \tReward: 13.0 \tLength: 12.0\n",
      "i: 998 \tReward: 14.0 \tLength: 13.0\n",
      "i: 999 \tReward: 18.0 \tLength: 17.0\n",
      "\n",
      "-------------- PRINTING STATS ------------------\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()  #resets the default graph to empty (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard8/tf.reset_default_graph.md)\n",
    "\n",
    "global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "policy_estimator = PolicyEstimator(learning_rate=0.001)\n",
    "value_estimator = ValueEstimator(learning_rate=0.1)\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    print ('Session Oject:',sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Note, due to randomness in the policy the number of episodes you need to learn a good\n",
    "    # TODO: Sometimes the algorithm gets stuck, I'm not sure what exactly is happening there.\n",
    "    num_episodes = 1000 #50\n",
    "    stats = actor_critic(env, policy_estimator, value_estimator, num_episodes, discount_factor=0.95)\n",
    "    sess.close()\n",
    "\n",
    "print ('\\n-------------- PRINTING STATS ------------------' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFRCAYAAADaTrE/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXmYFcXV/789M+zLLAxLBEURcMUlGsQYgSjv8xr9xeTV\nqBFfI1HcEASjUeIWdzEYRRZ3X1Q0blERiLgQAVHEjDsMKquIsg6zwOwzt+v3x73d00t1dXXf7tt9\n75zP8yh3uqurTndXV58+59QphTHGQBAEQRAEQURGXtQCEARBEARBtHdIISMIgiAIgogYUsgIgiAI\ngiAihhQygiAIgiCIiCGFjCAIgiAIImJIISMIgiAIgogYUsgIIocZN24cxowZE3o7iqLgueeeC72d\nqGkv5wlkru8QBJGEFDKCiCHjxo2Doii2/7p37+6pnoceegivvPJKSFIGy2233YbBgwdHLQYAYPz4\n8Rg9enTUYoTCgQceyO1bxv+A7Oo7BJELFEQtAEEQfE4++WS8/PLLpm15ed6+oQoLC4MUicgympub\n0bFjR9O2srIyJBIJAMDWrVsxfPhwvPHGGxg+fLipHPUdgsgsZCEjiJjSsWNH9OvXz/Rfnz599P2j\nR4/GxRdfjKlTp6K0tBQ9e/bEZZddhsbGRr2M1e1UXl6O//7v/0ZRURG6deuGww47DPPmzdP3b9++\nHb///e9RVFSELl26YPTo0fjkk09Mci1duhRHHXUUOnfujKOOOgpLly61yb5z506MGzcOvXv3Ro8e\nPXDSSSfh/fffT/uazJo1C4ceeig6d+6MIUOG4O6770Zra6u+/8ADD8Stt96KyZMno6SkBH379sU1\n11xjKtPQ0IDLLrsMhYWFKC4uxoQJE/CXv/xFt87ddttteOqpp7B8+XLdYvT000/rx+/duxcXXngh\nevTogQEDBuDee+91lXvVqlUYOXIkunTpguLiYowdOxa7du0CAKxfvx6KomDlypWmYz7++GMoioL1\n69cDAGprazF58mT0798fXbt2xbHHHovXXntNL//dd99BURQ8//zzOP3009GtWzfccsstNll69+6t\n96fevXsDAEpKSkz9DLD3He3vWbNmYcCAAejevTvGjx+PlpYWPProoxg4cCCKi4tx2WWXobm52dN9\nIwgCACMIInZcdNFF7NRTTxWWGTVqFOvRowcbP348W7t2LVuwYAHr3bs3mzJlimM9w4YNY+effz4r\nLy9nGzduZG+++SZbuHAhY4wxVVXZ8OHD2dFHH81WrFjBvvrqK3buueeyoqIitnv3bsYYYz/++CPr\n2rUrGzduHCsvL2fvvPMOGzZsGAPA5s2bxxhjrL6+nh122GHsrLPOYmVlZWz9+vXsrrvuYh07dmRr\n1651PJ+//vWv7OCDDxbuP+CAA9hrr73GNm3axP71r3+x/fffn9188816mYEDB7KioiJ27733snXr\n1rGXXnqJFRQUsCeffFIvM2nSJNanTx/2xhtvsG+++YZNnTqV9ezZU2973759bOzYsezEE09k27dv\nZ9u3b2f19fWMMcYAsD59+rDHH3+cbdiwgc2ePZsBYEuWLHGUe/v27axHjx7s/PPPZ1999RVbsWIF\nGzZsGDv55JP1MieeeCK74oorTMddeeWV7MQTT9TvzejRo9moUaPYihUr2MaNG9ljjz3GOnTooLe9\nefNmBoD179+fPffcc2zTpk1s06ZNjnIZj1mxYoVtn7XvXHTRRaxHjx7sD3/4g97fOnXqxE477TR2\n4YUXsrVr17JFixaxzp07s4cfftjTfSMIgjFSyAgihlx00UUsPz+fdevWzfTf//t//08vM2rUKDZw\n4EDW2tqqb3vsscdYp06dWG1trV6P8aXas2dPNnfuXG6bS5YsYQBYeXm5vq2xsZH169eP3X777Ywx\nxm666SZ2wAEHsJaWFr3MwoULTQrZ3LlzWf/+/U1lGGPsl7/8JZs8ebLjOYsUsrq6OtalSxe2ePFi\n0/ZnnnmGFRYW6n8PHDiQ/frXvzaVOe2009jvf/97xhhjtbW1rGPHjiYFjTHGTjjhBFPbl1xyCRs1\napRNDgBs0qRJpm2HHnoomzp1quN53Xzzzax///6sqalJ3/bFF18wAGz58uWMMcYeeeQRVlxcrJdp\nampiJSUl7NFHH2WMMbZ06VLWqVMnVl1dbar7j3/8I/vNb37DGGtTru644w5HWax4Vch69+5tOo/T\nTz+d9erVizU2NurbzjzzTHb22WczxuTvG0EQjFEMGUHElBNOOAHPPPOMaVvXrl1Nfw8fPhz5+fn6\n3yeddBKampqwceNGHHXUUbY6r7vuOowfPx5PP/00Ro8ejTPPPBM//elPASTdmb169cLhhx+ul+/U\nqRNOOOEElJeXAwDWrl2L4cOHo6Cgbej4xS9+YWqjrKwMO3bsQFFRkWl7U1MTunTp4uUS6JSXl6Oh\noQFnn322HnQOAIlEAo2Njdi9e7fufjvmmGNMx+63337YvHkzAGDDhg1obm7GiBEjTGVOPPFELFy4\nUEoWXv07d+4Uyj5ixAhTLNfRRx+NwsJClJeXY+TIkTjvvPMwZcoULFq0CGeddRYWLVqEuro6nHfe\neQCS17S5uRn9+/c31d3c3IwhQ4aYtlljwYLksMMOM51Hv379cMghh6BTp06mbV9//TUAb/eNINo7\npJARREzp0qVL4LMOb7nlFlxwwQV466238N577+Gee+7B9ddfj7vuuiuwNlRVxWGHHYbXX3/dts+q\nUHqpEwBeeeUVDB061La/pKRE/20NYlcURT/euM0vMvV7pbi4GL/+9a/x7LPP4qyzzsKzzz6LM888\nU1dqVVVFYWEhysrKXOXp1q1bWrKI6NChg+lvRVG427Tr4eW+EUR7hxQygshitBlzmpVs5cqV6NSp\nEw4++GDHYwYNGoQJEyZgwoQJmDZtGqZPn4677roLRxxxBPbs2YO1a9fqVrKmpiZ8/PHHmDBhAgDg\n8MMPx7x580xtfvjhh6b6jz/+eDz77LPo2bOnaRJCOhxxxBHo3LkzNm3ahNNPP913PYMHD0bHjh3x\n0UcfmSyBq1atMpXr2LGjPhMxXY444gjMnTvXNOPxyy+/RE1NDY488ki93EUXXYSzzjoL3377Ld58\n801TwP7xxx+P6upqNDY2mo6JO0HdN4JoD5BCRhAxpbm5GTt27LBt79u3r27h2bNnD6666ipMnjwZ\nmzZtwi233ILLL7+cayWpra3FDTfcgLPPPhsHHXQQqqur8dZbb+mKySmnnILhw4dj7NixmDNnDgoL\nC3HnnXeisbERV155JQDgyiuvxAMPPIDLLrsM1113HbZt24abbrrJ1M4FF1yABx98EGeccQbuvvtu\nDB06FDt37sR7772Hww47DL/97W+F5/zFF1+YtuXl5eGoo47CjTfeiBtvvBGKomDMmDFobW3F6tWr\n8fnnn+O+++6TuqbdunXD5Zdfjptvvhl9+/bF0KFD8cwzz+Drr782uc4OOuggvPLKKygvL0ffvn3R\no0cPk1vOCxMnTsRDDz2EcePG4cYbb0R1dTUmTJiAk08+GSeffLJe7rTTTkNxcTF+//vfo7i4GKed\ndpq+75RTTsGYMWNw1lln4W9/+xuOOuooVFVVYeXKlejcuTMuvfRSX7KFTffu3QO5bwTRHiCFjCBi\nyooVK/CTn/zEtn337t0oLS0FAPzud79Djx498Itf/ALNzc0477zzMG3aNG59BQUFqKqqwiWXXILt\n27ejZ8+e+OUvf4n7778fQNLVNH/+fFxzzTU444wz0NTUhOHDh+Pdd9/V2+vfvz8WLlyIKVOm4Jhj\njsGQIUMwc+ZMnHrqqXo7nTt3xvLly3HzzTfjj3/8ox4nNHz4cJOSwWPr1q049thjTds6deqExsZG\n3HLLLfjJT36C2bNn49prr0WXLl0wdOhQjBs3TvqaAsB9992HxsZGjB07Fnl5eRg7dizGjRuHf//7\n33qZSy65BEuXLsXPf/5z7N27F3PnzvXcjkbfvn3xzjvv4Prrr8fPfvYzdOrUCaeffjpmzJhhKldQ\nUICxY8dixowZmDJliilOT1EULFiwALfffjuuueYa/PjjjygpKcExxxyD66+/3pdcmSKo+0YQuY7C\nGGNRC0EQhHdGjx6NwYMH48knn4xalKznlFNOQXFxMV599dWoRSEIop1CFjKCINoVq1evxmeffYYT\nTzwRzc3NmDdvHpYuXYrFixdHLRpBEO0YUsgIgmhXKIqCRx55BFdffTVUVcWhhx6K119/3dWdShAE\nESbksiQIgiAIgogYWsuSIAiCIAgiYkghIwiCIAiCiBhSyAiCIAiCICImK4P6t23bFmr9paWlqKio\nCLUNwjt0X+IH3ZN4QvclftA9iSeZuC/77befVDmykBEEQRAEQUQMKWQEQRAEQRARQwoZQRAEQRBE\nxJBCRhAEQRAEETGkkBEEQRAEQUQMKWQEQRAEQRARQwoZQRAEQRBExJBCRhAEQRAEETGkkBEEQRAE\nQUQMKWQEQRAEYYFV7QH7cUvUYhDtiKxcOokgCIIgwkS9/o8AgPwnFkQsCdFeIAsZQRAEQRBExJBC\nRhAEQRAEETGkkBEEQRAEQUQMKWQEQRAEQRARQwoZQRAEQRBExJBCRhAEQRAEETGkkBEEQRAEQUQM\nKWQEQRAE0U5hlbuRmDoerGJn1KK0e0ghIwiCIIh2CvtoKbBnF9iKd6IWpd1DChlBEARBEETEkEJG\nEARBEO0VxqKWgEhBChlBEARBEETEkEJGEARBEAQRMaSQEQRBEES7R4lagHYPKWQEQRAE0e6hWLKo\nIYWMIAiCIAgiYkghIwiCIAiCiBhSyAiCIAiCICKGFDKCIAiCaPdQUH/UkEJGEARBEAQRMaSQEQRB\nEARBRAwpZARBEAQRMg3L3gJb+3nUYnDIjnQXbMPXUN9/K2oxQqUgagEIgiAIItfZ+9AdAID8JxZE\nLEl2ot53Q/LHyNOiFSREyEJGEARBEO0WCuaPC6SQEQRBEES7JTtclu0BUsgIgiAIgiAihhQygiAI\ngiCIiCGFjCAIgiDaOxRKFjmkkBEEQRAEQUQMKWQEQRAEQRARQwoZQRAEQRBExJBCRhAEQRAEETGk\nkBEEQRAEQUQMKWQEQRAE0V6hvLCxgRQygiAIgiCIiMnY4uKLFi3Ce++9B0VRsP/++2PChAmorq7G\njBkzsG/fPgwaNAiTJk1CQQGtd04QBEEQRPsiIxayyspKLF68GNOmTcPf//53qKqKlStX4rnnnsMZ\nZ5yBWbNmoVu3bnjvvfcyIQ5BEARBEEYUygwbNRlzWaqqiubmZiQSCTQ3N6OoqAjl5eUYMWIEAGD0\n6NEoKyvLlDgEQRAEQWgwCiaLmoz4B0tKSvDrX/8aV155JTp27Iijjz4agwYNQteuXZGfn6+Xqays\nzIQ4BEEQBEEQsSIjClltbS3KysowZ84cdO3aFQ888AC++OIL6eOXLFmCJUuWAACmTZuG0tLSsEQF\nABQUFITeBuEdui/xg+5JPKH7kj47U/8GdR2Dri8oart2RR2Arl27oXvMZDMS1vWL07OSEYVs9erV\n6NOnD3r27AkAOOGEE/Dtt9+ivr4eiUQC+fn5qKysRElJCff4MWPGYMyYMfrfFRUVocpbWloaehuE\nd+i+xA+6J/GE7ktwBH0d43Zf1Pp6AEB9Qz0aYyYbj6CvXyaelf3220+qXEZiyEpLS7F+/Xo0NTWB\nMYbVq1djwIABOOKII7Bq1SoAwLJly3D88cdnQhyCIAiCIIhYkREL2ZAhQzBixAjccMMNyM/Px4EH\nHogxY8bgpz/9KWbMmIEXX3wRBx10EE455ZRMiEMQBEEQBBErMpb069xzz8W5555r2ta3b1/ce++9\nmRKBIAiCIAgillCmfoIgCIKIOaypCYkrzgL79MOAK4423QXb/gMSl54Jtn1rpHLEAVLICIIgCCLu\nVO0GEq1QX38uakkChZWtSP77nxURSxI9pJARBEEQRHuFMvTHBlLICIIgCKK9Qhn6YwMpZARBEASR\nLZAClbOQQkYQBEEEBkskwHZtj1oMgsg6SCEjCIIgAoO9/izUmy4H27MralFyk9BiviiWLGpIISMI\ngiACg32zOvljb020guQq5LLMWUghIwiCyHLYxm/AaqqiFoMgiDTIWKZ+giAIIhzUadcDPQqR/8C8\nqEUhwobSVOQsZCEjCILIBfaRi7BdQC7LnIUUMoIgCIKIPWQZy3VIISMIgiCI2BOWZYwsbnGBFDKC\nIAiCIIiIIYWMIAiCIGIPuSxzHVLICIIgCKK9Q/pe5JBCRhAEQRDtnSwJJWM5PMuUFDKCIAiCILID\nUsgIgiAIgshZyGUZOaSQEQRBEASRJZCFjCAIgiAIIlpyVx8jhYwgCIIgnMjlIHIAOa3gZBukkBEE\nQRCEE7FTyOImT4aJ3f0IDlLICIIgCILIEkghIwiCIIh2SNwUgHY+HTJutyNASCEjCIIgiKwhYI2k\nnet3cYIUMoIgiCwm54POoyYul1cJSXOKy/lJk3UCS0MKGUEQRDZDCln7gO5zkhy+DqSQEQRBxBR1\nxTtgtXtdSuXuCyoW5LACQMQLUsgIgiBiCNu+FezZ2VCf/HvUohCxIGzFMEuCyXJYPyaFjCAIIo60\nNCf/3VstLpfDL6h4EJMLHBMxoid3LwQpZARBENkMudQIIicghYwgCCKrIYUsVGJzeWMjSLTk8AcI\nKWQEQRBxRPa9k7vvJ8JIDisi3sjd61AgU6i1tRXLli3Dd999h8bGRtO+iRMnhiIYQRBE+yb14nHN\nP5W7L6h4QNc3VuTw7ZBSyGbPno0tW7bguOOOQ2FhYdgyEQRBEDouChlZTtoHod1m6j9xQUoh+/LL\nLzF79mx069YtbHkIgiAIIj7ERuGNixwRE5v7ETxSMWSlpaVoaWkJWxaCIAjfJK44C+q8OVGLkXly\n9/1E8MhhhUSO3D1/RwvZmjVr9N8jR47E9OnT8atf/QpFRUWmckceeWR40hEEQciSaAV7/23gwqui\nliTD5O4LKhbE5fKGrYiFtVYmIY2jQvbII4/Ytr3wwgumvxVFwezZs4OXiiAIor0j+wJu9xaTsInL\n9ZWd5OG3+ricpwtZIqYfHBWyOXPaoemfIAgibtAsS8JItihOoZG75y8VQ/a3v/2Nu/3+++8PVBiC\nIAjCI7n7fooHcVGAQl/KMktclnG5HyEgpZCVl5d72k4QBEFkiBx+QRFEe0KY9uKll14CkEwMq/3W\n2LlzJ3r37h2eZARBEAQROTFReEnxTpLDl0GokO3ZswcAoKqq/lujtLQU5557bniSEQRBEBLE9Q0V\nV7mylZCuZ9YpetkmrzxChWzChAkAgKFDh2LMmDEZEYggCIIArWUZF7Lk+rKvyoD+B0LpRZ6rbEUq\nU/+wYcOwc+dO2/YOHTqgqKgIeXm0RjlBEEQ0xFRjyDrLS8xxuZzqrDuBbj2QP+P5zMgTFTncr6QU\nsquvvtpxX15eHo477jiMHz/eljSWIAiCCJm4vqDiKpdXAjgPFsi1kKijbp//6rNkkmVsP0ACQEoh\nu/zyy1FeXo5zzjkHpaWlqKiowKuvvoqhQ4fi8MMPx/PPP4+nnnoK1157rWMddXV1ePTRR7F161Yo\nioIrr7wS++23Hx588EHs3r0bvXv3xjXXXIPu3bsHdnIEQRA5T+6+n2IF27webMt65I0+3cfBWXCT\nskDEXEfK1/jyyy/j8ssvR79+/VBQUIB+/fph/PjxePXVV9G/f39MmDABa9euFdYxd+5cHHPMMZgx\nYwamT5+O/v37Y/78+Rg2bBhmzpyJYcOGYf78+YGcFEEQRPuB3qThkry+6j3Xgj3/aIRi0H0GkNPd\nXUohY4xh9+7dpm0VFRVQVRUA0LlzZyQSCcfj6+vr8fXXX+OUU04BABQUFKBbt24oKyvDqFGjAACj\nRo1CWVmZr5MgCIJot8T1RR1XuSIhgGtBlzNJDvcrKZfl6aefjjvuuAOjR49Gr169UFlZiaVLl+L0\n05Om288++wxDhw51PH7Xrl3o2bMnHn74YWzZsgWDBg3CuHHjUFNTg+LiYgBAUVERampqAjglgkgf\n9T/vA6s/Rd4l10QtCtFuyfYXT7bLnyJHTiN3yN0bIqWQ/eY3v8HAgQPx0UcfYfPmzSgqKsKVV16J\nY445BgAwfPhwDB8+3PH4RCKBzZs34+KLL8aQIUMwd+5cm3tSURQoDks3LFmyBEuWLAEATJs2DaWl\npVIn55eCgoLQ2yC8k8n7svOJ5LJgpTfcnZH2spU4PSvaPPC4yJMuLZW7UAmgoEMH9BKcU6IgDxWp\n39q5R3lf9hQUoBVAYWEROmbxvdD6U69eJcjr3jOt/sUSrdiVxvFAW3/Iz8vj1uFXvtquXVEHoGu3\nbugewf2q7ZZqv2tXYfva+ZWUlCC/JDg54zSGSSlkAHDMMcfoCphXevXqhV69emHIkCEAgBEjRmD+\n/PkoLCxEVVUViouLUVVVhZ49e3KPHzNmjCkPWkVFBbdcUGgTF4h4EcV9oX4gJo7PStzk8QurqQaQ\nXClFdE6spkr/rZWL8r4kWlsBADXV1VBy4F7s2bMHSmOz/ref68pS18Tv8QDAqpP3OaGqwjq81q/W\n1wMA6uvr0BjB/VLrtPbrpdqv3FMJRQ1uSmgmnpX99ttPqpyUQtba2oply5bhu+++Q2Njo2nfxIkT\nXY8vKipCr169sG3bNuy3335YvXo1BgwYgAEDBmD58uX47W9/i+XLl+NnP/uZlNAEQYhJ/HUilIGD\nkXfxlEDqU//1MtjCF5H/6GuB1EcESFxjauIql1ey4DyCSauRJeTwuUopZLNnz8aWLVtw3HHHobCw\n0FdDF198MWbOnInW1lb06dMHEyZMAGMMDz74IN577z097QVBEAGw7Xuwbd8DASlkbP5zgdQTFu3q\nhWSjPZ97thBEUL+gjnbd/3MHKYXsyy+/xOzZs9GtWzffDR144IGYNm2abfutt97qu06CIORgrS0A\nFCgF0lEK2QVTo5YgOmL7Lo6tYN7IUE7XmDcQI3L3XKXSXpSWlqKlpSVsWQiCCAn1qnOg3nBx1GKE\nRy6O0bJWj7haR2IqVk7Snq51Dp+r1OfyyJEjMX36dPzqV7+yLY905JFHhiIYQRABoqrA3uqopQiP\nXLSQaYqWw+xzIlPExEQWlssyhxWcbENKIXvrrbcAAC+88IJpu6IomD17dvBSEQQRC9j2rUBpv6jF\ncKddv1TievJxlSsCQl/Lsj1d69w9VymFbM6cOWHLQRBEzGD7aqDeehWUn58atSgS5OAgLe2yDFcM\n38TVleqVbDiPLBAxMLLhfvhEKoYMSKa++Prrr7Fy5UoAQGNjoy0FBkEQOURDHQCArS+PWBAJ1Fwc\npGXPKabnnsMvTs+E7vUMooEscY3ncL+SUsi+//57TJ48GY899hgeeeQRAMDatWv13wRBhAtb8ynY\nvr1RixF5egm25jOwfbwl1nJwkJbWx3Lw3GNFTK6vxxgytq4crGInp7BjJd5lIgJFSiF74okncN55\n52HGjBkoSE2bP/zww/HNN9+EKhxBEABrboL60O1QH7otwy1zvpgjfPmz1laoD90G9YFbODtzOKg/\nqHJEhIR8jzjVq9P/AvUvl4bbLhEoUgrZDz/8gJNPPtm0rXPnzmhubnY4giCIwFBTysaOHzLcMO8l\nEuHLX1M8eNchJ3WSLJ9lmSuKYiDuxmwI6s+SfpYr/YqDlELWu3dvbNq0ybRtw4YN6NcvC2ZfEUSu\nEIeBKAYicInDtQmaHDyl9gbbVwP1Xy8jmLQXon1tO9UPl4Bt3Zx+e0TGkZpled5552HatGn4r//6\nL7S2tuL111/Hu+++i8svvzxs+QgiUhhjUKK2UOjtx+ANHVfFJ65ypUW2uyzjKpdHLNfXy5igPjML\n+PI/UPY/KDR5rNvY0zN9XvlsuV/ZIqd3pCxkxx13HG688Ubs3bsXhx9+OHbv3o3rrrsORx99dNjy\nEUS0xOFlp8mQaVG47UV5PUTXIQb3KWik+15Mzz2mYqWNlzGhKZWJoLU1iIYFu9K52Fl2o7JMXC9I\nL2x30EEHYfz48frfqqripZdewnnnnReKYET7g7W2Qn3yfuT9+nwo/QdGLU6SOChkuiISA1ki1ccE\njedi2gvKQxYTrOcR0XkJV24I2SUaJ3KmX9mRzkNmJZFI4LXXXgtSFqK98+N3wKcrof7fjKglaSMO\nDz+z/cgMXK9MlEH9vnfmNnHoo7lMIPpYgPeI67IMrnoiOnwrZAQRHnEaXWIgS1QvXO4kyxi4LLm7\nYnCfgkZ6Lcu4nntc5UoTP30t9JmaIa+VGSuyRU7vkEJGxIgYTruOw7MfVQyZhlEhiKvLMmteJl7I\ndpdl1AIEhK1veTgxl36pPnof1Efv8y6Tx3YkKwmgjgyQJWL6QRhDtmbNGsd9rYEEKRIEhzi9XGOR\ncJRZ/o0SspBlDOlTysFzjzNBeh8//TCgioKphogWoULmtjRSaWlpoMIQ7ZwYZXfQiYMsuoUsw8K4\nTK/POJIxZExVoeTlgPE/65XMbJdfIw0LWZApa8JyWUZtgfdM1gjqGaFCNmfOnEzJQRCIpcsyDg9/\nnAxkccjUz8Mwy1KddSfyJ/81AwKFTZbnIYurXOniK4YsZJdirl5rHjl8rjnwGUnkHjF64MhlaSZS\nESQtBGs+DV2SjJDlachyhgBmWYavQwSRh4w6UtSQQkbEB828H6cvoDiIEtn1yCKXZZz6TGAEq5Gx\nvdVgdbX+xfFKLt4SAEEG9QfWbM5eaw45fK7SiWEJInRi6bGMwdMfeQyZ8cZQUH/GkE4MK1dOvfYP\nQH4+8h99PQ2hvJAr98RyHpGloQmp/+sGsmy5X9kip3fIQkYQIuIwSMXpBUBpLzJHGLMsEwk/kvgj\nF+8JAH8PQdjXoh0F9edsv/KgkO3btw/vv/8+3njjDQBAZWUl9uzZE5pgRPiwr8rAYpW+JIYuy1iM\nUlEpZNIbMwO5LNMqRvjE2re8XO9AwzBEHyQBVE9EjpRCtnbtWkyZMgUrVqzAq6++CgDYsWMHnnji\niVCFI8JmFyFEAAAgAElEQVSDffMV1Fl3gr3xfNSitOGakTwC4vCijyyEjDOhIdIYspQ8cVvSKSzi\n0PfSItvldyCqWZahfZBkW1B/tsjpHSmF7Omnn8aUKVNw0003IT8/HwAwePBgbNy4MVThiPBg+2qS\nP3bviFYQHnF6EcVBllgF9WdeCqnGc3Fx8axPexG1AAERYqZ+XwSdHzDb7lO2yesBKYVs9+7dGDZs\nmGlbQUEBEpmMRyDaAdllIWPVlVCXvZkJITLQBgdNyVH8B/Wzpkaob78GpgYwVgibzsFRWp9TkZ1r\nWapLFoDFVVlMhzh9IEntk60+B+9VliGlkA0YMABffPGFadvq1atxwAEHhCIUkQmSgzyL6WAeH5yv\nj/rwPWDPPwq2Z1fIIsToBeBRFvb6PLB/Pg32SQBLxIiCj3OxG0vPspQoEkWs6Lo1wKZvM99u2EQ9\nyYanoAfisswSclhxlEp7ceGFF+K+++7Dsccei+bmZjz++OP49NNP8ec//zls+QgiWkTPfu3e5L9h\nW4ojewFIb3SmoT75b3NTutKI245FAt+A4aYd4RZ0r6ulOV1p/NHaEk27QZJOUL9THekQuMuSYsji\ngpSFbOjQoZg+fTr2339//PKXv0SfPn1wzz33YPDgwWHLR7QrYvigcV707IfNUF96KnOKEqcd9Y3n\nwTasDbldXlC/oPjuHVCfe9jsngzSC621nWiF+s+5ZneYLVVUDPuSZwKMIQtEIfaBmoOKsshqvuhF\nsG/XtG0IdC3L9KuItP6gyBY5fSCdGLakpAS/+c1vwpSFyCCKkurXcercUSVAFcERRZ1+I1BfB3Tt\nlnl5UrBFL4Etegn5TywIsRHeNsHL6Mm/A5u+hTLil8Dgw0KQp61t9vbrUH77v0BBB22LuWxLM9Cx\nU/AyZJIAXZaRKWQ5Ybm0afvOJd/4BxjQ9lwGOpaF5LKM0XDb3nFUyGbNmgVFIg3BxIkTAxWIyBBx\nTDERx+nXvIEukXrJ5OVHJ0NmGpbcZiHwGBentg3tWF/8OaCQBXrbo3JZtjMLWWaaDzqIMoYfwkKy\nRU7vOLos+/Xrh759+6Jv377o2rUrysrKoKoqSkpKoKoqysrK0LVr10zKSuQ6cXzOeIOU5pLLlFJr\nkYFl6iWncvJ+eb5HctdIff05JObcLS5ka9vZZYnmiBSQQNEsIpLlRESlkGXNS15AGlkv0jrGVoco\nXiCA+rOFXOhTDjhayM455xz99913342pU6fisMPa3BDffPONniSWyGZi1LljuYSHQCHLlDvGOgC5\nTCIINX5Kpm4f7bM3X5Yp5dyO9V4EkWYjaoJcyzIqBTUX88NFlRg2rLVcsy6oP3eRCupft24dhgwZ\nYto2ePBgrFu3LhShiEwQ42WK4iQT10KWevlz83SFIoSlfRdlI6jrF4RrJMhrY5vtJrCQxakP+SVI\nhawlFUOW6VCFXIghSycxbJBB/UJyoL/LksOnKqWQHXTQQXjhhRfQnPrKam5uxosvvogDDzwwTNmI\n9kYcHzSZKeZhv/yt1Sfcckp5kyfx95uRmHgepxreuUtUGNZLX3jdM3xPsg3NQqZPgsgQuRhD5qVr\nBZruwue+IOqPFVkjqGekZllOmDABM2fOxEUXXYTu3bujtrYWBx98MK6++uqw5SPaFTE0nQsH1EzJ\n6c1l6Vmsb75yqMenhSzoPEky7VhdY7mgkAVpIdPjATNtIcuB+xCEsh92DFk6DeTEPcoNpBSyPn36\n4K677kJFRQWqqqpQXFyM0tLSsGUjwiRTlnQvZHBgYI0NgJqA0rW7W0nBrgy5LD3GkPm9jqypCWht\nhtKth7bFW92865Apl2UgkdfBwhgDqiuhFPfyW0OA5SK6HhIuS9ZYD6gMSoRpZLwR7rVklRVAcS+p\nLAdtB2VPDBmrrwXy8qF07uKzguif7bCQclkCQG1tLcrLy7FmzRqUl5ejtrY2TLmI9og+LoT/wKnX\nXQR18liJghIKWeguSweFLM/h8fUpj3rbRKhTLuDUo3C2eSUEn4rJQqYKi0YB+/dCqNf/EezHLT4r\nSP3r9mKW0scyFe9obdZdOHXKBVAnn58BaXwSiK4vdxD7bj3UGy4GW/GOtzpCt8AFhzp5LNQbLjY2\n7K2C9q6QrVu3DpMmTcK7776LLVu2YMmSJZg0aRIF9RMBk8EHralRsmDIg6CUCA5B/U4KmV/BKnaK\n240aL4H7MZCdaa7g3dt9VhBk/FFE10MmhizspccCx8e1lIylY9t/SP5YX+6x2XTubwR9o76O03z0\nz2zUSLksn376aYwfPx4nnXSSvm3lypWYO3cu7r333tCEI9KH7doGKHlQevez7InOZ8n27AJamqH0\nG2DZEcMHUhi2kamAZauFLBXUrwRrIZOqJ+R7xNQEFKeEu6LZbpmeaJEJeC9lHg7nylpbgY1fQzlk\nWIS5hXMhqD+IGLIMW9E9HWv5l4gMKQvZ9u3bceKJJ5q2jRgxAjt27AhFKCI41JuugHrjZVGLYUKd\nOh7qLRPsO+K4dJLU1KZMz7LUVgpwUsiCatdnUD+3LslyQmuJ1VIoUMiy/O3CdvwA9sG7sqX5W19/\nFur9N4F9tz46xSgnZ1lGpZDF2yLsH4/jflafqxgphaxfv35YuXKladtHH32Evn37hiIU0c6J0wMn\niiHT9oUtri2GLGUhC9plKVOPVNWGQl5jlloFKT1sbWeLhcxH3Fadhxhdh1PVY9dq90Z3PWJ1H3wi\n2beE8XJBKMShuegjNpF5TgieA33KASmX5bhx4zBt2jQsXrwYpaWl2L17N7Zv346pU6eGLR8RFkoM\nE8PGSRYdCQuZh8GWqQmwZYuhjPxvKNI5oRyC+kN3WYZYtxMihczmOjJcd9tLMzCJosGTIuukkflv\nnjEGtuIdKMefZJuJrK5aBuWQYXKzR3PRQuZ4vQXnGnp/DGKWJRE1UgrZIYccglmzZuGzzz5DVVUV\njjvuOPz0pz9F9+5uKQOI2BLLtcVjODDIfJV6EJt98C7YC48DDfVQzjjXnwxuQf2BKWS83FV+XZaS\nx4mS3gqVLoGyFhXp3AfTNXebZenUjj5N0/v1+G492Lw5YGs/R/4VbR/erLEB7KkHwH6yP/LvmONe\nTxyfaa/IesMl400ZY95SWujHiXZ6rs5jAyHiNag/B7qUE1IKGQB0794dI0eODFMWor0Tx8FbJJPu\nzvQgd0ND8t+6ff5l0IP6HQb1UC1kMgd6UCasCBUy698CC1kuj9pW3O63oni/HFpm/73V5u2axauq\nQq6enLCQSbrDQ5/1G5JGFvmjQjFkGo4K2d13342bbroJAHDrrbc6avS33357OJIR7RC5B41t/wFs\n1VIov/1fW79U338LSkkfKEf+NCCR3GViSxYAJ4yCMvRI9/p0VzGnHjUB9spcKP/1GyglvQ072n6q\ni14EOnZO/uE0GzHMGDLfSUglZfLksjT+zjGXZRAmbNNanx4vSDrNp9NuVuDDRGb9eAg6H1wI15mt\n+QyscjfyRv53evVUVoC9Ox/KOX90nkGdIdjeKrBFL0M59xIoBdL2qIzhKNGoUaP036ecckpGhCEy\nSRxjyLR/xTKpM24FKiug/PIMoKjEXMW8h8EA5D+xIGChnPex998Ge/9tuTZ1hYxjOdjwDdiSBWBb\nNyP/uru5MrA3/tG2OexZlqIJDbJ4fe8Ig/q9xJBluWUmyPe1AsP1CahiWYUiS+8DEymVjvqYjDVd\nVIGrUIJ9/qo0HWypX33otuSPNBUydd5sYM1nUI76GXDY0ZzmvXoa/J+sOu9h4IuPkx/sR/3Mdz1h\n4aiQ/eIXv9B/jx49OhOyEO2eIKwoARO0G0L0HnNy1zm1E8ksS78vE8lywoXTvcSQSbYXV4JYNsek\nhHl86bkVk11CK04ffF7wE7AlO1b4vSTZupalVr/juO0xFjcdcbVQkU6d06gkPKRsdh988AEOPPBA\nDBgwANu2bcNjjz2GvLw8jB8/Hv3795duTFVVTJ06FSUlJZg6dSp27dqFGTNmYN++fRg0aBAmTZqE\nghiaEYkMkeE11aQIfLASWCa1bVZFy0kGHzFkiRsvQ951d5tdok7wrBteL4eLYqEufBGorjQI6DOG\nzGbNC6cPqWUfgC17E/l/vse9cFrLFQUwy1KvSgmwH3usp13FkHmoI2iCuL9hKWb5qXe68GPLC97l\nVB+fDgw6BGhMxfD6XUczZKTykL300kv6jMpnn30WBx98MA477DA8+eSTnhp78803TQrcc889hzPO\nOAOzZs1Ct27d8N5773mqjwiAOH3B+pi1GDqB62OpR4533VXerEaHsoC/WZa7d4Ct/LdYRr0e6Y2+\nYQv+Afb+W20bPLksBW6gkPo1e/xvwLo1odRtwjQvwudally3m6Si51TM63XNUpelOB7MabvgXIVJ\njAMgTuO4lfxU3JhT0mfJUJV0YGUrwF56sk0hc0oZFDFSUu3duxdFRUVobm7Gt99+i/PPPx+/+93v\n8N1330k3tGfPHnz22Wc49dRTASR99OXl5RgxYgSApFu0rKzM+xkQPonxAyxLJhZKDvqFoq9YxY3q\nT/5rU7QCVMgE1UnV43vQlDzOk8tSFOeT7f07AJelXlWAFjKvcYXZaiEThnylGdQfduoY3/WGU7+S\nspAx15AMWXd6GnJqCllM339SClnPnj2xY8cOfPHFFzj44IPRoUMHtLS0eGro6aefxv/+b9usuH37\n9qFr167IT2nPJSUlqKysFFVBBEkQAdtBE8Olk9TXnkXi0jODq1BXInkWMs3FZXVZOtUVcgyZ36WT\nTEUoU78vAkkMG0QguWRbTjgoZGzLBiQuPRPs+42+xIoUPy5Ll/6YuPMa//JI1C9XR/pVcHGzkHkl\nnXNtqE+/jhCRCtg6++yzccMNNyAvLw/XXJPsOKtXr8bAgQOlGvn0009RWFiIQYMGobxccsFcA0uW\nLMGSJUsAANOmTUNpaannOrxQUFAQehuZYmfqX+v5NPbogRoAHTt2QHGGz9VJpqaePVENIC9P4V5/\n7b7szsuDiqQSn2/JFu5Ut6wM1v34drWt3E57cak2AaC+W3fsA9C5c2f0tN6T7t2S96RzZ9M9ad7V\nE1Wcugo6dEAvTpuJfAValihNJqPMXbt1Q3fB+WjHNPbojhoA+QUF0IbSosIidDAca3xWKjt0RAuA\nwsJCdExt29u5MxoAdO/WHV05slrb7tmtKzo5XMeWmgoYP9mKi4pRkCrb1CPZdzSMMgSJJm+vXr1c\nk3tWdeyIZiQ/aJ3OyYmWfVX6uXbo0AElguObehbq567di4KCguSHM4DCoiK01tZgHwBF4T9bVpp3\nFaGK03aiIA8VLvXsyc+HplZ37dLZ1Nc0at95DXUAuqwvR51F9jjAWluxK/W7qKgQHUpL9XtfVGR+\nBjTUun3Ynfrd9kwk70HXLl3azrNXLygdOgIw9P/vN6K0tBQNPbpjL4BOnTqh0NJGQ/fkvry8PNu1\nat5dyB0jjLI4UdOpExphH5Nkx1I3arp1RyOAHl06o4vhOmr17uvSBfUAunTugh6CtrTj/Dzb+nVu\nTRqSinr21O9hnN73UgrZ6NGj9cXFO3XqBAAYMmQIpkyZItXIt99+i08++QSff/45mpub0dDQgKef\nfhr19fVIJBLIz89HZWUlSkpKuMePGTMGY8aM0f+uqJBMSuiT0tLS0NvINNbzYXv3AgCam1siO1eb\nTDU1AJKTP7R9rLUVaG6C0rWbfl/U1Fd3ZWUllAT/S4d3Tqy5CWCAkurDTuVk6/NTRq1LDsuNDQ1o\ntp1/8rXa3NJqqotVW5JzpmhVGf88DUHyvP319XVoFMiqX/tUH0kYrFbVVVVQerQda3xWEi3JZKI1\nO3cAxX2gdOgAtbERAFBbuw/1Etdnb2UlFIdyrMr8yqmq3AOlYzI4V7t2GjXV1Y71BEHF7t1QHFzG\nrLEeyO8ANZVcde/efZ5lMd7zlhbxM6o9N0DbvSstLUWLdj9q9oLVJmeXMcbvM/b2a7hta32LOfQ9\nwNxf6vfVcvuamkqQXF9Xp28LaxxijQ1AfgGUDrJLlaXGnRTVVdWmPl9dVQWlO+e5M6w/2vZMJBUA\n63lqCpmRiooKqPuSdTQ1Ndmuh7oveQ+N46PetsMYYZTFCTXlxmtstI9JMse7oaau5b7qatQZ6tLq\nVeuTVquGhno0SbRVU1OT9rNdXVWl15GJ9/1+++0nVU56SmNra6u+dFJxcTGOPfZY6aWTxo4di7Fj\nxwIAysvLsXDhQlx99dV44IEHsGrVKpx00klYtmwZjj/+eFlxiHSJY7AtJ6ifzZ0B9p/3zTm+fLo2\n1cnnA62tAeYo84FoDVHVIYYsyKB+D+i5mDwunaTOvB3oPxD5t83y7LFkiVbnQ4QTKa0uy5D7t+Aa\nq5N+DwwcDPQsCqV+TmFxHaY8ZJ4FkWvLiLG/qE5uKoHrPmDUSecB/QYg/86HPRzlZ8KIbAxZCMTU\nBQcgXi7LIOsIAakYsjVr1uCqq67C4sWLsWHDBrz11luYOHEiVq9enVbjF1xwARYtWoRJkyahtraW\nEtBmkLY4yug6JrPFl9iDO9l/3k/+y41Z9Ch7APnLWLrXS6CQadfDZnkJMO2FJ7hB/ZLH/rgluDad\nGhelvQi7W7td4y0bgqvfdZalREyTUTlLh6CC+jO9lu6OH7yVF56mw07RtQli9YKwlmYK+13gmvbC\n6wd27ipkUhayp556Cpdddhl+/vOf69s++ugjPPXUU5gxY4anBo844ggcccQRAIC+ffvi3nvv9XQ8\nERTBdUjW2gps3QzloCHeDlQTZisPT6SOHZPr6jXU2fdl8JnSFwRu9TaZxYboReQ1D5nfxLDpzLK0\nHMyamsC+3wjlgIPFioN0mwJLgjBjeoaD+kMf0D3U71iUSZRxwPFeelXIXCxk8XwvmrEZCX1YyFT3\ne8E2fuPtg0R6nwth92XXtBd2z0joxFQhk7KQVVVV6ekpNIYPH45qgd+aiDkBTkdn/5wL9Z5rwbZv\nTVMGzkPSKZXAT5sdYyqeQber1pbH2cV2JFyWsjPswl46SSLtxd4590C98xow6yLUOh5NIbJWBsB8\n/6VfmkERcv2eLFEuLksG78+Ka/Z/SRwtZJlzWfrDhzVKaMFyv/7qtOvBlr3pWs5z29J1pF8FFzcL\nGbP9EBOEnHEM2YGkQjZy5Ei89dZbpm3vvPMORo4cGYpQRCZJv3ezLamp6/v2ejvQ+vXMewl16Zr8\ntz5aC5kuW2tzevUEGUPmSGAameumlnWpWdN6fh8PdaVVzlLWNsDGSGHy5Z7zYiFzK8u81Wes01q3\n1w85t/IxtVSIkw47HuSvPiPbBB+1QgNZOtcxYguZV3I4hkzKZbl582a8++67WLBggZ4vrKamBkOG\nDMFf//pXvdztt98emqBEwMQh55eThcwoU+eUQsZzWWZSI6uqAPtxC7D/oPTqESpkqQFLNjFs6DFk\n/I3sy/8ABxwMxZRyxKOMjm16sEwYlCLbYWleA7ZzG1C5GwpvMeRkibTqdxcgAAuZhqradYrN6wEF\nUA50CDNIx4JglN3JZRl3A5kBtnMbYJhB6Sh0EDFkTKS0hHSxvFqovOIhhox9vwloaYZy8KG+m2Or\nPwH2OwBKrz6CQvHseFIK2amnnqpn2CdyhRh0yIRl0OcpiZ0FLssMZgFX75sK1FQi7w4vM7U4iBQy\nPVN/vqVxn9aNdGEcFypjUGffBZT0Rv59TxnOJyCZhPfUpnU570vzGqg3XwEAzjNyZepPK9A6YCuA\nRcFS77kWgOD8nO6DV0XN+ozrxFwjM166d+abXfK+ZllKWshkxrRAV9AIuA4esjFkANQ7k6m0xDPh\nxXKqM+8AunRF/swXBVXEs99J5yEjcow4ZOq3fQ1yZEopZIxrIcsgNancXmnL4SNTv1QmduftXmeG\n6hMYeIdpdVWmUmCKFEzj/iAQWcGsL7I4BfX7uQaeZlm61WW3kHlq34g+bggqNCnwLjFkMX0xms6v\ntcU8mcdXpn5JRdb3TMoYuyw1glpcXEZc3ge8qY4sjCH7v//7P9Pf1sW/77///uAlIkKDfVUG9ulK\n7S/TP5Fgs5DZiyidRTFkETxU9bXuZUSILEq6hcy6uLhDXbJf6l5fekzw0rV+5erKI0MguQw8zbIM\n6wUlgZdr6kfpCKJ+bbvqHEPGPl0J9f9mgNVa4j8d74NHy2BQcUNRkkjInYds3xVdQpGFjJsXUKJO\nN0L/eEn963YNM6mcx8EgwUGokC1fvtz097x580x/p5uHjMgs6qw7oT46LflHHPqjk1XD+GBqWfWb\nGjnlwhPNRkrxYHVpKmQavMFbn2WZroXMdYML2oucI6NVbpPBLwAFSThQChQyq1xh9w1PClPI9bub\nyAzWV/PLXH3hMbCP3gM2r5Nrv73MsrTGwZlm9PqxkMnGkPl0hYeozKSde1G7dm6Li2cyD1lM+51Q\nIUv7RhDxJQ4mW1vAL89Elhq4efm/Mtk/81OPSrouS5EyqVvIJGdZOsb5WBUXaelS9QoOsH3lSr5Y\nZb9IhS8rQVnRvlAIUmFK8xg3CyozWMis1yW1tJVowoTUdiOeXJbu1UWOzUImaZk27YpTf3Q41FHR\nTPNdodUbQGJuU31R1xECQoXMbfFcIosRuaWcDvn6SyRm3sHJsO8Tm4XM9sPwMEetkKXCLdO1kOmD\nG0d2x7QXnhux/GmvQF2yAIm7rwWr4C2VLvhitSrR2hihurks0/v6ZaoKddYdlo0Cq0PYfcOLy8PP\nCy1ICxlj7vXZrl8aLktRvV73R4bF+mocq3iPxePTwT5fJajOeD19nrOXjxVvFYt3p+ve0+R2DeqX\n/WhL/fP5KqiPT7dUFYQlPjqEQf2JRAJr1qzR/1ZV1fY30X5Q59wDNDUk3YdafrC0KpSwkGl9rIWX\n/8tcPlSLrqaQ8WLZvCAyzzsqZB5nvNlzQNiLvPkKsK+Gv8SRSEYt7k9TxGQ/2tIdKBsbzG5ra50S\n5xwsMvWn4VoPMobMqJDZ7pdWRnJShIxyKeWei7vL0vA7oZrHKs45sbIVQNkKQX0Ca24ghGg1Sntc\ndehjtv3ealUfvif547I/G6qSVeriqbsIFbLCwkI88sgj+t/du3c3/d2zZ8/wJCPCxU+H1MfQgEYU\nxxgy08bkP7wM+bb1C0N8yLSp2+kG9csoZLIxZE7KixerBO+rVShjqrzTi92KyYImgRfLjCiVQJxm\nWYYd1C9Tl1Tgv3G7k7LvsekcyEMGNWEZq3wIHYhFJiSXqJuFKl3DS+DWqCCuQzw7nlAhmzNnTqbk\nIDKNW9wAj6Bd2BZlgPFk0h5mk4XMYQAJ0wydUshYJhQyWZel7EuTd7yuKAkUMs6B+ldp6ng9rMFl\n0GavPQP1+43Iu/x6YTmAgTXWQ716LPIuvx7KcT93Pgdh2gsg8deJUA4airxxV7u06QPO/Utc+wco\nJ54iVdZP/bb2rvgfKP/zB6Ckt7gOYwyZvRC/Pad+KvPRY8lb51omjog+WnxZPINwWfrclybqxHOQ\nN/EWKEf/zGcNgjHPuFt22SjRsyGrPMbUZSm1dBKRg6T1BR5QZ5ZZ7iYlJ5OJIcsKl2XynBnXPetg\nffLsSpDQyLRZo14tZG0VpP7RgrPdB0L2yQeuZaAyoGoPwFSoLz7uUqHoS1kFtn0P9uES9zb9wGt7\nbzXY26/xCvtpwKV5BiQSYP+c614/YwJrKr895mZ9lZ0p6Prii+eL0SSXyzglFSrBceMGG2IRhMvS\neZf67vz065Uer9KAMw5xr3NMYxdJIePAEgkwbsxS/GAtLfyXquuBfjpkwMkcbV+eHMuMaFFvP1/v\nftEVsqAsZJx9WnyWbZ9HhcxNUU0k2pQ/bt+ReOlqOqOrhczH0knava6uNGzn1W9/yXH3hYGHZ0BT\nblhTk3z9boqMTBoG030U9xWbAsZ7sTU1+Vg1wmWWZUwtFSYcxynt7wxl15dVgr0Suns/9REa2Pjs\n8Trw2o1pDBkpZBxqHrwN6oTfRS2GFOqEs6E+eKuPI308hNq7NbRZlhxlRfvNU5AzaiHTYsiCCurn\nXEM9T4/1vFzqsu8Q//nmy8mAfoDvslQ598GGYv7XMd+UqA4eDGhu5GwWuHh5+8N+z3uyijCwzz6C\nOvEcsC0bZRsQ7zYqMq6KORNYKRz6o6Uca6yHOvEcqG88l9wgcjka9wWlqPvEtxXKeJj1GbHWKaNU\ncoP6vcoWkkImU0c6LmatWr8xr0716YeLrJn28n6azBSkkHFo+vDfUYvgjW99JOiVcktZkYsXksYp\n4NeI9oBJuSwzYCGzzvTzishCpl0P28tRdjalVg8zFBFYR4xtmis2t8sbjLXVBAJX0llbbizTdpf6\nM9kXeO25lGVrPk3+3LJe8hi3/TJWGa0oaysvq9xr11vbXrsv+W/55/zyTnW5XidrXw0Y33UajnNa\nc1f/26uFLPVbdjFyGcK2kKVVv6r/y3cf8g7x4PUxXn/eNSULGREmrKUFbPsPaVaSzrEhW8h424wu\nS6cvTJ/uD/bDd+651TQLWVODrzbaGpPIQyZr+JOZkSiaYQfwF392m3UFAC2tYDt+dF+T0LMRQHWw\nkInk5LTv+DHOwLZu9igUt6bk/1ua3Z9F4z2wzaB1OsalP4qsgxYZTRYyJ+up7EeAV9wy9XtQ3tj2\nrWC80AXhQUFYjlxiXaUsZLz7lZ5lyMNOl2p9yuOhheQ/LmOREVEYjshC6TZOiLbFAFLIshD2/CNQ\nb50AprmdfFXiY8DNC9lCxhmo9LgDGZeljwGFbdkA9farwRb/U1xQU8ia04wtVA2DkxVtEJI9Lykl\nyIeFTKtX+AWvQr3lyra4KMc+4f1Ln3EtZC6DqswEEQDsP+9DvWMy2Gcruful0WKvPvw31Dun8GNO\njW7CdNwysnExDjIm742Ta9LBcqYrkGnGjTrGkHELO1ezrwbqrVeB/ePRYNp3PU7U9320we2/gvJc\nFz6OcjcAACAASURBVKEHmfwQlo5iHPO411UwFnIRfLG6jRP6NrKQEQHB1qWS87qtaC+uJfWPl6fQ\nbXD2+ER7sZDxlt0IIoasYlfy0C0bxOUC+6KSUI5kz0tGCXLRx4R5yGTupxb3pib4L1k/rhc/FjKr\nS9up3W3fJ3enbWFO1V+3L/mxILTcGG6CdCJdFwuY17xYri5Ly/W1uiy9TBySSXvB6yyiD4C6pMuU\nrV8rL4ew/TRwcu+KD+L89iubpFKTTnWBYvgYkLVWCS1k1r9V/m9R/fE0kJFCJiL+a3lG9BA6rqHo\nsR6bu4yjJOouSwkLmQ+XJXNMxmrBz0xWboMSFjJZn6XMdleXpSjthfNhOqmXL/viY28yOsEYP06P\nu9C5oW6LQuT32WW7toNt/EaiIAP7+kugsiL599dfOpdVmePi3oIGxLtdlvIxV6WarXW8Ztw+ApwW\nhua2x3l+rXAtb6J+6pCjzw3BmMC2bgb7YbPDTlGlPj4EeUH9bi7aTz80W15l4/Y8k66CKFn9xm+A\nndvkjvESQyZw37P1a/WPbvOOeFrIhIlh2z2q2uaqiiNpPYN+MvW75JzyWqfNZcmr04NC5uecUjK4\nrtvq5YUkbE+gkHm1kMm4Mv0E9esKmXY9RdcmpZC9twgoKRXLIvMsMbVNISvoYN5uL9z2U9ZC5oJ6\n0+VyBRmD+sAtbcc9Ok1UuE0eaQuZuS1e+8L9xu3MWMZmXkj+42attvV/yevr9mKVjSFjqXq8KmTM\nuX31jskAgPwnFvAOFNRp/VvGZSlpudF2bfgabNUyKKNPh3LBFZZ27X0o1rYD7fo01EO9baLcMcLx\nVjA+Wu6F+repDlXE84KRhUxETLXoQLJch2Ih82oNcbKQceo0uiydrEx+HjLdQuZyTYOKmxP1KUfr\nmcN5SU0jZ+J7na6FzFiIm2fLsD9PRiFzqId3rsZtVoXdVUmR6yuOljYvfc2oFIcR1O+mmBtdRbLn\nY22fFzLghIzLkqcgiq6p0yoWboSS58x93LH2G8ZTPEXn25gMR2EVO9zbd9wmicdnwnv9ku0b4U02\ncirvNsuSR0zX4SaFTERMb1owBPAAy26XrccwSKvvvA5WudvT4uLGB5N99lFbrJ1QBkmFLBMuSyfr\nmdNlrd7Dd7kEZSGT6SNus/2M22Repkxtm8nqmvzUaCGzKAyGY9WFL3qbRm+qJ52+brifustStl3H\nP5K4uCzVmipg+1bDfpePGLePGy8KmVfrnVtZwOCy9Oix8KtkeHEP8t4TVXugLv6nWSluq8DyLwft\nPBMJqP96GWxvtbh8OspUCHqY+uG/wb7flKrfY8oaIA0XueQ7O6YWMnJZioi7QpZOp/Lz5eiYld3f\nFxZTmfn9pB3f1Aj2ylywj5cDhSXJbbwH1HoOhr/VR+4FwHdHmL5WpS1kQStkgtw4Hix/6u2THVwu\n2rHi48WzLL32/yAUMtbmflQ598lU1rDNqrAbFGi24B9AvwFQfvaLtvss7Tp0sk56uDZ+LGRuliOX\ntRH3PnKfuaxbsl+3eEy/LntXa7rky1Trp15DSHx7OUTKj3sb6pP3A+vXAl26psrw7qGgee1Z2fg1\n2Ndfgm38Bsrhx6R2cvpuEApGgDoKe/ohMDi5gyUQfAAzZrkCbuMEvxY/UoUOWchE5JBCZne9+FCi\nwo4hs9LYYFJSHM9B/9P5XByzOUemkPHacFDIfKSOMB0rOlyYh0yiKVcLmeG3jDJitCYZE0m6ZeC2\nznK0KhAJj/mrjPLw8JS4kvn6WGn7g9e++LqzxgbLfherjJvLMiyFjLmcp7UezzFk/Ep9LTfXdrT5\nT97HrTYDXrMs8s5T1Ce089TS7JgmugStTISsnLi+R3kmXi9pL2Ry8lnrJ4Us+4ipWbMtY754UOHG\nLTj97QXbA6Ypah7rcZVJES8RI/Glyj2W90Xl6rL0rpyrb70KdaVl1QdBYti2++Vynq5IuIy03R+8\na9+YaIX6+HTgxy0STXmwYslayHjT2N3qtgb129YfdG/aSR62+lOoLz9l3u5JQTcoZA7XQF21LOni\nMh7D/a0dwO+P7KuyVDsGS5JRIWQMiZT12HygQ1A/L4bTDakYMpf7qW1KJKA+Pr3NNe9ZIXN4bhtc\nlkAT9Rc35RWwexO4Y7FIIbNYAhWFW56tWwN13sNgLzwuENiFlDyssR7qo/eBVe3xXxe/Ac+72duv\nOZdXVSSMk2hkXOS2BuL5bieXpYi4W8jcvloDV8jcsrJ7tZC5JPNUFP7L2fFvkZvBwUImG0Pmw0LG\nXn0m+ePnp9rlECkYMgO+CJsSK7guvMXSt24CK1vR9rfo0hhldXtpy86yNCnMLPnZ6GJ9s2Vwt8WU\n+dbIoM68Pfnz3EvaNnuxsKgMbQsr8y8me+qB5I9fpdbQ9RKbZ/itzroz6SbKd1DIAOCzj8T1AelZ\nyGRiergxZJxyP2xO9kWtP3qNIXMaw91yOAr7i9VCxlPIUopjgmMhk2mDd548vXz6jc51eKX8M7BE\nAkxNIH9CgPX6ePTYR0uBi6/h76yvAz41JHZ2y0PGbSCe73aykIkQTJmOBa5frTIKmReXZerfwGZZ\nuliCrEqS29R8YayUw0wc7cWa6TxkomnwaSvPlvue7n2RbYv30jbFkEnOsvRlIbPEkNkUaJ8KmZNr\nw7OFLPlLyQtghjTg+rGo5Bu+tWX6gFNiWG23FwuZoB6TTMkfzjLw8KyQOZy3m4VMhM0yL9G3eDF/\nouOCmEnvle49k//u+DHYev0E9Yuw9imRF8WxTW9NZgpSyETE1M+s46YkmL4+meGnwWri6WFwWTrJ\n84PltHSS1pzioEjJKy7qvDmpffyvKPbSk6m2PMrqF5FCZnFvqIv/icRtk3y0Yahy8vlAtTcXhPrY\n3zwU9jDYys6y5LmXee4s4+12tZC5N+0oDw8vLuzN6wF9qaY0JxNoiJJhrvkUTR8vt+x3q8/lWbIq\n26LqvKS9cI0hs1yvNGPI2JaNSFx6JtgP37Vt270jtW2zsaRrnYwxJP50Idjyxe5y8GICRdfQOt4o\nShpWXjts6+bkOVfsbKtXu8eBK2RpFzBjuTZs2ZtIXPuH1D7D2C70mJCFLPuIq8tSG/CscTNWnEy5\njPl7QbkG9adrieG5LEVf0O6uPfb+28kfJsWOJ3+mgvpV87+mfeaXFHvt2WQcVzoWMgDs6688Hi+s\nzrLPzfLiVSEzuvfQZqXmunw8xJD518j4m2X6g3YfrXGEokO02aJucTGCWZbqopeshSX6kIsbLvC0\nF3IxZLbHMs0YMk15Yv9emNyQX6CvMsE+lL1Pho+EfTVg78y3F7FZuHi+WXelj1tfAHoZW/FO8t8v\ny9o26hMQAn7vBV2fVSFb/E9gb3VSAZN1X8Y0howUMhEx1aJ1/MaQqaq/c3N1WXqsU8ZlabRm2VyW\nLvU57eOVcxvofQT1c9G+lN1ccOYd3toIerBJZ2Az7pedZcmzkLkunWRNexHwygqw9D+/H2tuz4jm\nShP0V8aY+aXkdrtVGZelRwuZsaiaAGtt5Vsk3JZZczhP27OuEVQesh+Ta5qiqEQsn6hOL2OC1xgy\nrsIfkhLhYeIGU1X+fU6rfY/lRR4a2RQYMX23k0ImIrYWstS/Lg+QOun3bX9YBz4Zs7lTw45fvV7q\ngntQv3WTW1C/yMXMS3VhJFNpL7QT4rosHfaJritPkczg15/74MyzDAgrtLh3JCyKgHvaizSC+nVM\nCpm//uB6veo5Cpm1jhefgHqnIeDZZk2x9gkJi7hXl6Xx0Mv/B+qVZ4G9+ARHWJePN45Cxip2Qr38\nt1A/Woq0XZa2eKPU39r5+Am/0MMORAtgCyyOMvG72hqppjpT/4YVXubyEcPqa6Fe/luwdzkWQWM5\n0bnzj3AVzVSnU6iOag13EClkrk1GAilkImKqRetPpJsVwLjf1lENZnevpGEhc8wHBthfCkqeRZHS\nZIb5X5n2TQOiD5dlUEqOaDB3SokhOi/ubCwXV7BXZC2Pbvtlg59595zb5wz1uaa98HkNTM+NoU6/\nkzzcXk767D+Bhey9ReI6rBMHrNeUh9PHjhfriRYeYNro9PHG7Pu139uS1iv2n/dh7btKumkvPCsL\nnCq1Kvz2AX0M8NAnA3ZZcivT5OLNhmYM2Lc3+XP5Wy5VSnxou6El1LXKBjgrwraxgyxkuUVcLWQp\nPM18ssbliBa5RvIr1Va/SwyZlClb+MBYFTKLfExNpjfQZ0i5fNU77XONyQkRGRccgyXhqqC+1haw\nXdvMiUCD/vxLJzjWs0Jmca+JYshMa1m6WMj84vTFHfRSTJpVi+eydK+UX5fDbim5rAqTzFjzkwH2\nbW4WKJ7lSJef2eVK12VpU8gSpnNl9bXuyxTpVm4vqU/SdEFW7DTVwfbsAnOLIZbF1cKaoiA1c9et\nL9isrR7bB4CG+tR94NXv0KdUVSJWOEVNNRgv5U/EkEImIqaBfzqecgMZfqusbQPnHFldLdS/XAr2\nwmP8utKZZWnyYLkMlkqeaRtTVbBnZhrk8GBJcntQvXztSi9/w0GUxkGfZamap+W7KD3qTVdAve8G\nQ3n/4nnG7StfdL+55S0vYcEsS7OFzHnpJOm2neTRZTG8EP3GFDrJ0blz8t+GBns5Vyuk5W+r+906\nc5Vbh4O1WtvuMNYYP8KUn+zvXm/bgal2EvZteqwqsz8n+WkuLm4bc8z1q9eNg3rtH1z0MZHV1uUY\n0zb5w7FrO9j855K/mxqgTh0PNu9hDxWIsCq9TtdY0jPjFlri0ryGqs2ctBYSWsgEHhhj0SVvQL32\nIrFcEUAKmYiYW8g8KRHW2Sc8l4FGY9JtwtZ8Zt6uuMWQebSQuZm2rbMsVRVs9SfO5R3FYu6mbC9f\nu15fClyhBEH9DG1LpgBy/dAwjT/4oP50LGSSs54OGgr0LEopZJx75RbUb/1qt700/CpkhnaNSphv\nC5nDNUgp+brVIy0LmVUhE7TrUIXNZen0EjbW26mzvX0nhV1X9IzXUSurtP1tve9puCxN6X40Eqp5\nfVPr5BBunTIWMoEiKBp7RWjXIrWMElvzqbfjjYhiZp2usXYtrdZoK14tZF4RWch44Q5OBGVhDBBS\nyESkbjyr2we2bk3EwhjQ0160DZKspcWirFgwWpq++E/bQGiNT6neA2xeJ24/nVmWoqBL3vMjshRY\np7RvWc9vs7nZ1d3EvizTs70zt7xdDgMW++JjsNUug6SMgsFU82Dh4eXPWlrsA3W6CppQIfNQj2iA\nLClts4jyEj26zVKzfpwElsjX8Nt4H7x8rMnk5dLivr78T1Ip82Qhc1PIVPf7tGubKTeXzQrk5KZa\nV972mzemOMmeuseMd001+St3g31neabTcVmqqr0POt5HiY6d7ixL3x8JmiXRX3Q/+2Ez2O4dqT9U\nwPrh7XSN9b7grMiwDV8De6ssG9MP6jcVcbru1vsb98TuHGjpJBGpDqg+dDuweR3yHnkVSkGHiIUy\nYPhqZa89A7ZkAfL+Mh3KoEPsZY0K2dMPcbcDgHrzlZaFbA245SGTCVIVKlgc07nxy9yWSNbyp5MJ\nv6lB/PIGgIY6sNeegXLeeKg3T+DXo8vFH7DUOXcnd9/6EJT9D+IfK3J3GGLITF/qHpQL9uITYO+7\nBN16RagQeFAW3BQLzSLKOMqzVwtZGIlhjffBi4XMaOl1UgA0C1nZCqC4FOjdzyiEi4yc9qz7Xa49\nW7UMbNWy5LJLAMdCxncBq3+/uW2bfk0k3Eu82cZWl+WOH+0zN/1alYDUOVkHDSf3l+gjRMJCJhzb\nmOmfTKPePrlNkg+W2As4WcisM1R5Re67oS3jv94IvyxjDIpswlsZV6Qt3CHmHi4OZCETod34rZuS\n/waViyoojAqZll25bh+/rKOb0XJOTsqYkXS+KoUPDOd4m7VEwtpgpalRKiCb7dmVKt/A3a/j9pUu\nMoXLxJCBmd0CXhQyra+aNkof7lSr8x6XQY/JuiyBpJWIqZyXqMOxzGBlsVpL3VaBkMX0HnVQztww\nxhw6BvW39Wu2a7u5YVfZZSxkHs/faK0FuC9h2yQe3jVxC2/guSyF+r/HMdiWEFvWQiasNPmPqA/Y\nXMDMvs/vRCJd5gDyX/AC5x1dluLzZtr22r2WHWnEHPMQpr2QDOqPKaSQibDlsAneBMoYg7rkDTAn\nRUqE31mWZgFEB5n/1AZ6l6B+tvoTsI3fuLdnC/60lM3LM220J4b1oJDxrC4WlA4d5epzWyS7Yyfn\nfZrIbmtZ+nRZotGuTLK1n8sfz0PGWuC4X66sAgWAAlsSU31WKt/lo368HPhhi31XUJn6HZQw9sG7\n8nUY35uOLkvrzEgP8lqfI9ssSwbP52+dDSyRyFhXgj24LM2pRFSob78OVi9YZ5IjB9uzC+oy/vJF\nzLiQujVPVapN/oHubnq2gpPmQ8OWqF/SDe+FIPKR5cs6yZi7giPzMW+tkwd3fJWwunqZZRlTyGUp\nwvolEoJChk3fgr30FNi35ci/6kZvx/JMx46LIbt8qUqhpA5h/LFAc/HOvAMA2twfTu3ZZOLIIhzc\nJWVvbACMrmanQbiDpDvaLbCYMbv1QN9ncQUZMa5l6dNlyR0Uv0lz6SQRXqw3Mi5LWFyWIguZysCe\n/Du/FwSVGJY5vAjc4iyNx5osZGKXJbddN9Gt/cNmIeNYhtxwc1kC9udI77+ceuwN2Opln38E9vo8\noKiXQC77eahP3A9s/AbsqOOhlPQ2F1/8T5MszPYR6M96yBrq+UsmOR4ThnIQgEbGG/McP7hdxqFm\nB4VMpJTncfbn5+v9QndrSslnuZdZqJCRhUyE7WsqoNxGpjo1M2+N/2ONtDQ5FPajkDk88Ol0dJEL\nixecLHA1MtnEig31cqZsWQuZW9oL65eaEVH8SUpGZg3qT1chS5d0Eix6iSHLy7MrD3rwN99C5ojV\neux7qSNDG35DFkyzDp0UMk7cFwAMPhzC8+TVyVtH0W/slf4vpw86ZcF32wbwn4Om1NhldXmZ6uOc\nh3avUwllnY91mNzgWVlnwD6HHFnGtkx/m7RUn+1a8BnUb4IXE+30Qek23jbyxx6bEty2R2/PhDEk\nRF9f07CfXJbtE/WlJ8G+32iY1RiChSzPxQ3IgzPLEqmZdazJQSFzevi3fQ/13Te8teu2HIoIoxhu\n06NtaS+YZRAyujOd7436yL2GDOhwtnQG5bJUE+4zUUVLATH4iiFj5Z+Ho5CJcOu3Fhc1a6iHOvch\nvltKsbss2b9SC2XLKARGrB9P6WZVB8DW+5xpLTPLkhf3BSSV1B++4ywYbsB6bt+sNv8ts5alVvSZ\nWWDVlW3l9+wC276V7wK23hO9jIzLMnV+69caymrxaqLYLM4975W0irGP34f6j0ed4xqdXLfcjyMX\nl6VT0lIN6wfBD5vbDv/kw+S/0ouZOyCpjwkTdhdwnGQ81y5guvbqghfs+x0tZA6bl7+dDDmwYlTI\ndE+BINRFF0q1jTfZBilkIrZsgHo/bxZRgGidz482z7PYOQWkC+pnLz8l157b4uJSsyyNFjKXOB9N\nIdMsUiKLWovAetnSDGZ88J0GfFmFzHUhcoFCJrVYNgMzuix5/a5rN3vVM/4aTm6dtGLIzC9n9u58\nsJX/BluywPyiUFIxZJagfla2wrkd0bla77HfIH+jQvb8o3LHCOpwfEmY+pRBcUgpauyN553rt56b\ndQzwYIlhH7ybHA+M+bvWlfM/eKzbuDFkXiYAaR8kgrGQ99xo12jVUrClbwJ1DhnYVcYfozyPvUxC\nIROkhkjdS/bmyx7btSKtkRl+csZYW3kHhcz4XC7kKGQOFjLHlV1efDwVcmBoq2cRlN9e0Pa3NeEz\n4Dx+M8v99bI0VUwghcwC92tC67NB5TYy1Z2GhYyrkHm0kHnCJTGs13wyblm0tbxUqUSswqB+N0VE\nS1oJmF8kAwe3/ZaNIXOzkDFVoLwLFDLdPcTcg/r79jfLHioBDWwqa3P75XGmu+cJ+hdvmyhBpU0h\nk3Cv8UjnueG55WRfElo5mUSoIleqFpfnVekwfgipKmfsU+x18sZHL6t6yAwfvOOs1lbHVBYJh7hb\nnozijxDHZX00wghv8Y1xnJSwHFtdf8btIjxayHj78y75E5SeRW0btA9tmdgwVTXf+yzMQ0YKmRXb\njCXD7zAsZIJZTExVkbjlSiTm3IPErVfZByPeLEsfFrJkW17WZfMzY1NvyLm8k5lcmwkkspD5VciM\nX4iyM47c0l4kZGLIRLPWmLvL0i1bdpBUVvg/1nSerG2QtCyLpW9zcpfwrpdolvGWDZbjLdYbHxYy\n3yTsfZ7t2YXElAvAdm5zaMdsIQOSz2jipis4Moqe3aQbmHlVqhnT3VnsH48CtoTHjJObTGT1tcBT\nTCXHD3XFO0jcOaVtmzEcAXBUUNnCF/npOxb8g1NYIMIzs4Aajy7LMKjcLVfOeC7WcZI3tjQ3QX3s\nb5x6fM6y9OI6zM83x+hqngKT0VU0y1JCcYsxpJBZsQXIGi5RKEH92hcA74XTAuz4EfhiFbB9q3k5\nHSd5HC1kLp2zocE1p5RzDJmmZMgM+h4eGC3IW3frMucUAm4KmbEt44AtE3BtkyuNGDKRy9K44Lub\ny5J374MI8g2Lgw81uyPz8s33T3M7MZZSwtuusW3pKw2ZZW40bEHqmbCQceIFtYkb/3kfqNvXlj7D\n1I7S9pgY72ldHbBrm70d0cs/T5u56lF2VTXHF8lYlniZ+t2WTjJvlJKLPTsb+H5T2zabQuaw7uay\nxfIufbfxcueP4v1xspCZQjsk3iEA8MXH9m2W+201EDDf8atGE5llXOC5LEWzQGmWZY5h/brSYlt4\n+wJpTzITOWA3CfMG4oY6sGaOUubWORvq5F9wbgHrwmMF8SVOrqo8mRgyl4HWScExBVzLKmQSsywd\n3SaioH5tn8Vlyet31uV1tOPiBmPAgUOgDDkCpsWi8zgWMi3vnMrMbmGnWate4uUShmsLyN/rdAKD\nRa5Xa6iCzR1vUFw1nF6ewr6fisvznFCVuVuMbTFklmsMtCmgUtYvSbn0n6nfDRaXpZow7zdiHDNF\ns6Vdxnrbkk6idqLGOGvS2ldkw3AYx+1tPVZTyAz9hjlZvK11a+TlmfuqHhss47K0fLiRQsanoqIC\nt99+O6655hr86U9/wptvvgkAqK2txZ133omrr74ad955J2prHYIxM4l1kDG+sB0GxMQV/4NEatkc\nz4gUMus2S9JPxnmY2IdLoF51jn09RrcHr6HefYae4+LihsWA3RB9wfACTo0KmSizv9vL2RSTla6F\nTEIhc1PeRQr4V2XJ4GQNY7/T2m5thXezRwQwNXmNtXupnff276FOONtcVp9lqdqnvnsN6rfJkUBi\n6niwd15P/q2qSNz1JySmjnc5Tr4J+7EC16thokpi2vVAlcUtzLGQqX8ex29HdB2UlLXNs4UswZ+B\nZyojEUMGgH3yAdTLfgNWWQG29nMkLj0TjJeiwu9auBYLGVv+FhKXnslPTWFUlKyxoKYUJy59S1sL\n0okYLVytXvO/UB++J/mHVS7ZUJX1a83LZAHOCplxfEwk3BWyz1e1/c7PNynS6j3X2ss7BvWrZiWc\nFDI++fn5uPDCC/Hggw/i7rvvxttvv40ffvgB8+fPx7BhwzBz5kwMGzYM8+d7SLQXFtYOm5dnCKJ3\n6AiJBN/EK4OukEnMYtIsX6Kgfg1r3I/bg9dQJz+ICL5QXL+ERXmpnBSy1BdX0qXqkELASfbDj7Hv\nt1jI8u5NrZcnawFNJ+2FwYpgu1bGvw3xIVrMRN6f7kTen+9NbuRZyDKFVSHNz4dy4in8srpikWdy\nWbJveSkkNGuOxTqTaPFnITO9GFRAWxoLSLaxZYN5G1f+kC1kjAG8VS2MaS/cEFm2FX8WMlZXC3Qv\nFBdymmVpLbbwxeSPqgqo/16U/G1cyFxvVEYwY+hBa/IZspw/07L2/8hR+oxjpkjhTDdG08uzOeDA\n9Npyo6mh7f1kc1kaYjpl6dwldazD+rEmxdbhY8qJvHx3b5HTey8HMvVnRCErLi7GoEGDAABdunRB\n//79UVlZibKyMowaNQoAMGrUKJSVlWVCHDHWDmuyoKQf1M+qLJYrh8WTWUsLUFNlLmu1YFVXOjdk\nLevWOeudFTK2twqstdXmZmHVe8CMMS2MAbUuS0AJv2B4CpkhnkikwDjIrhxwcLKo4VqaLYsKlNK+\nSQVAdlaOjIWM01dYfR2Y0b3i5KayoimKhxwJFKeymEepkB16tPnvQYcAPxngUJilLGRIyitSNIw5\n+Wxf2fZrw/a4BDV3MCxh5XKtWdUeh4+JdGLI+AoZa6hvCz9wuodWxU3UjEh50D5qrOOOCEVJpnUo\nKhE0CrkYMqAtYWt+fptliTejWSrkwfjCdfjw0dLX8HLdySpkbrMo04Q1tln1lJ/+PNS29DbVhF3R\n1JSoAQOl61GOGp784Zj2xHKPvAb1u816dfoQs84O3ecj2XrEZHzppF27dmHz5s0YPHgwampqUFxc\nDAAoKipCTU0MLqD1ZgcY1M82rIV631Qol/wJeSNGm+u0dFr1kXuB1Z+YK7AqWdaZZEascWQuyiRr\nrIfCiXtgiQTUay+CoslrkFX9y6XJB7q/9jAzqH/6X2E7ME+XcdwFoG0mnu6yFOSScnopaYOucU07\n43XU3nd5efJfVG4vSYdBSJ18vmWDao+Vcqov2XDbOplBxKjkF/jr01YLoZIHdO5q2fb/2zvzMCuK\ne+9/q882+z4sw76qoGxCMMZRCESDohKIiDuKehUU90iMW6ImXBVFAwaS12A0uTeXGPXGvEnMiwaX\nEBMEIYqKqKCgIAwzwCzMck7X+0d3dVdXVy/nzHIGrM/z8DCnTy91urZf/bbiNECE2HWp+whkfJQl\nn0Hcy2QpbgnFbbkCAIjH7ahjL38nGP5A+gO3gFx6nfsZ7cll5BE1rC+cw90/YBEQRnMRYLKks6zI\n5gAAIABJREFUr77kHX3txaEDIH0G+IujfNmjMa7Ne1yVSgE1Xxp/S/ZcDYVDU5ICiKT9mm2HNklc\nYPhxQvSR401lzMTXSejfm2d/CKMF7Qjq9kuiLNuM/hkUqMQTM9+baDFin/njyWR6axotAtKjt/8l\nXmMf1R39VV+xOI0Hdw+6VCBrbm7GkiVLMHfuXOTlOQdwQoh7zyqTNWvWYM2aNQCAxYsXo6KiotPK\nmGw8CH4tqUUjoEQDBVCUX4CE5NnmEBNYrqa3alAPIGfXdhRVfBcAcDg/D4dgqCr5678UhTEAhYk4\ncioqsD8aRdA0WhCPgt+ApLigEHWeZwOFubmIFuSD17lpmoaKkmLsBUDf+juifQcgCSA/Nxf5FRX4\n0uwYWlsrdPM4PwTK3kcq1QpmTE0kEijmzmnIzQW/po3HYkgSAhKPIwUgomkgmmZ11oL8fOSZ17fk\n5UG2ps0rLLLvGU8ArS3IPVADtj6NxRMoq6jA3kgUufE4CisqrPr0IqZF4GfQKMzPR7SoyGpHFRUV\noJRCNI5VlJWCcOk49hECXiSLDhyK5I6PEI9E0AqgorIStLAA+wAg2YZoJBLYDnyJZiaQJXJzwYv7\nsXgcuaWljvYGQlBRUYG6aBSUUsQL8tEIIBGLoRmGGwM/nMcTCaRiUWixGFIaAcw6B4CyokI0C21L\nSiTqmAy0RA50c5WcE4+DFwFychLW54JDdTgEIPHZRxC9KEuKi+Gjh/ZFVj95Oc42npNIQBRNEok4\nomZfSOTkwGszNEacAF5GS6JphkYuDeLxOFrqDyK3Zy94XkkISoqKrHdD4nFrDKsR6pZRnJuDOmaB\nSCZdAjRfJ17EInbfKy8uBmIxiHpSLZEwxiNQq83Ejj0BbR+8A9LUYI0fWjzu6G9iG+kMSGExaP1B\nRyBCflGxb9uO9B0IvbZGLmCmQWleLlLNuc5xsq0NiEQRjQXPKYycgiIcBlBWXIwIN37XJ+Ku9lJW\nkI9Dsahn+3SVsaIC0d5jkFz23zi07CdI7duNiooK6E2NVj1HQaVlLS4sRKqpHj4bb7moqKhANBrt\nVJkiHbpMIEsmk1iyZAmqq6sxceJEAEBxcTHq6upQWlqKuro6FBUVSa+dOnUqpk6dan2uqWlHXqQA\naI2ze+vctiOH6mpBzGfT1hbg048dGdODyqWbQQvNzYfRap6r1xndQ08mA68/tG8vGmpqkAqxhVP9\nu5sdnw9se9///IMHrN9mlVdPoeZLJp5QJM3nNjY04DB3rr53t3WcZ9/rL4McZ5u3KKWgf/+b9bml\nqcnxm3XBxNDa0myaq4zPqbY2h1mpoaEeTaw+auUmmaYWeyggo78Gum0Lmrh30Wa+d0oImt7+F5r3\n7HbfpKDIsb9eW0Dww6EDB0D229N4TU2N1LxWs28vCKdZ0oWVX6qyN7DjI7Sa2oT9+/fbOXgoRbK9\nWrJ0VsUcLUL7a0smkWwShmJdx75tW6G3tgKpFJKHjd/Q0mjUcUowbbe2tICmdEOzm0w6NEO1+/aB\nBpnCAVPjYYsvOvf7moW21dxol7e+3rh3S4t72jjg0a7CkOS1Mbl5QEszmhqFcjS5RYCWvXvQapqp\nW0P4MrX6CFyZ6PdaDtQByTYcjia8T6IUB7g2TiNRpNraUOMzPh14X/Ab1JwC2eEN/0AQbZzmf/++\nfVJ/TlbvjTX2EijZqx/wwTsO4VQXtJ9iG+kMaFV/YKtza6tGrwz3JqlY3HBVaKdAVrdvr9vNxbRA\nJP12OhFoNuusdt9eEM7rSa93l6929xfGGBC2jAcPgsRygEQ+9B69QXfvNMZPrt6SHuPvwQMHQA+l\nI44ZY3NFRUWnyhQAUFVVFeq8LtGVUkqxYsUK9OnTB9OnT7eOjx8/Hq++amxp8+qrr2LChAldURx/\nZD5k1pZB9uBBf7MC+oOLoN97ffh7y0ZHDx8yKWnkebGiydjnp5f5X5BKSUwfJI3M1nCZaPRH7gLl\nNX0b/g76zHLu/ACTJfM5MgdYl48PN6BSL7MNP2AncoBefeU5hA43Aru2g/72F/73AILrSkh7QXVd\nnj8qKMqUme1SKcsESMx3QSad2X4fsiHHZHSZS5NNiDRFgv69y40/NGILWKw9yQQsFmUpmnJTyXD9\nQ/QJinNbYfn5kPn5uLRH6OXvSzTTbBsimer2D0HfesO8LkRuuSAfsnRhEZ9+PmSA02TJaye92uWe\nnc7PYn3tCcjtBThNyKmkPNCK+afxAlZcIly6fOC6IFWFzG8taGFESHAgURja2uS5wiLR9NoJG5fC\nvL+W5vSd+vm/ZalUvNp7mBQb3ZwuEci2bt2K1157De+++y5uu+023Hbbbdi4cSNmzJiBf//731i4\ncCHeeecdzJgxoyuK449Y2XymbK7zU1mUUFj4NuOV9kLWcVln6oz8n6mUfPJx5O0x/6e6PFuypDNQ\nLpyfihFtQU79LPMyG4xczwzRSXnn4USOabbkhG7Bf4Pymx1b5wiDYVAKEdHZWMwrZp0XIJCxsusp\n8JWurXwe5ML/aPfgQ/oMAJk9L/hEEdHnxc8HhTojY60+5JXY1oqyDJH2QkQUCvm9SV1Z5WXRvu1L\nrUEmTfN+hkZMP0XhGUFtqb0CWcBgQSZNAyp7OQ9+/qnxneUbaiK+X779xmIhIrkFTV4mQoboMC6r\nH1ZOXqMk3URbKG8aWqJQxCV740YlwQxB7yGkj5d2y/3+JySTwCGJn3YkTTHAWigK70tW/+kKZPy7\n0DT5hvVhoyyPQLrEZHnsscdi9Wr5Rqp33313VxQhPGGd+jtixcLfU1wpx+JuASnjTMjB0LV/Bs6e\n4/6ClS+ZBHZuN/6W7m0HDydmn+/5JI+ff+rUplnf8079zuvpuleASWea5fPSkHFNPJFjDCZ+E5jM\nLODKV+TR6ZmTfFMjKAvvB4z3JXtm0P6KTKBIpRzzKpENzukEJTjK3AHtmBCQSERuHmNBGZqgIZPc\nw4oIFNNeJD3SXoiIgiIvkIl1JgrMgFyDnY7WxMdJHEQz0jT87Y/OU97b5H0/9k6CkGUzZ2gB13sl\nf41Ejf1SeWIx5/vg32Ekyn2WT8BUdOTPxGTucuqXpUMxyugwc8t+pzCG0Y8ki7H2kFcAtAomQll9\nhumDYRz/A/LG0X+vB9290/1FuhqymK25p/v3gn7yIbQJp8jnhPZqyJoaQLe8DQwaZh/3c+pvT5qa\nboDK1C8imiz5AY3PU5VJZIx0w1YvDZlkJeW1eWtH8OXnoKuWuo/LGj+l3sf9jslMkib6vdfbAp91\nMOXUlojvb/uHoCxfVxiTZTwBEo06JzBxIJIJZGE1ZCy660+/A133Mvc7dNAwpl/x97EBVtflAyb/\nbmOS1XgY0sk/5HWNn0mFwilY+AlWlkAWLu2FC86fE4Bz/1KxvTruRyXHPK7zQ6wjMQO5rru3PxMT\nODtvGO65HgsM8u1Zwfcgkk3CAaCip9FXeMQxSYyyFPcLFREXlEGJZ2U4tkDz0uqb75jz+yTDRvjf\nCwi/NyQAMu/m4JPyC93Hwi5kRcIIrwF9mf71eSNyXzwv3UVZ1Nbc6w/cAvrzBw13Elmi8pbm9IQk\nvt+bf+tL7xGsSj4aMmWyPLpw5fQhfGJYXkOWwWDChD1+jAyY3J3Xm8/nB36WpK8jcJWFevuQhRXI\nnCoy5zdBJg5KDa0Y8yHzSw5q/k8uuFo4QXhX0Zjzd4qTqMwBVRywvAYENsGIwjqV5P8BQpgsOQ2Z\ndGLlBTJJewlDJuZvUetCNB+BTLfTXgD+GieWGsOVGDYZmH6CzLzU1SdJrh0w4dpOzJHPyltD5pvj\ny10K4WJBQ5YuRHJPGZLFSGz4SGizLguh+SDyCTO/wH3MIfRTuEyWQYmVmYaswBRUMhlDRQ2ZbPxk\nddZoaMi0BT8Ayiol90pfm6I9sBKRX/zBTlvkh9RvTTbmBQgRYX3IwmocRd/AdDWVbKxJJu1cX151\n0dIc+PMc8OZTL1Oqnw9Ze9LUdAOUQCYiDm68D4zZmfSXngM+kWTXZpc01kP/zQpQUdvGJns2/qdS\noM8+ZX4QHbrdgxVd87+g24U91PhBsjM2l5ZNoFSXHqdr/yQ5l//b22QphWlLvDRkgN0BWSf10xTF\nE+73GuadhXXqZ0J0gTNamD7zM/d+e4Dhi5dsg/6bn0H/+UMSDYJ5v13bPeqBP7cLNWSikODh1O86\nBwCCTHQsm7/Lhyxg8pQ9nxPIXHn5JD5k9F+vuu+RzgbmoqAq+pClCx9Q5IdsgmKLgqD2rRH5JJab\n5z4m9h2Hhizq7UPG6oYJZPlm/8jIZBnCh4wdYxqySNSpLWWE3ceRJx3LiOzcjHycSLjnhi2bKJBl\n6NSv/+l39rFkm7z+W9PVkHFtgvDtI9iHjH76Eehvfx7+WQBSj92LZHv8wTsYJZCJiAMwrwkyOzB9\n9ilfUwb93/8CXfsn0H+8ItzbnBTYPmkfyraPMfEQLIy9vbjOw6/CMkxj4A2R/86UXCDjTQQ2Mudp\nkzDRij4+ZMYxcxBg5RQ0i+RELgs28yFznuFfBsDfmZmHTVjC5E//9apcWNV10A3rQNf+GXT965L7\ncWUtlGxjQyUasjBahxIz2z8zJ/ohm5hlUZaeTv3UEPrCCCTWvouCU38IDZn0d/PJakX/Jf5+fppa\nP/8sET+TZSaCr7hVmBcyocQSyIKeS6QLI5Kb7z6Vb4+iRsTPZNnf2KXFWnAw7Vsm/ouuKEvJOMTG\ncGuza00qkJEp013HAklHICME5MzznMcyEQIJOs7PDDB2JsngOgs21vyb21knlZS7ZQSk9HDBjyO8\nhkz3mUfY4Uy2L3x3o1txkkWUQCYiDm7JpD0mBjj4WhFkbGASOx/TkLH/eTNTGB8y60G8qaAzNWQe\nvmKpZHjfGj8tWJCGjKmgNR8NGW+yjMYcgwu58hYQzqRLErmZacjEActTE2CWU9TGAECjxDdN1+Xb\nuzC4NkDOucD7PP7cINNlNAYy9Wz7c9DvZ9o+fr89l8nSz4eMhje98VGWmiCQCXVPzheiQ2X+SLww\nKUb48X3ZL1gmHZOlj4+k76Q3yiPdD9vlIAiphsx8f4EWSw+TpUwQF9qWYyLzSXtB+g0y/mg+bLwH\nJhy1N8rSy4dMfB+RKJCQmA8LikFmXpbe89MUyLTvXOI8FqTp9rxXB2rIxGANXkMW4h5E6k7TJhc2\nW5vT0wpKfMiM+wSlR4bc3SQEJNGBbj/tRAlkImJn5jtQSthNXuSzj5G6e4E9+HN7Pqbumg+6e5fx\nmQ1k4oqTx29i5Z3f+fM6egsO3cM0+f5m6Hdek/79xIF/87+gP7vK/3xOW3LwoTvd+5O1cQJZLOac\nwMTJLJFwC7qZmCy9VrkRuYYMgNRkqd+zAPh0m/tcRowTMmKyJJ0Sp/4g535xog1qM0wgcyxUxHfm\nI5Bt/9DpQ+YJH2XpbCc0KclDJppoZQIZ7+QvBGs48tb5CWTpDPJiX+Hz3fn8fpIn8deyvgzxXIlA\nZeWK89vvFjCEa9mYFqQhA5zvjQW0yCbfgWaEXPNho30yrX4mGn1+y6uN/4D+qCRK3xWYFfGOTE43\n5QPfX2Q+YjyyOs8k+Ca0D1nI3yKmOeHvHSbQQiKQ6Ut+IBc209SQEYdAxpUrzNZfGWq6SI7EnJ0l\nlEAmYk7w5LtzgRPGm42Mc+r3UTnrzz8D7N4J+r6ZJd8cKOm6V4A9u4D33jaOs0HeEXqvOwezsKtH\nfuAMIVyQkyaHuy9gmiUknYxtFhwGh/O0e7CmLz0vH8QBQzvGJYaVwibWtlZD+8Pn/hEHxPzCzAQy\ncVbMRCCTahpToH9/2X2cwZdVltMowGSpXbPIeX5FT2iXLnAeC6sh4xcq4sCvBU0YJA2TJbVN1YxU\n0i3QihNbkA+ZeD0/ePtqyNIY5P1Mn36/n5nwhh8PMuVsYPjI8M/0fF7IoZ3tHyoiRqwCEoHMbufE\nkTOPu/05F4KMP8X4QHWjj7K649ueKCSIxfzOJcCQYx1tnr7yR58rOLzaJtHSDyzgxiLtzkdBzrvc\nfQ57T2Yd8Npc7dyL3OcHRgaGy0MW1ixOJlQ7D/DvJxIiOEgmVO75HNgr2eWkrTXzyEe+DYfZ+5S5\nBA0Y6nsaOXM2MPpr9mdxH94sogQykaQxsWtnzATp3decSM0G5eVEal0rfOfl98ImbK/NWdOBX9GE\nES5Gjgl/by+TQDrwAp3Xu2v22PrF1JARv8ne2hvPNFlyAioRJ6WiksxMlrKEtTKs4IMM/J1kcAMf\nka3G+eewSYD7PQ7/OQDaRdeAjDnJeY+AQdyKVPQVTAKc+sV8Wl7vnI+y5EkmQQ8JO5WKAmok6jaV\n8YsVv5x+fgJZOj5krP8Wl7q/83vPZjnJ0BHQ5lwFcvIU/kLnuYMz213BE6+0FyFMlo40PKxfpZyp\nB7Sz5zivi8VszRLXDrSZl/oWUzvzPJDyHhnm2vNom4ELCdk1nEtE774gU85xn8Pqn+2uMXGS/V1u\nnlC/cGs4xXQZZp6/dMrmBTnjO7bwzOgADRkAYN8e97FkWzsEMl5DFkLT1toKFBZDu/wG39PIhFNA\njh1lf5YFfGQJJZCJtCVtLQtL9MlMjy+/CP36872vZYM+6xhe0SVsIBO1Tw7zaEjhjB+g+pq+Gn4N\nLJ2+4aUhSwdes+LljyPzrwLsvDJ+A02yDamFFxiapmjUX2NYUJSZUz8bUNik6qUJISGjoWTaLtnt\n+LLKVqWyPGRpDX4UpEC+f6wF+57XYAjCBQnKJC6aLGXtk8BpsuQEUPrCrwHBYVecVEg0ClQKzsoy\noYLxMRcl3RE+ZHn5dp+VTVh+pkM2CbLxgr9ebMN+vqU8YQWX4lIPH7JgDRl97mn7g1mn9JUX4Rpk\neIEoGrPbv0NID9FvvPzdgmBmSddiTEvfbOrSDkvKbQlk5nfiM8RrxDFW0tepLEo7qGzScyS/l/ch\nC7NYTCN/HH1zLfDpR6HPd8D9Hv0XDwef39piCPyij5yIkKYnlLDbRSiBTICccCLyZ19hfIgnjEGW\naQeCNp8VTVVWmgthgPpyt2Gm89OQhR1QzfPI5DOh3fwjkKtvAzjpX3a+9sNlIFfcBDL1XP97p9oM\n/532wA82XlqWzz6WH2eDr88gQQ8dtM1R0ZhzEhbMRCQSkQzKnrfmHmLWH/Pp8nonvGCSyDFM3jLC\nasiCTJbSc8MEUXA/+vhxIJf57MdaWg7tujuhXX2bfUx8Z5pPHjLArSHzmjistBcUpEcVtGu/bxwX\n/QYBt09dNApt7kL7GsAZZemDdH8/BmuzHu+fzL0B2s33Qbvnp/4Cmd+Eai3gjPohvlrvcAK3r68r\nY9zJIKdNk0dZyvIb+jhWW1ogiTsD4X2gYnFb4HAIZN7F1G641/xDy0zbwvqb2Ga0EOlaRIiznRNC\noF27COQizqe2yBTIWL062rtk8SLmbxM1WIQAH2+1P867Sb7PaBiBTNJPjahLswLCCFthcx5mlFKH\ngy+rbAyQXhN19B9y2rfdC0CNtL9snUT3LFUWISPGIP9cM6KNVWRYbRXbt5GtqusPuBNSAoaDoiy3\nVGsL6O6dnlmPpTCBbPwpILE4tAnV/mY4PQVS1R/a1yeDDD3W/97JNKIpveA1DB4mS+n+kYD9DvwG\nGn71FYs5fV9knc7lQxaiC7BJgPlXeK3SeQ1ZTi7IxNPk54UWyIKc+rlHs0HSb76SmNAJIdBO+ZZv\nGcjor9m5owB520xHIPNabPBbJxECMu7rht+QDInZheTkGddY54R0oBb3WOVh7TdPknUdABk1AeS4\n0SBlFbbmNO0M9Oa7kWnIvMoTRIgFnTbxVMOsL2vPsqhEPkhBpLgUGDTcMC3L2iBrH9Go3Zb9NGSs\n7kaOBTl+nH2ONLVOAEwAEs3+xO3UT752asC93OMFGXey4zpSXOJ/jStqW3j/rnISh0CvnTQZZMTY\n4LL1qHJrOmUaMkcEdQhtUVgtbUhLgCeZCE2utEffkIy3xENYzj7dqzTdjXRty0yDZgph9G9/gn7b\nXOc5ZRUATBWsuJfa6ieh373AUPMGZbEHgMpeIMynpJhbMfkJZI4s9SGqP4wzpR8ODZmXQLbF41om\nkHkPEpSPOI3GnFoR6b5xGWjIGKzzHnOC/HtCbC3CwTrvzh42sivmryEjvPM3+97PpEP9nM69ymq+\nL/49iUK6X6Z+wCmQRXwSiFo+ZLrVNklVf/m5Lqd+ySQRVjAyN9OWwjRkssz1gEMLa+VhSnciYfdg\ngoyfyTLsZudhXA2s3RNkAplEQ+ZnCiLE8NE8dECuxWLWgs8/tduqYywSzu/R2zg8wN7DkLYc9h6P\n/Nof+44JmfxkLI4HfhGv/LUifJ0XmQIZE6L4ayQ5xUjP3s57yQQeljrEqxzHjXYdI0OOBRF3FJAJ\nlFX97fcfJvjGTyDjf5tsQVRaEXx/2b3CIvZ5qVWEE8gy3XKuk1ACmR+ZOvvxg6Zg5iRDjgP6DDD8\nptigaTpfU+YUeaA2lIZMu/NRkJmXQrvncZCeVdxDfKqVn7BlnU8ciL0c7v0YwQUOcO/CMwHfZ584\nPmr3LjMigdjK0U+A4VfM0ZjTH8B8D9pDq6A9/CvjmOh7JM4EBRJNCCsHpdDuXwHtujvlZRF9q4KE\nnCACfMjIJdfZH5gg6qfR9Emuqi15Gtri/wPtnsedX1gCGfeexMmewFdoJgVF9ruJx20BQMyhR2Br\nyFjblPkyAW4NmUz46oDoKWvrJFnUIeCs86CtgyRoD62CW0Pm0z5Caqx1c2Nt7UfLnc+7i9uvVrYl\nHEPQkGl3PWpsxeSFpoEwgcy3YLpd7/wCTew7/QZBu+cxZ/69eh/tmN/kzZ7HNE9cAIyVDiMaM0yj\nw4/3L79Xn+aPszbLolA1QUjhAwPOuxxknDP4RtbXtVse8C2HtuAHDnOqtvBukPPngcy5Etrdj9mJ\npWVtq7DYXgwI9aAteRpE1KD7CTH8GMOXccxEaPc85hYs/QjQ1ml3LHEfFIXFSNT9m2Nx+96ZbjnX\nSSiBzIdOib6Ix0HGTATqD4J+sdN4Tu9+xndMYKmrAXbv9L9PTi5IXj5IJALCq5wBOweRjKCVc39n\nh6HbP/Q/XwLhBzWHydLn2VxHJX36m3tOmuf7CTC8b47YGVnYeUk5iOloS8R7iQNsgSQjvgUF6Vkl\n968B3AKuVz2EXfk5fMjcJiTCO7CyMvlpUHz8b0hBEUh5D1dbcg9wETuHFxNeg7ZOKiiy30UsbmvI\nxPfIUjDwCVHZgClqyiQ+ZC78nPrDwqIsvYQ7zUdQDQEpKbd/q0xDJi4YQqbh0JnPjaDVIixrPuCv\nSY8LY1/fQf55tzTN1pD5bpgO+z5+ue0iUZC+g5wLLD9zpV/7Y88TBTLe97HPANs06oPn2MqPI6xd\ns7oSc5fxAtlAWwNoIfEhI6KGlhdWojFjruLve8J4kPxCEC1iJOa1tIKSsSc3314MiFq2ohKgV1/h\n2SEX/A6/0QhI30H+bU4kyJxY1c99TKYhE9sGXweZbjnXSSiBzI/OEMhiCUulTV/8b+MYG/zMhLL0\nb/83+D5+E69fQw5YxbtMRJv/FVwWEX4i5CepJo9oSggTBWD8BibA+QkwfAZ2mTOsSNCKiB/42GDJ\nBJnAdEHCe/eaJMJqyHiBxcsfg5XNSk/h3S5c+d7COEhbG6YbdUBO/bZdL6b5gbY0+9dRIscWXOIJ\n+7mCQEb4KDr2LiXpPBzHGTJnZZmQlq4TN8tL6GWu4528LVNsmo7nmo+GjNMOk2mzQpssWZoQTy0t\n4D85Cskyiab5a96ZQBbEgKFcW+a3lhLOk9Wdn2O3X72KGjLrmdxvMvs96eNhIg+CezeEaVPNvFgO\nIY7XzgBAoeSdCeUkY7/uPocXvqq/5TrmWT6pQJZnWwFkdSyOPV4LUj/YK+hIgczs8440IuK4EI26\nj8U5LWUmv6UTUQKZH3zHkEW1hIWf+OJxY9Uhe05QFCePn7YpwKnfl/yANAhh4LUJ5oRGKfVPKCvb\nX41pvwS/DjJpmv2BM+26tvSQvYegc0zBhpwxE9q5F5oHqfA/V8wnngWZPU9+Ly+tSlihgBdsA5z6\nrWcJPmTaE78Hxp7k/C6NMZG9UxKJQFv2O5A5V9lCNkuJ0driDCNniUAZiRx7oOfNHaJ5nBC7PnmN\nGuDMbbXsd24ztkdCS+2J34Ncep11T+2nv4W2bDW0J34P7bq73Ocv/53zgOkTSM69ENrN90kewGvI\nMsgjCNjvhk2KfBs1Jwzyzekg37k0va2cwj5XhqghAwIm/Ih7XJOgLXrQbv/lPbzLIvNTMs2wjvtd\nczu0R39ttRcy7yZ30ZhwxxbYXG45arpkEDP3F6nqD+2n/xP4O9wF4crPtOyyXR54YWDQcCPXpau8\n9m/Xfvo/RqSgx/PIyVNA5lztLoNX+WTuHzm5dtvj2zMfGcuXL5ED7YEV3s+yz7T/YvWblkDmvcjT\nbrgHJBozxqTzr7S/YO+OlT0SdY+3sbj9e3sFpMjoYpRA5gcvPfODR7rwWiI+7JvBViBhtocIg69A\nFuDnktd+Mw+fLZ85OtP1r7v3E+QprRRuwjVNMVGi195jMUGbIhugXE79QmoMdu+cXPtcJgzIohRj\ncbvzi+/dy+8orMmSG5A8c+WwZ3qs9EiMy4yeScoAPoQ8kTA0JeZigHgIZC54TTO/yBG3LCHETi4p\nmiy5spNEwl2PHn6GJMYFeuTkgsTiIIkc43i+u35cCXiZABSPA7yfJl9mhtfm2kFY92DRvNxvyzUX\nI9GooWkJ69Qf6rk+38nMk0ETvkzbIz4yGgUOGjnZSA/e71U4UdaeZAErFT0dufT8sq5bdcsLSo2m\nkMdpxj1dEnxwaCJZu5aZlyNRW9vsNadw4yfJyZWbSdnYkJtnPzuMQCYRchyRtvy4y4RymbYyzMKd\nLzb7DWkEvBA/32GWTDmRkCe25QUzofxE04C9Xxh/95aYPbOIEsj84AclWfbtsPAdMxauTpMaAAAe\nW0lEQVR3b+0QtCca4C9keJ0rI2gVH9YRmkV1ypyuJRmWLTNs737A0BHGFk6cmZKUCdE3/EpNjHzy\ncnoW93OUvQfRDO3SapmDMR+BRSUasngc5Ow5znsQ4vR18vJh8nJUF9EixjPEdyOB8M/q1dfpiGv5\nKJkpUszNrAND/AG5poItMJig3NrqGGipuH3OiLF2u+WdxcX3UFpu/235eHiYmMWJxW+vyF59DIFG\n3DYsTD0kjd9GtIi87zk2Qc9UQ8bqx2xfvCCfa7ZHlistpECWN4PbosdMGG3VtxWo4fPOpL+1HSbL\nQcNBvmakgSEjTzT+5zU/LgHb3ceJpbHmYBpttol3obcPKJl0pvHH0BHG/1QHMQOQXI7r7YGNMZKU\nR4SP8PPQAJFTzwh+hrj4BIJNyoD3wskyWXL3szaBlwXM5ALxBMiMi30KKRl/M4lql8HPAbz51hLE\notb/2rTvuothbp3k2jUhy6SbMOerBb9Sao+pgNcMxRMgJWUg514E+r+/AWBI+YHuSd+cDm3OVaCU\nQr86IKFre0yWHkKE9uOfQ7/javsRp54BzYyASl0lbB/Cd3oWddXUCIw9CZH5dzhOta4VBV5+C6D8\nAuf78ZpI2fF43BgMZR1aHLBd2fxNIYPb1JyPsmRElj/rvgchiPxwmf2bPMpJevUBZfuaAiAzLgbd\n9E9gh7DReESDds6FwDmSiUiEE6Qj9z0hPJCZxMzEo736IvKLPwTfE5ALv0m3ydKxijcFE23+HSDM\nXLp9q1GH3OKDlFZw9UqMPvHXF8yPgslSRJxYfAZv0m8QIj97zv2FTOMl0tZmJwQWnuF6hxI3Au2G\ne6A/9kP/Z4gCGd9GmZaCCWReQl9lL0u7qN3zGArHTEBLjZEXMXLPY85zC4oMLVU65iMgwGQJX4Es\ncoedaZ306e9+d+K4I2l32vQ50BO5oKuf5K4z+phWfTpQfTrorh3eRRw+EpFf/AH6k4+AfvSekYA4\nnb4QFlZnXppSy5zmfp+hy1IopNYAwvmQZSCQkUjENT+RSASR5b8DbT5s7KQRBEtjAxLew9IvytKR\nGob73ZaGzPZ9JeO+DnLJAtBn7IhjMmBox9d7B6A0ZH7wfhR+5rYA6Gsv2R/YBOMw44QIHmA+A2EG\nUb+OGSCQES9hR1wlieYmx/O5jrTnc+irHgO++Mz73oB74uXvIZosPTVP5nEr8aTkPRSJK2hRIDOF\njKYGt0DmOZR4qONzA0yrDFmuHCAw7NuBX32IE346yDRUYpSlqAmw/FEk5efrmdeIQTAXik79YtnF\niSVd4QJw+xzKaGu1/dNIQH2EyR0oLYj5W1mmfn4xYtYrbQ7Yy8/xfgLeRaHZxtMWyCS/n2+3Xib6\nMIhjg5efpSj0iWNBGP/M9vSHMPj1RSBQQxYKFhjG+dX5BnAEPVOXRFn6acgYfilaZDsxpJOI1VdD\nFpOfx46z/63cgFwexG5M9y5dtonHQU6aBHLSZOjPrpKfU1gM9OgN0rsf6Bv/L8Q9zUnHy6/GC87h\nn0w8zdY8SCBnnW/s7cg+f+tcQNdBP9kKMnm6/3O8hIio0JE5IZJUnw66+V+2NkzTQKbNAl37F+Bw\nI+g6sywSQYpcdj3w5RdASTlwzAm2k6vPQE/y8uWikaUhk2QCZ9fyHXnQcJDps43jl15n5ENjAllD\nvT14RSLAqAnQvil/d2TQcNB+g6zM/GTqOUDvfnaOI9cFGsjseaDP/crQqrQ0u4VOBAywIn5O/2IU\nXzqEMlk6BTJt1lzoh5uAY+z0JyyfF4nb2mAyaZqlJbYoLDai6dgCJBYzzqcU2oIfQP/HK8Z5vEA2\ncqwjMTL55nRn9nEfyJyrjGSjeflAzZfuE5oP2+0qIGmmdsl10J/7lXEvlmx2mJ28l5w5G/RPqyWF\nMP/n/eQuux7Yvcv2lzT9S7Xr7oL++kuu6GftipugP7jIvDhIIDMXJaa2jZx/Jejf1wCmdolMtTXe\n5IqbgK3vmA9hQnIUOH48oBFop02DvuYPQDwHhBCQSdNAjh0FuuVt710WZIjCnMdETwqL7fZz8hS3\nUB3GP9NaOIUXyMi8m4H3N/ufc/IUwx0gaIFtjSuZT7+kyHwPYXcuYP1JTEo708wtJ4uyZO4Fvkl3\no8CYk6Cddgbo318GmXgq9OU/Nu/FP8h8/jkXgn7xmTsZczwBcsZ3hJtzC5NJ00B377Lbori9WCRi\ntGfzuHbVrdD/7//YiWhFn9RuihLIfCCEGB0RAH79hPScyCPPADCiCB0CmUeSRMvhnRfIQjQSumeX\n9bd25S3+5a7sBXLyFNB1L4PMXQjtG1MD72+XRTKxE81XQ6aZUWypR+4yBi0CaDMvg15SDvrfP7ev\nkWjI+G17Irc+ID9XzMHjabJkGjIfHzIO3oyiVZ8OAKCb/gkKgDYcsnOW6Toi17sj8hhkwBBE7rbN\nQhof9SO9gED71rnQYezOgMNNIFX9DaE2U/x+qqCBSQsfkyUpKDQmBSGajPTpj8jti53XmCkAHCbL\ngiKQy28AXcWZ1AqKDIFMEmVJxkxEZMxE8yfZk0TkRqdJULvgaoRFm3K2/wmtLUCZGXAS0J7IoGGI\n3HI/Uj8zfrv2H99z5DLUvnMxUlKBTIiyhN0v6Efv2+UAQEZPgDZyLPRrZzpvMWyE4Z+5eyeCNGRM\nqKENB42cvlPPAe3ZB/rjPwRKKxztV/v6ZODrk53ljMYQWWC7HkS4RNDaRdcap574Dd8yuAir6WJa\n2T4DoF1+g/v7UBoy8/+w+wUD0E6aBIhZ78VzZOWRPp9pa9phoGKRnI3uyFP5M+UaMm3aLOMPKomy\nZIsBn3dKCLHaAjn+RPFb15+kVx9o9zzucruJiNHNRqGM/44fZ7Uryx2EE8QJIcac0HDIOk6GHocI\n2wPVOMn4v5tl5hdRJsuwBGgrXKbEyl7yE02Bh/DOzWFWdZKQ74ACGf/7DTpSE4Sg8gUMM5+4svJb\nBZr9yBUGn45Jgz9XjHryMFky8450a5awMO1Bss0eMDN11hZhdcLeLdMw6XpojU67nttRGjLmK5XP\nRVkG0eoWyADYbZAtStj7F02W6eb26khYewursQyT0JhHdETmkUX8eZWDTTZB5SwxTcX8NkRW2/Qp\nM2s/YYNS0sCl6fJKsss02F7jWloasizBFkbtMVkWcmNHGMKaLHlBhy2EM9Uq8UoHrpyh3G4ArsvL\n0hcJ7ZT1Ua/2q0yWRxfadXeBblxnfGioN8yUYjJTE/KNqSAzLwF94TdGZvO1f7a/LDVNK3zqBq6R\nkG/PApoaHH5nZMbFVlRI+AKH0IocPw7kjJkgg4ZBX/GfxrGqfiBnzwE5dhT0h4yVj3bL/e6GLEua\nK/pmiEJpOgMQJ3QRLQIy8zLDxAd4C3ZMu2dtzSLPaq5dd6eRzFTGoOEgZ80GqT7dFsQy9Q0CQK68\nBXTNH4Ad20C+NcOI7DJV8+Rr1cDnO0Cmfddwyv/2LNC//D7zZ12yAETMqg1AdOpPC9kAZ5kszQGb\nRW9eMt9770m2jUw8Dm3+HdY7JeNPAXZuBznzPON75t+kCSYGSTsm588DGe6xr2g70G79MeiWjaB/\nNgM3zPZGcvJAzr7ATujsBWs3LHHlvJtB/KL/JlQDu3bY74CnzwCQ6XNAvmFHgxFNA5l1Gchxo6Hf\nf7Nd7vnfB31jTWBuJXL2+UY75CPMgqJaASC/EOTci4zydgLaDfdCX/2koeVr9EgiXVphlEHMdccI\ns39pexYoISEXXQPSTz4/WOOJj/Co3XwfaJ3PjgeFJca8IGy7ROZcBTL0OMkNnXnIyNW3OdN7mGMm\nmTjJ0LS2toDMvNT4bvCxIGeeB9J/CKhfcl5WhhkXAw31IFPPgf79q4z37LFHqHbN7T5tjq3sQ+ST\nZPOTVyBVUWl6Jt4soQSykJDefUHOmh3qXG3uQuMaZsrjBbLe5oTFawp4gYyZzjiBTAv5XGeBhdxG\nslO0CMh35wqXEcPOz8ytefmGf5wolEh3MRCeKeZ4SYbb9gUASK7TT0ybNgv6X58HbTjkvUJng7Es\n3xB/79Ff8zTqEE2zQrnp/r3GwXYIZNrE06B/vgN0xzYgNw/a9PPtZ0VjIOddYX+edRlS7RDINK9w\neU0QlNPBT0MmCMbaqZIElgxWF7GEw/+RRKMg511uf2Y+QmxF7WNi0KYGRBtnCDnmeKCswhLI+GAU\ncuZ5hkDmp2URNGRagKlLfAeO7wiRpnvQvj3L3sKKnVveQ54aQrxnTp6dzNi6IZuw/c1ThGu/HQ05\nfhzIvj2g/7XCUyALLEM6Tv2ZLFBCorEUGzKYwO63/+txo/29EAiRzkeeJngrbZLxTE0Uqk1TMInH\nDb9K/lJNs9KKhNFt8fMVOWUq6Ot/9dyY3te07TdeifXM+oJXpG/fAc7zuinKZNnFELbil6xOABgZ\n6ztiO4ciM41EphssswZvJm90OahLNWTm/2xhI5qn0ikL05BxE1+EZfP3ug/b/oSdF2a17Acrf2lw\nHjBfmGmyPbnsvGA5yvw0G6wteAVs+CF7h+yZTCMZpr2yZwfteMEHVQDeUZadDb8q503k7LiXSwI4\nU317og7DkE7QRxDWTgrZdXomzF8vKFLRi1Amy06OsgxCDxbIOpwggbugA3ZokcGc+TNxyWDVI03w\nLbw7U9Dy3C2iuB077XQhSkPWgWi3/th2OuWP37EEdMc2Y5NXBp+luaQM5IKrjU2wzQSL2n98D6js\nHbxRrwfkrPOAsgpv1b5YxvueAGpr7OvzC4wycBuFawt+AH3FYmOFl/Bw/gfAa+W02xcDRAP9/FOQ\ndIILmFYiZjfRkruWoPatdSCJBLSFdwNlPaDfa2ghybybQPoPMf7+7lwj6SznbJwJpLDY9Q4yus+U\nc4C8AofZyQvtvidAP3gHxGfCd5x/9W2g722yhVDZ86fNMtqYmZgzLSSCnnbjD4FPPgBJJFBy58M4\nlBc8mJOp5xomr6A2wJyVG0zTCBt4u1wg06R/k0jEMLkOkmwKzc656Fpg5DiQQcNd32mLHjSEXJ2i\n3X5xneEL1d5FTJpodz7i9NEcNR5k7kKQ8RmaRTmBQ7vpR/KkylaQi7fJUvvhMtDtH4I+9Xhm5RDv\nd+sDKO03AAcAez/hNJ36tQdWAnt3Z1iAAB/ofCNAhzY1ppW7NQgy61Jg6HHA8JGO49rti0Oke/Kx\n7ohmzDZ/DRkhxNj6rKgTFsUdiBLIOhByjHziJoOGgQgDOG+/J4QYofr890yQGjAks7JEY5b5M9T5\nvfoCgv+RKMyRMRMNp+sDtUBUYkqSmAKImRWbpBMCD3BOmvZzImUVls8EOWG8sT+micZlYSfxRIdl\n3g4r0PreIxoNXRekV1+5H5jX+QVFgRn3020LDiQTNCkpA8x6SJx4MkhNjescdxlCvgPTh8zyVckg\nv1iHwD2W1jl/n1/KGQAguXkgX58s/y7dfuD3nI58NylzQguTm60DIcKuJYSQ9BZuInzWdq8FmaUh\n8ylXVX8gFjdOkbpnpAc55gREKyqAmpqMNWSkR2+gR+/MCsCe5eV+wTRkYaM2Q0LyCqR9gc0LvlAf\nHzIR5i/s56t53Ojg+2QZZbJUpMfgY4z/JWYqy4m1OHhPu0CYuee4UZ6nWBNSe/YZVfjimUuts55n\nCqOk0px4TPM0Ye2uq+D3Ec10EuwqPIKL0qLN9HvrYoGsowklpFYZvq2kvDLgRPOeYbYYSwcr6KML\n9SFagFaQCcbdSYNkmhlJX86y5OU+wjRwIfZT7c4oDVkW0R7+Vbt2AMgG2hU3AWfNBpH4x5BzLgAZ\nNR5koLc5Jywkr8AwZ/Ty3/xV+9Fy31WR4siC9B8M7Y6HAdO8TwqLjHbQxZsAk5Iyw7xIacZa6q5A\nu+dxO09ae2DOzl1ssswG5LRpIH0HBmppSGUvow10wHjmwBLIbH2I9p+/bFfwUCCSXHc82oRTQEvL\ngCGSCM0sQQYNM94/Z13S7l4K1LsjJbX/+B6wd4/to32EcvT3vm4MKS7tHEfvToQkcoD+8gmKRCLp\nZecOepa4CbvsnC6eqBWdj+h7FaYddEo5OrAtdxYZOUtLYBGbobaTOsIhhNgbjAed2xltQGKyJDJf\nt46ERVr75C0LZUbsYsT3TwqKpAEIJCevYzTFWUaZLBUKhROJM7ri6Mbasuz4cdktSEfRzkCczoSY\n5jUysOsWGmTUBOOPym5ufv+KQyjNVuxv5nzxxRedev+KigrUhHBUVnQtql66BtrWZmRxj0ZBvDZy\nN1F10j3JpF5o/SGQwk5Kf9CF0MNNQCzW7bR9fJ109bumlBrJWo+C+u1oumIMq6qqCnWeMlkqFAoH\nJBbLej4qRddztEzWQYuI7kBXv2tCiL0LhqLbokyWCoVCoVAoFFlGCWQKhUKhUCgUWUYJZAqFQqFQ\nKBRZRglkCoVCoVAoFFlGCWQKhUKhUCgUWUYJZAqFQqFQKBRZRglkCoVCoVAoFFlGCWQKhUKhUCgU\nWUYJZAqFQqFQKBRZRglkCoVCoVAoFFnmiNzLUqFQKBQKheJoQmnIJCxatCjbRVBIUPXS/VB10j1R\n9dL9UHXSPelO9aIEMoVCoVAoFIosowQyhUKhUCgUiiwTuffee+/NdiG6I4MHD852ERQSVL10P1Sd\ndE9UvXQ/VJ10T7pLvSinfoVCoVAoFIoso0yWCoVCoVAoFFkmmu0CdDc2bdqEVatWQdd1TJkyBTNm\nzMh2kb4S1NTUYPny5Thw4AAIIZg6dSrOPPNMNDQ04NFHH8W+fftQWVmJm266CQUFBaCUYtWqVXj7\n7beRSCQwf/78bqN2PtrQdR2LFi1CWVkZFi1ahL1792Lp0qWor6/H4MGDcf311yMajaKtrQ3Lli3D\nJ598gsLCQtx4443o0aNHtot/VNLY2IgVK1Zg586dIITg2muvRVVVleorWeaPf/wjXnnlFRBC0K9f\nP8yfPx8HDhxQ/aWLeeKJJ7Bx40YUFxdjyZIlAJDRXLJ27Vo899xzAICZM2di0qRJnVtwqrBIpVL0\nuuuuo3v27KFtbW301ltvpTt37sx2sb4S1NbW0o8//phSSmlTUxNduHAh3blzJ33mmWfo888/Tyml\n9Pnnn6fPPPMMpZTSDRs20AceeIDquk63bt1Kv//972et7Ec7L774Il26dCn9yU9+QimldMmSJfSN\nN96glFK6cuVK+tJLL1FKKf3LX/5CV65cSSml9I033qCPPPJIdgr8FeCnP/0pXbNmDaWU0ra2NtrQ\n0KD6SpbZv38/nT9/Pm1paaGUGv3kb3/7m+ovWWDLli30448/pjfffLN1LN3+UV9fTxcsWEDr6+sd\nf3cmymTJ8dFHH6FXr17o2bMnotEoTj75ZKxfvz7bxfpKUFpaaq1KcnNz0adPH9TW1mL9+vU47bTT\nAACnnXaaVR9vvfUWTj31VBBCMHz4cDQ2NqKuri5r5T9a2b9/PzZu3IgpU6YAACil2LJlC0466SQA\nwKRJkxx1wlaQJ510Et59911Q5aLa4TQ1NeH999/HN7/5TQBANBpFfn6+6ivdAF3X0drailQqhdbW\nVpSUlKj+kgVGjBiBgoICx7F0+8emTZswatQoFBQUoKCgAKNGjcKmTZs6tdzKZMlRW1uL8vJy63N5\neTm2bduWxRJ9Ndm7dy+2b9+OoUOH4uDBgygtLQUAlJSU4ODBgwCMuqqoqLCuKS8vR21trXWuomN4\n6qmncPHFF+Pw4cMAgPr6euTl5SESiQAAysrKUFtbC8DZfyKRCPLy8lBfX4+ioqLsFP4oZe/evSgq\nKsITTzyBTz/9FIMHD8bcuXNVX8kyZWVlOPvss3HttdciHo9j9OjRGDx4sOov3YR0+4coD/B111ko\nDZmiW9Hc3IwlS5Zg7ty5yMvLc3xHCAEhJEsl++qxYcMGFBcXK3+jbkYqlcL27dtx+umn48EHH0Qi\nkcALL7zgOEf1la6noaEB69evx/Lly7Fy5Uo0Nzd3ukZFkRndtX8oDRlHWVkZ9u/fb33ev38/ysrK\nsliirxbJZBJLlixBdXU1Jk6cCAAoLi5GXV0dSktLUVdXZ60ey8rKUFNTY12r6qrj2bp1K9566y28\n/fbbaG1txeHDh/HUU0+hqakJqVQKkUgEtbW11ntn/ae8vBypVApNTU0oLCzM8q84+igvL0d5eTmG\nDRsGwDB3vfDCC6qvZJl33nkHPXr0sN77xIkTsXXrVtVfugnp9o+ysjK899571vHa2lqMGDGiU8uo\nNGQcQ4YMwe7du7F3714kk0msW7cO48ePz3axvhJQSrFixQr06dMH06dPt46PHz8er776KgDg1Vdf\nxYQJE6zjr732Giil+PDDD5GXl6dMMB3MhRdeiBUrVmD58uW48cYbcfzxx2PhwoUYOXIk3nzzTQBG\nFBLrIyeeeCLWrl0LAHjzzTcxcuTIbrkKPdIpKSlBeXk5vvjiCwCGINC3b1/VV7JMRUUFtm3bhpaW\nFlBKrXpR/aV7kG7/GDNmDDZv3oyGhgY0NDRg8+bNGDNmTKeWUSWGFdi4cSN+9atfQdd1TJ48GTNn\nzsx2kb4SfPDBB7j77rvRv39/a1C64IILMGzYMDz66KOoqalxhSo/+eST2Lx5M+LxOObPn48hQ4Zk\n+VccvWzZsgUvvvgiFi1ahC+//BJLly5FQ0MDBg0ahOuvvx6xWAytra1YtmwZtm/fjoKCAtx4443o\n2bNntot+VLJjxw6sWLECyWQSPXr0wPz580EpVX0ly6xevRrr1q1DJBLBwIEDcc0116C2tlb1ly5m\n6dKleO+991BfX4/i4mLMnj0bEyZMSLt/vPLKK3j++ecBGGkvJk+e3KnlVgKZQqFQKBQKRZZRJkuF\nQqFQKBSKLKMEMoVCoVAoFIosowQyhUKhUCgUiiyjBDKFQqFQKBSKLKMEMoVCoVAoFIosowQyhULx\nleX111/H/fffn9G1q1evxuOPP97BJVIoFF9VVKZ+hUJxxLBgwQIcOHAAmmavJSdNmoR58+ZldL/q\n6mpUV1d3VPEUCoUiY5RAplAojihuv/12jBo1KtvFUCgUig5FCWQKheKIZ+3atXj55ZcxcOBAvPba\naygtLcW8efNwwgknWN8/++yzOHToEAoLCzFnzhxUV1db1913330AjP07n3rqKXzxxReoqqrC3Llz\nccwxxwAA9u7di+XLl2P79u0YNmwYqqqqHGX48MMP8fTTT2PXrl2orKzE3LlzMXLkyK59EQqF4ohF\n+ZApFIqjgm3btqFnz5548sknMXv2bDz88MNoaGhAc3MzVq1ahTvuuANPP/007r//fgwcONB1fUND\nAxYvXoxp06bhl7/8Jc466ywsXrwY9fX1AIDHHnsMgwcPxpNPPolZs2ZZ++IBxsbDixcvxsyZM/HL\nX/4Sl1xyCZYsWYJDhw511c9XKBRHOEogUygURxQPPfQQ5s6da/1bs2YNAKC4uBhnnXUWotEoTj75\nZFRVVWHjxo0AAEIIPvvsM7S2tqK0tBT9+vVz3Xfjxo3o1asXTj31VEQiEZxyyimoqqrChg0bUFNT\ng48//hjnn38+YrEYRowYgRNPPNG69rXXXsPYsWMxbtw4aJqGUaNGYciQIdbzFQqFIghlslQoFEcU\nt912m8uHbO3atSgrK7M2pgeAyspK1NbWIicnBzfeeCNefPFFrFixAscccwwuvfRS9OnTx3GP2tpa\nVFZWOo6xe9TW1iI/Px85OTmO72pqagAANTU1ePPNN7Fhwwbr+1QqpUyWCoUiNEogUygURwW1tbWg\nlFpCWU1NDcaPHw8AGDNmDMaMGYPW1lb89re/xcqVK/GjH/3IcX1ZWRn++c9/Oo7V1NRgzJgxKC0t\nRWNjI5qbmy2hjAljAFBeXo7q6mpcc801nfkTFQrFUYwyWSoUiqOCgwcP4s9//jOSyST+8Y9/4PPP\nP8fYsWNx4MABrF+/Hs3NzYhGo8jJyXFo0hhjx47F7t278cYbbyCVSmHdunXYtWsXxo0bh8rKSgwZ\nMgSrV69GMpnEBx984NCGVVdXY8OGDdi0aRN0XUdrayu2bNmC/fv3d+UrUCgURzCEUkqzXQiFQqEI\ngywP2ahRozBhwgRHlGVJSQmuuOIKjB49GnV1dVi6dCl27NgBQggGDhyIK6+8En379nVFWX7wwQdY\ntWoV9uzZg169euHyyy/HscceCwD48ssvrSjL4cOHo6qqCo2NjVi4cCEAI6jg17/+NT777DNomoah\nQ4fiqquuQkVFRde/KIVCccShBDKFQnHEIwpWCoVCcaShTJYKhUKhUCgUWUYJZAqFQqFQKBRZRpks\nFQqFQqFQKLKM0pApFAqFQqFQZBklkCkUCoVCoVBkGSWQKRQKhUKhUGQZJZApFAqFQqFQZBklkCkU\nCoVCoVBkGSWQKRQKhUKhUGSZ/w+xmjF1gmZoOwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x192cc04c470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAFRCAYAAADaTrE/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x192ff6337f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAFRCAYAAAAbyfuTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhBBCg6QTJ4QQQgihQdKJE0IIIYTQoP8BnjkqW0xm7JcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x192ff633198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.figure.Figure at 0x192cc04c470>,\n",
       " <matplotlib.figure.Figure at 0x192ff6337f0>,\n",
       " <matplotlib.figure.Figure at 0x192ff633198>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotting.plot_episode_stats(stats, smoothing_window=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
